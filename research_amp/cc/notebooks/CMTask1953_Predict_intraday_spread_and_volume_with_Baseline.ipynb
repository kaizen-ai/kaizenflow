{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54da1cc1",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44249f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "import logging\n",
    "from datetime import timedelta\n",
    "\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import GridSearchCV, TimeSeriesSplit, cross_val_score\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "import core.explore as coexplor\n",
    "import helpers.hdbg as hdbg\n",
    "import helpers.hpandas as hpandas\n",
    "import helpers.hprint as hprint\n",
    "import research_amp.transform as ramptran"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296c560f",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6153685d",
   "metadata": {},
   "outputs": [],
   "source": [
    "hdbg.init_logger(verbosity=logging.INFO)\n",
    "\n",
    "_LOG = logging.getLogger(__name__)\n",
    "\n",
    "hprint.config_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74027f12",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f1fd6d",
   "metadata": {},
   "source": [
    "## OHLCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b377ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read saved 1 month of data.\n",
    "ohlcv_cc = pd.read_csv(\"/shared_data/cc_ohlcv.csv\", index_col=\"timestamp\")\n",
    "btc_ohlcv = ohlcv_cc[ohlcv_cc[\"full_symbol\"] == \"binance::BTC_USDT\"]\n",
    "btc_ohlcv.index = pd.to_datetime(btc_ohlcv.index)\n",
    "ohlcv_cols = [\n",
    "    \"open\",\n",
    "    \"high\",\n",
    "    \"low\",\n",
    "    \"close\",\n",
    "    \"volume\",\n",
    "    \"full_symbol\",\n",
    "]\n",
    "btc_ohlcv = btc_ohlcv[ohlcv_cols]\n",
    "btc_ohlcv.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c0fa2b",
   "metadata": {},
   "source": [
    "## Bid ask data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f308d137",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read saved 1 month of data.\n",
    "bid_ask_btc = pd.read_csv(\n",
    "    \"/shared_data/bid_ask_btc_jan22_1min_last.csv\", index_col=\"timestamp\"\n",
    ")\n",
    "bid_ask_btc.index = pd.to_datetime(bid_ask_btc.index)\n",
    "\n",
    "# Transform the data.\n",
    "bid_ask_btc.index = pd.to_datetime(bid_ask_btc.index)\n",
    "# Compute bid ask stats.\n",
    "bid_ask_btc = ramptran.calculate_bid_ask_statistics(bid_ask_btc)\n",
    "# Choose only necessary values.\n",
    "bid_ask_btc = bid_ask_btc.swaplevel(axis=1)[\"binance::BTC_USDT\"][\n",
    "    [\"bid_size\", \"ask_size\", \"bid_price\", \"ask_price\", \"mid\", \"quoted_spread\"]\n",
    "]\n",
    "bid_ask_btc.index = bid_ask_btc.index.shift(-1, freq=\"T\")\n",
    "\n",
    "bid_ask_btc.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3aad4de",
   "metadata": {},
   "source": [
    "## Combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73201765",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OHLCV + bid ask\n",
    "btc = pd.concat([btc_ohlcv, bid_ask_btc], axis=1)\n",
    "btc.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace30295",
   "metadata": {},
   "source": [
    "# Create and test functions for each estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a2bd409",
   "metadata": {},
   "source": [
    "## Estimate intraday spread, volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335e291e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_target_value(df: pd.DataFrame, timestamp: pd.Timestamp, column_name: str):\n",
    "    \"\"\"\n",
    "    :param df: data that contains spread and/or volume\n",
    "    :param timestamp: timestamp for prediciton\n",
    "    :param column_name: targeted estimation value (e.g., \"quoted_spread\", \"volume\")\n",
    "    :return: value of targeted spread or volume\n",
    "    \"\"\"\n",
    "    hpandas.dassert_monotonic_index(df.index)\n",
    "    if timestamp >= df.index.min() and timestamp <= df.index.max():\n",
    "        value = df[column_name].loc[timestamp]\n",
    "    else:\n",
    "        value = np.nan\n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7784353",
   "metadata": {},
   "outputs": [],
   "source": [
    "date = pd.Timestamp(\"2022-01-01 00:01\", tz=\"UTC\")\n",
    "display(get_target_value(btc, date, \"quoted_spread\"))\n",
    "display(get_target_value(btc, date, \"volume\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d57e0fe1",
   "metadata": {},
   "source": [
    "## Naive estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e0536d5",
   "metadata": {},
   "source": [
    "Value(t+2) = Value(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59416f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_naive_value(\n",
    "    df: pd.DataFrame,\n",
    "    timestamp: pd.Timestamp,\n",
    "    column_name: str,\n",
    "    delay_in_mins: int = 2,\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Estimator for a given time is a `t - delay_in_mins` of a real value.\n",
    "\n",
    "    :param df: data that contains spread and/or volume\n",
    "    :param timestamp: timestamp for prediciton\n",
    "    :param column_name: targeted estimation value (e.g., \"quoted_spread\", \"volume\")\n",
    "    :param delay_in_mins: desired gap for target estimator, in mins\n",
    "    :return: value of predicted spread or volume\n",
    "    \"\"\"\n",
    "    # Check and define delay.\n",
    "    hdbg.dassert_lte(1, delay_in_mins)\n",
    "    delay_in_mins = timedelta(minutes=delay_in_mins)\n",
    "    # Get the value.\n",
    "    lookup_timestamp = timestamp - delay_in_mins\n",
    "    if lookup_timestamp >= df.index.min() and lookup_timestamp <= df.index.max():\n",
    "        value = get_target_value(df, lookup_timestamp, column_name)\n",
    "    else:\n",
    "        value = np.nan\n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94eec9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "date = pd.Timestamp(\"2022-01-01 00:03\", tz=\"UTC\")\n",
    "display(get_naive_value(btc, date, \"quoted_spread\"))\n",
    "display(get_naive_value(btc, date, \"volume\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee476ef0",
   "metadata": {},
   "source": [
    "## Look back N days"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85269e03",
   "metadata": {},
   "source": [
    "spread_lookback(t) = E_date[spread(t, date)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52366786",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add column with intraday time.\n",
    "btc[\"time\"] = btc.index.time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b46e4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lookback_value(\n",
    "    df: pd.DataFrame,\n",
    "    timestamp: pd.Timestamp,\n",
    "    lookback_days: int,\n",
    "    column_name: str,\n",
    "    delay: int = 0,\n",
    "    mode: str = \"mean\",\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    1) Set the period that is equal `timestamp for prediciton` - N days (lookback_days).\n",
    "    2) For that period, calculate mean (or median) value for spread in time during days.\n",
    "    3) Choose this mean value as an estimation for spread in the given timestamp.\n",
    "\n",
    "    :param df: data that contains spread\n",
    "    :param timestamp: timestamp for prediciton\n",
    "    :param lookback_days: historical period for estimation, in days\n",
    "    :param column_name: targeted estimation value (e.g., \"quoted_spread\", \"volume\")\n",
    "    :param delay: how many minutes to substract from the lookback starting period\n",
    "    :param mode: 'mean' or 'median'\n",
    "    :return: value of predicted spread\n",
    "    \"\"\"\n",
    "    # Choose sample data using lookback period (with a delay).\n",
    "    start_date = timestamp - timedelta(days=lookback_days, minutes=delay)\n",
    "    if start_date >= df.index.min() and start_date <= df.index.max():\n",
    "        sample = df.loc[start_date:timestamp]\n",
    "        # Look for the reference value for the period.\n",
    "        time_grouper = sample.groupby(\"time\")\n",
    "        if mode == \"mean\":\n",
    "            grouped = time_grouper[column_name].mean().to_frame()\n",
    "        else:\n",
    "            grouped = time_grouper[column_name].median().to_frame()\n",
    "        # Choose the lookback spread for a given time.\n",
    "        # value = grouped[timestamp.time()]\n",
    "        value = get_target_value(grouped, timestamp.time(), column_name)\n",
    "    else:\n",
    "        value = np.nan\n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c08371",
   "metadata": {},
   "outputs": [],
   "source": [
    "date = pd.Timestamp(\"2022-01-21 19:59\", tz=\"UTC\")\n",
    "display(get_lookback_value(btc, date, 14, \"quoted_spread\"))\n",
    "display(get_lookback_value(btc, date, 14, \"volume\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d6e6de",
   "metadata": {},
   "source": [
    "# Collect all estimators for the whole period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c77a237",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimation_target = \"volume\"\n",
    "\n",
    "# Generate the separate DataFrame for estimators.\n",
    "estimators = pd.DataFrame(index=btc.index[1:])\n",
    "# Add the values of a real volume.\n",
    "estimators[\"real_volume\"] = estimators.index\n",
    "estimators[\"real_volume\"] = estimators[\"real_volume\"].apply(\n",
    "    lambda x: get_target_value(btc, x, estimation_target)\n",
    ")\n",
    "\n",
    "# Add the values of naive estimator.\n",
    "estimators[\"naive_volume\"] = estimators.index\n",
    "# Starting from the second value since this estimator looks back for two periods.\n",
    "estimators[\"naive_volume\"] = estimators[\"naive_volume\"].apply(\n",
    "    lambda x: get_naive_value(btc, x, estimation_target)\n",
    ")\n",
    "\n",
    "# Add the values of lookback estimator.\n",
    "# Parameters.\n",
    "lookback = 14\n",
    "# Calculate values.\n",
    "estimators[\"lookback_volume\"] = estimators.index\n",
    "estimators[\"lookback_volume\"] = estimators[\"lookback_volume\"].apply(\n",
    "    lambda x: get_lookback_value(btc, x, lookback, estimation_target)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82c31e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fabd6db",
   "metadata": {},
   "source": [
    "# Evaluate results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a2a6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_error(\n",
    "    df: pd.DataFrame,\n",
    "    column_name_actual: str,\n",
    "    column_name_estimator: str,\n",
    "    num_std: int = 1,\n",
    "    print_results: bool = True,\n",
    ") -> pd.Series:\n",
    "    \"\"\"\n",
    "    - Calculate the error of difference between real and estimated values.\n",
    "    - Show the mean and Â± num_std*standard_deviation levels.\n",
    "\n",
    "    :param df: data with real values and estimators\n",
    "    :param column_name_actual: e.g., \"spread\", \"volume\")\n",
    "    :param column_name_estimator: estimator (e.g., \"naive_spread\", \"lookback_spread\")\n",
    "    :param num_std: number of standard deviations from mean\n",
    "    :param print_results: whether or not print results\n",
    "    :return: errors for each data point\n",
    "    \"\"\"\n",
    "    err = (\n",
    "        abs(df[column_name_actual] - df[column_name_estimator])\n",
    "        / df[column_name_actual]\n",
    "    )\n",
    "    err_mean = err.mean()\n",
    "    err_std = err.std()\n",
    "    if print_results:\n",
    "        print(\n",
    "            f\"Mean error + {num_std} std = {err_mean+num_std*err_std} \\\n",
    "              \\nMean error = {err_mean}\\\n",
    "              \\nMean error - {num_std} std = {err_mean-num_std*err_std}\"\n",
    "        )\n",
    "    return err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e2f308",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the period that is equally filled by both estimators.\n",
    "test = estimators[estimators[\"lookback_volume\"].notna()]\n",
    "test.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d271e87",
   "metadata": {},
   "source": [
    "## Naive estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f8db41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean error and upper/lower level of errors' standard deviation.\n",
    "column_name_actual = \"real_volume\"\n",
    "column_name_estimator = \"naive_volume\"\n",
    "naive_err = get_mean_error(test, column_name_actual, column_name_estimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ae9f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regress (OLS) between `real_spread` and `naive_spread`.\n",
    "predicted_var = \"real_volume\"\n",
    "predictor_vars = \"naive_volume\"\n",
    "intercept = True\n",
    "# Run OLS.\n",
    "coexplor.ols_regress(\n",
    "    test,\n",
    "    predicted_var,\n",
    "    predictor_vars,\n",
    "    intercept,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4c279b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test[[\"real_volume\", \"naive_volume\"]].plot(figsize=(15, 7))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df698048",
   "metadata": {},
   "source": [
    "## Lookback estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce817220",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean error and upper/lower level of errors' standard deviation.\n",
    "column_name_actual = \"real_volume\"\n",
    "column_name_estimator = \"lookback_volume\"\n",
    "lookback_err = get_mean_error(test, column_name_actual, column_name_estimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e802f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regress (OLS) between `real_spread` and `lookback_spread`.\n",
    "predicted_var = \"real_volume\"\n",
    "predictor_vars = \"lookback_volume\"\n",
    "intercept = True\n",
    "# Run OLS.\n",
    "coexplor.ols_regress(\n",
    "    test,\n",
    "    predicted_var,\n",
    "    predictor_vars,\n",
    "    intercept,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7da15e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test[[\"real_volume\", \"lookback_volume\"]].plot(figsize=(15, 7))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d005654f",
   "metadata": {},
   "source": [
    "# Predict via sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8953538",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd42e93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression_results(y_true, y_pred):\n",
    "    # Regression metrics\n",
    "    explained_variance = metrics.explained_variance_score(y_true, y_pred)\n",
    "    mean_absolute_error = metrics.mean_absolute_error(y_true, y_pred)\n",
    "    mse = metrics.mean_squared_error(y_true, y_pred)\n",
    "    mean_squared_log_error = metrics.mean_squared_log_error(y_true, y_pred)\n",
    "    metrics.median_absolute_error(y_true, y_pred)\n",
    "    r2 = metrics.r2_score(y_true, y_pred)\n",
    "    print(\"explained_variance: \", round(explained_variance, 4))\n",
    "    print(\"mean_squared_log_error: \", round(mean_squared_log_error, 4))\n",
    "    print(\"r2: \", round(r2, 4))\n",
    "    print(\"MAE: \", round(mean_absolute_error, 4))\n",
    "    print(\"MSE: \", round(mse, 4))\n",
    "    print(\"RMSE: \", round(np.sqrt(mse), 4))\n",
    "\n",
    "\n",
    "def rmse(actual, predict):\n",
    "    predict = np.array(predict)\n",
    "    actual = np.array(actual)\n",
    "    distance = predict - actual\n",
    "    square_distance = distance**2\n",
    "    mean_square_distance = square_distance.mean()\n",
    "    score = np.sqrt(mean_square_distance)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f0d3fc",
   "metadata": {},
   "source": [
    "## Defining training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3b847e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop NaNs.\n",
    "test_sk = hpandas.dropna(test)\n",
    "# Get rid of days with only one observations (first and last rows).\n",
    "test_sk = test_sk.iloc[1:-1]\n",
    "# Add 2 more features.\n",
    "test_sk[\"naive_real_diff\"] = test_sk[\"naive_volume\"] - test_sk[\"real_volume\"]\n",
    "test_sk[\"naive_look_diff\"] = test_sk[\"naive_volume\"] - test_sk[\"lookback_volume\"]\n",
    "# Display the results.\n",
    "display(test_sk.corr())\n",
    "display(test_sk.shape)\n",
    "display(test_sk.tail(3))\n",
    "print(f\"Set of prediciton features = {list(test_sk.columns[1:])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a04074",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training dataset: first 14 days.\n",
    "X_train = test_sk.loc[\"2022-01-15\":\"2022-01-28\"].drop([\"real_volume\"], axis=1)\n",
    "y_train = test_sk.loc[\"2022-01-15\":\"2022-01-28\", \"real_volume\"]\n",
    "\n",
    "# Testing dataset: last 3 days.\n",
    "X_test = test_sk.loc[\"2022-01-29\":\"2022-01-31\"].drop([\"real_volume\"], axis=1)\n",
    "y_test = test_sk.loc[\"2022-01-29\":\"2022-01-31\", \"real_volume\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb267e14",
   "metadata": {},
   "source": [
    "The `TimeSerieSplit` function takes as input the number of splits. Since our training data has 14 unique days (2022-01-15 - 2022-01-28), we would be setting `n_splits = 14`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e24d6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_splits = 14"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e5c7bd6",
   "metadata": {},
   "source": [
    "## Models Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b1c6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a set of various estimation modes.\n",
    "models = []\n",
    "models.append((\"LR\", LinearRegression()))\n",
    "models.append((\"NN\", MLPRegressor(solver=\"lbfgs\")))  # neural network\n",
    "models.append((\"KNN\", KNeighborsRegressor()))\n",
    "models.append(\n",
    "    (\"RF\", RandomForestRegressor(n_estimators=10))\n",
    ")  # Ensemble method - collection of many decision trees\n",
    "models.append((\"SVR\", SVR(gamma=\"auto\")))  # kernel = linear\n",
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "783f84fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate each model in turn\n",
    "results = []\n",
    "names = []\n",
    "results_stats = pd.DataFrame()\n",
    "for name, model in models:\n",
    "    # TimeSeries Cross validation\n",
    "    tscv = TimeSeriesSplit(n_splits=n_splits)\n",
    "\n",
    "    cv_results = cross_val_score(model, X_train, y_train, cv=tscv, scoring=\"r2\")\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    print(\"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std()))\n",
    "\n",
    "    results_stats.loc[name, \"mean_perf\"] = cv_results.mean()\n",
    "    results_stats.loc[name, \"std_dev_perf\"] = cv_results.std()\n",
    "\n",
    "display(results_stats.sort_values(\"mean_perf\", ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "527b5e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare Algorithms\n",
    "plt.boxplot(results, labels=names)\n",
    "plt.title(\"Algorithm Comparison\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec637cf",
   "metadata": {},
   "source": [
    "LR is a winner here, but it produces perfect results:\n",
    "- explained_variance = 1\n",
    "- mean_squared_log_error = 0\n",
    "\n",
    "That's why will try to also use RF for comparison reasons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "691f64f4",
   "metadata": {},
   "source": [
    "### Grid Searching Hyperparameters (RandomForestRegressor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79299f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-time RMSE definition.\n",
    "rmse_score = make_scorer(rmse, greater_is_better=False)\n",
    "\n",
    "# Run the model with different param variations.\n",
    "model = RandomForestRegressor()\n",
    "param_search = {\n",
    "    \"n_estimators\": [20, 50, 100],\n",
    "    \"max_features\": [\"auto\", \"sqrt\", \"log2\"],\n",
    "    \"max_depth\": [i for i in range(5, 15)],\n",
    "}\n",
    "tscv = TimeSeriesSplit(n_splits=n_splits)\n",
    "gsearch = GridSearchCV(\n",
    "    estimator=model, cv=tscv, param_grid=param_search, scoring=rmse_score\n",
    ")\n",
    "gsearch.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90dc92ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results of the best param fit.\n",
    "best_score = gsearch.best_score_\n",
    "best_model = gsearch.best_estimator_\n",
    "display(best_score)\n",
    "display(best_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b4e841",
   "metadata": {},
   "source": [
    "#### Evaluate results using testing sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c71d190",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate testing results.\n",
    "y_true = y_test.values\n",
    "y_pred = best_model.predict(X_test)\n",
    "regression_results(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73fd58b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the importance for each feature.\n",
    "imp = best_model.feature_importances_\n",
    "features = X_train.columns\n",
    "indices = np.argsort(imp)\n",
    "plt.title(\"Feature Importances\")\n",
    "plt.barh(range(len(indices)), imp[indices], color=\"b\", align=\"center\")\n",
    "plt.yticks(range(len(indices)), [features[i] for i in indices])\n",
    "plt.xlabel(\"Relative Importance\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01988efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the results of predicting on testing sample.\n",
    "rf_test = pd.concat([pd.Series(y_true), pd.Series(y_pred)], axis=1)\n",
    "rf_test.columns = [\"true\", \"predicted\"]\n",
    "rf_test.index = y_test.index\n",
    "rf_test.plot(figsize=(15, 7))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61fb5ac3",
   "metadata": {},
   "source": [
    "### Grid Searching Hyperparameters (LinearRegression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a99c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the model with different param variations.\n",
    "model_lin = LinearRegression()\n",
    "param_search_lin = {\n",
    "    \"fit_intercept\": [True, False],\n",
    "    \"normalize\": [True, False],\n",
    "}\n",
    "tscv_lin = TimeSeriesSplit(n_splits=n_splits)\n",
    "gsearch = GridSearchCV(\n",
    "    estimator=model_lin,\n",
    "    cv=tscv_lin,\n",
    "    param_grid=param_search_lin,\n",
    "    scoring=rmse_score,\n",
    ")\n",
    "gsearch.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9703717",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results of the best param fit.\n",
    "best_score_lin = gsearch.best_score_\n",
    "best_model_lin = gsearch.best_estimator_\n",
    "display(best_score_lin)\n",
    "display(best_model_lin)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221049b0",
   "metadata": {},
   "source": [
    "#### Evaluate results using testing sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9367f397",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate testing results.\n",
    "y_true = y_test.values\n",
    "y_pred_lin = best_model_lin.predict(X_test)\n",
    "regression_results(y_true, y_pred_lin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67de5b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the results of predicting on testing sample.\n",
    "lr_test = pd.concat([pd.Series(y_true), pd.Series(y_pred_lin)], axis=1)\n",
    "lr_test.columns = [\"true\", \"predicted\"]\n",
    "lr_test.index = y_test.index\n",
    "lr_test.plot(figsize=(15, 7))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
