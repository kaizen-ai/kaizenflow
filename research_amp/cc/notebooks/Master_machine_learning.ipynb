{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54da1cc1",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44249f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import logging\n",
    "import os\n",
    "import warnings\n",
    "from datetime import timedelta\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.metrics as metrics\n",
    "from scipy import stats\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import (\n",
    "    GridSearchCV,\n",
    "    TimeSeriesSplit,\n",
    "    cross_val_score,\n",
    "    train_test_split,\n",
    ")\n",
    "\n",
    "import core.config.config_ as cconconf\n",
    "import core.config.config_utils as ccocouti\n",
    "import core.features as cofeatur\n",
    "import helpers.hdbg as hdbg\n",
    "import helpers.hpandas as hpandas\n",
    "import helpers.hparquet as hparque\n",
    "import helpers.hprint as hprint\n",
    "import im_v2.crypto_chassis.data.client.crypto_chassis_clients as imvccdcccc\n",
    "import research_amp.cc.crypto_chassis_api as raccchap\n",
    "import research_amp.transform as ramptran"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296c560f",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6153685d",
   "metadata": {},
   "outputs": [],
   "source": [
    "hdbg.init_logger(verbosity=logging.INFO)\n",
    "\n",
    "_LOG = logging.getLogger(__name__)\n",
    "\n",
    "hprint.config_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03cde933",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542fec59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cmtask1953_config() -> cconconf.Config:\n",
    "    config = cconconf.Config()\n",
    "    param_dict = {\n",
    "        \"data\": {\n",
    "            # Parameters for client initialization.\n",
    "            \"im_client_ohlcv\": {\n",
    "                \"universe_version\": \"v1\",\n",
    "                \"resample_1min\": True,\n",
    "                \"root_dir\": os.path.join(\n",
    "                    # hs3.get_s3_bucket_path(\"ck\"),\n",
    "                    \"s3://cryptokaizen-data\",\n",
    "                    \"reorg\",\n",
    "                    \"historical.manual.pq\",\n",
    "                ),\n",
    "                \"partition_mode\": \"by_year_month\",\n",
    "                \"dataset\": \"ohlcv\",\n",
    "                \"contract_type\": \"spot\",\n",
    "                \"data_snapshot\": \"latest\",\n",
    "                \"aws_profile\": \"ck\",\n",
    "            },\n",
    "            \"im_client_bid_ask\": {\n",
    "                \"base_path\": \"s3://cryptokaizen-data/reorg/historical.manual.pq/20220520/bid_ask/crypto_chassis/binance/currency_pair=BTC_USDT/year=2022/\",\n",
    "                \"aws_profile\": \"ck\",\n",
    "                \"resample_bid_ask\": \"1T\",\n",
    "            },\n",
    "            # Parameters for data query.\n",
    "            \"read_data\": {\n",
    "                \"full_symbols\": [\"binance::BTC_USDT\"],\n",
    "                \"start_ts\": pd.Timestamp(\"2022-01-01 00:00\", tz=\"UTC\"),\n",
    "                \"end_ts\": pd.Timestamp(\"2022-03-31 23:59\", tz=\"UTC\"),\n",
    "                \"columns\": [\"close\", \"full_symbol\", \"volume\"],\n",
    "                \"filter_data_mode\": \"assert\",\n",
    "            },\n",
    "        },\n",
    "        \"model\": {\n",
    "            \"resampling_rule\": \"5T\",\n",
    "            \"target_value\": \"volume\",\n",
    "            \"delay_lag\": 1,\n",
    "            \"num_lags\": 4,\n",
    "            \"test_size\": 0.2,\n",
    "            \"shuffle\": False,\n",
    "            \"n_splits\": 5,\n",
    "        },\n",
    "    }\n",
    "    config = cconfig.Config.from_dict(param_dict)\n",
    "    return config\n",
    "\n",
    "\n",
    "config = get_cmtask1953_config()\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74027f12",
   "metadata": {},
   "source": [
    "# Read data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f1fd6d",
   "metadata": {},
   "source": [
    "## OHLCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fddd0618",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate the client.\n",
    "client = imvccdcccc.CryptoChassisHistoricalPqByTileClient(\n",
    "    **config[\"data\"][\"im_client_ohlcv\"]\n",
    ")\n",
    "# Load OHLCV data.\n",
    "df_ohlcv = client.read_data(**config[\"data\"][\"read_data\"])\n",
    "# Resample.\n",
    "df_ohlcv.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c0fa2b",
   "metadata": {},
   "source": [
    "## Bid ask data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0304ad14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample_and_process_bid_ask_data(df, resample_rule):\n",
    "    # Resample.\n",
    "    df = raccchap.resample_bid_ask(df, resample_rule)\n",
    "    # Convert.\n",
    "    for cols in df.columns[:-1]:\n",
    "        df[cols] = pd.to_numeric(df[cols], downcast=\"float\")\n",
    "    # Compute bid ask stats.\n",
    "    df = ramptran.calculate_bid_ask_statistics(df)\n",
    "    # Choose only necessary values (`full_symbol`).\n",
    "    df = df.swaplevel(axis=1)[\n",
    "        str(config[\"data\"][\"read_data\"][\"full_symbols\"])[2:-2]\n",
    "    ][[\"bid_size\", \"ask_size\", \"bid_price\", \"ask_price\", \"mid\", \"quoted_spread\"]]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51d8ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = config[\"data\"][\"read_data\"][\"start_ts\"]\n",
    "end_date = config[\"data\"][\"read_data\"][\"end_ts\"]\n",
    "\n",
    "# Load bid ask from s3. Note: works only for 2022 for now.\n",
    "# TODO(Grisha, Dan): How to load the bid/ask data through ImClient?\n",
    "result = []\n",
    "\n",
    "for i in range(start_date.month, end_date.month + 1):\n",
    "    print(i)\n",
    "    tmp_df = hparque.from_parquet(\n",
    "        os.path.join(\n",
    "            config[\"data\"][\"im_client_bid_ask\"][\"base_path\"],\n",
    "            f\"month={i}/data.parquet\",\n",
    "        ),\n",
    "        aws_profile=config[\"data\"][\"im_client_bid_ask\"][\"aws_profile\"],\n",
    "    )\n",
    "    result.append(tmp_df)\n",
    "bid_ask_df = pd.concat(result)\n",
    "bid_ask_df = bid_ask_df[:end_date]\n",
    "# Add `full_symbol` (necessary param for `calculate_bid_ask_statistics`).\n",
    "bid_ask_df[\"full_symbol\"] = str(config[\"data\"][\"read_data\"][\"full_symbols\"])[2:-2]\n",
    "# Choose only valid cols.\n",
    "bid_ask_df = bid_ask_df[\n",
    "    [\"bid_price\", \"bid_size\", \"ask_price\", \"ask_size\", \"full_symbol\"]\n",
    "]\n",
    "# Resample to 1-min (to be consistent with OHLCV data).\n",
    "bid_ask_df_1min = resample_and_process_bid_ask_data(\n",
    "    bid_ask_df, config[\"data\"][\"im_client_bid_ask\"][\"resample_bid_ask\"]\n",
    ")\n",
    "\n",
    "bid_ask_df_1min.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3aad4de",
   "metadata": {},
   "source": [
    "## Combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73201765",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OHLCV + bid ask\n",
    "data = pd.concat([df_ohlcv, bid_ask_df_1min], axis=1)\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace30295",
   "metadata": {},
   "source": [
    "# Compute features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b46e4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_average_intraday_value(\n",
    "    df: pd.DataFrame,\n",
    "    timestamp: pd.Timestamp,\n",
    "    lookback_days: int,\n",
    "    column_name: str,\n",
    "    delay: int = 0,\n",
    "    mode: str = \"mean\",\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Compute a feature as the mean / median of the target variable in the same\n",
    "    period of time using data in the last `lookback_days` days.\n",
    "\n",
    "    This is useful for volume, spread, volatility.\n",
    "\n",
    "    1) Set the period that is equal `timestamp for prediciton` - N days (lookback_days).\n",
    "    2) For that period, calculate mean (or median) value for target in time during days.\n",
    "    3) Choose this mean value as an estimation for target in the given timestamp.\n",
    "\n",
    "    :param df: data that contains target value\n",
    "    :param timestamp: timestamp for prediciton\n",
    "    :param lookback_days: historical period for estimation, in days\n",
    "    :param column_name: targeted estimation value (e.g., \"quoted_spread\", \"volume\")\n",
    "    :param delay: how many minutes to substract from the lookback starting period\n",
    "    :param mode: 'mean' or 'median'\n",
    "    :return: value of predicted target\n",
    "    \"\"\"\n",
    "    # Choose sample data using lookback period (with a delay).\n",
    "    start_date = timestamp - timedelta(days=lookback_days, minutes=delay)\n",
    "    if start_date >= df.index.min() and start_date <= df.index.max():\n",
    "        sample = df.loc[start_date:timestamp].loc[timestamp.time()]\n",
    "        if mode == \"mean\":\n",
    "            value = sample[column_name].mean()\n",
    "        else:\n",
    "            value = sample[column_name].median()\n",
    "    else:\n",
    "        value = np.nan\n",
    "    return value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be2f5021",
   "metadata": {},
   "source": [
    "# Assemble ml_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff993115",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify target value.\n",
    "target = config[\"model\"][\"target_value\"]\n",
    "# Add column with intraday time.\n",
    "data[\"time\"] = data.index.time\n",
    "# Add initial target values.\n",
    "ml_df = data[[target]]\n",
    "ml_df.columns = [f\"{target}_0\"]\n",
    "# Add lagged values.\n",
    "delay_lag = config[\"model\"][\"delay_lag\"]\n",
    "num_lags = config[\"model\"][\"num_lags\"]\n",
    "ml_df, info = cofeatur.compute_lagged_features(\n",
    "    ml_df, f\"{target}_0\", delay_lag, num_lags\n",
    ")\n",
    "# Add lookback estimator.\n",
    "ml_df[f\"avg_intraday_{target}\"] = ml_df.index\n",
    "ml_df[f\"avg_intraday_{target}\"] = ml_df[f\"avg_intraday_{target}\"].apply(\n",
    "    lambda x: get_average_intraday_value(data, x, 14, target)\n",
    ")\n",
    "# Drop the column with `{target}_0`, since Y-var will be added later (resampled).\n",
    "ml_df = ml_df.drop(columns=f\"{target}_0\")\n",
    "ml_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfae799c",
   "metadata": {},
   "source": [
    "# Y pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12610576",
   "metadata": {},
   "outputs": [],
   "source": [
    "def attach_resampled_y_var(\n",
    "    resampled_df: pd.DataFrame, estimators_df: pd.DataFrame, target: str\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    :param resampled_df: Data for Y-var with >1-min frequency\n",
    "    :param estimators_df: Data for X-vars with 1-min frequency\n",
    "    :param target: i.e., \"spread\" or \"volume\"\n",
    "    \"\"\"\n",
    "    if target == \"spread\":\n",
    "        # Choose Y-var.\n",
    "        resampled_df = resampled_df[[f\"quoted_{target}\"]]\n",
    "        # Rename Y-var.\n",
    "        resampled_df = resampled_df.rename(columns={\"quoted_spread\": \"spread_0\"})\n",
    "    elif target == \"volume\":\n",
    "        # Choose Y-var.\n",
    "        resampled_df = resampled_df[[f\"{target}\"]]\n",
    "        # Rename Y-var.\n",
    "        resampled_df = resampled_df.rename(columns={\"volume\": \"volume_0\"})\n",
    "    else:\n",
    "        raise ValueError(f\"Invalid target='{target}'\")\n",
    "    # Attach Y-var to the computed estimators.\n",
    "    yx_df = pd.merge(\n",
    "        resampled_df, estimators_df, left_index=True, right_index=True\n",
    "    )\n",
    "    return yx_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64154228",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The goal is to set Y-var with 5-min frequency and\n",
    "# attach previously calculated features with 1-min frequency.\n",
    "resampling_rule = config[\"model\"][\"resampling_rule\"]\n",
    "# Resample initial bid ask.\n",
    "bid_ask_df_5min = resample_and_process_bid_ask_data(bid_ask_df, resampling_rule)\n",
    "# Resample initial OHLCV.\n",
    "df_ohlcv_5min = df_ohlcv.resample(resampling_rule).agg(\n",
    "    {\"close\": \"last\", \"volume\": \"sum\"}\n",
    ")\n",
    "# Combine resampled data.\n",
    "df_5min = pd.concat([df_ohlcv_5min, bid_ask_df_5min], axis=1)\n",
    "# Update DataFrame with ML features (add resampled y-var).\n",
    "ml_df = attach_resampled_y_var(df_5min, ml_df, target)\n",
    "\n",
    "# Now we have Y-var that is sampled by 5-min, while X-vars are 1-mins.\n",
    "ml_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d005654f",
   "metadata": {},
   "source": [
    "# Train / test separation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f62c172",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify modelling data.\n",
    "ml_df = hpandas.dropna(ml_df, report_stats=True)\n",
    "display(ml_df.shape)\n",
    "display(ml_df.head(3))\n",
    "print(f\"Set of prediciton features = {list(ml_df.columns[1:])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b588e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct X and y.\n",
    "y_var_col = f\"{target}_0\"\n",
    "y = ml_df[[y_var_col]]\n",
    "X = ml_df.drop(columns=[y_var_col])\n",
    "# Split into train and test sets.\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=config[\"model\"][\"test_size\"],\n",
    "    shuffle=config[\"model\"][\"shuffle\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bbd5f4e",
   "metadata": {},
   "source": [
    "# Model set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8451b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression_results(y_true, y_pred, mae_only: bool = True):\n",
    "    # Regression metrics\n",
    "    mean_absolute_error = metrics.mean_absolute_error(y_true, y_pred)\n",
    "    print(\"MAE: \", round(mean_absolute_error, 4))\n",
    "    if not mae_only:\n",
    "        explained_variance = metrics.explained_variance_score(y_true, y_pred)\n",
    "        mse = metrics.mean_squared_error(y_true, y_pred)\n",
    "        mean_squared_log_error = metrics.mean_squared_log_error(y_true, y_pred)\n",
    "        metrics.median_absolute_error(y_true, y_pred)\n",
    "        r2 = metrics.r2_score(y_true, y_pred)\n",
    "        print(\"mean_squared_log_error: \", round(mean_squared_log_error, 4))\n",
    "        print(\"explained_variance: \", round(explained_variance, 4))\n",
    "        print(\"r2: \", round(r2, 4))\n",
    "        print(\"MAE: \", round(mean_absolute_error, 4))\n",
    "        print(\"MSE: \", round(mse, 4))\n",
    "        print(\"RMSE: \", round(np.sqrt(mse), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e24d6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_splits = config[\"model\"][\"n_splits\"]\n",
    "print(f\"Number of splits: {n_splits}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b4b890",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a set of various estimation modes.\n",
    "models = []\n",
    "models.append((\"LR\", LinearRegression()))\n",
    "# models.append((\"NN\", MLPRegressor(solver=\"lbfgs\")))  # neural network\n",
    "# models.append((\"KNN\", KNeighborsRegressor()))\n",
    "# models.append(\n",
    "#    (\"RF\", RandomForestRegressor(n_estimators=10))\n",
    "# )  # Ensemble method - collection of many decision trees\n",
    "# models.append((\"SVR\", SVR(gamma=\"auto\")))  # kernel = linear\n",
    "models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c79e3ba2",
   "metadata": {},
   "source": [
    "# Learn / evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "783f84fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate each model in turn\n",
    "results = []\n",
    "names = []\n",
    "results_stats = pd.DataFrame()\n",
    "for name, model in models:\n",
    "    # TimeSeries Cross validation\n",
    "    tscv = TimeSeriesSplit(n_splits=n_splits)\n",
    "\n",
    "    cv_results = cross_val_score(model, X_train, y_train, cv=tscv, scoring=\"r2\")\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    print(\"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std()))\n",
    "\n",
    "    results_stats.loc[name, \"mean_perf\"] = cv_results.mean()\n",
    "    results_stats.loc[name, \"std_dev_perf\"] = cv_results.std()\n",
    "\n",
    "display(results_stats.sort_values(\"mean_perf\", ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "527b5e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare Algorithms\n",
    "plt.boxplot(results, labels=names)\n",
    "plt.title(\"Algorithm Comparison\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f65f457",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO(Max): consider adding the hyperparameters tuning step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81cd750a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model.\n",
    "model = LinearRegression()\n",
    "model = model.fit(X_train, y_train)\n",
    "\n",
    "# Estimate testing results.\n",
    "y_true = y_test.values\n",
    "y_pred = model.predict(X_test)\n",
    "regression_results(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221049b0",
   "metadata": {},
   "source": [
    "# Model analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5868bf98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO(Max): consider displaying p-values.\n",
    "# Check coefficients.\n",
    "coef = pd.DataFrame(\n",
    "    {\"coef_value\": model.coef_.ravel()},\n",
    "    index=model.feature_names_in_,\n",
    ")\n",
    "coef = coef.sort_values(by=\"coef_value\", ascending=False)\n",
    "coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67de5b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the results of predicting on testing sample.\n",
    "lr_test = pd.concat(\n",
    "    [pd.Series(y_true.ravel()), pd.Series(y_pred.ravel())], axis=1\n",
    ")\n",
    "lr_test.columns = [\"true\", \"predicted\"]\n",
    "lr_test.index = y_test.index\n",
    "lr_test.plot(figsize=(15, 7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b0619a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the difference between true and predicted values.\n",
    "lr_test[\"diff\"] = lr_test[\"true\"] - lr_test[\"predicted\"]\n",
    "lr_test[\"diff\"].plot(figsize=(15, 7))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
