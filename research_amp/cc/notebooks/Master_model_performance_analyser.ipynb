{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d75d00e",
   "metadata": {},
   "source": [
    "# Description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f710a02",
   "metadata": {},
   "source": [
    "Compute and analyze model performance stats."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4549477a",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e783ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc596de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import logging\n",
    "from typing import Any, Callable, List\n",
    "\n",
    "import ipywidgets as widgets\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as st\n",
    "\n",
    "import core.config.config_ as cconconf\n",
    "import core.config.config_utils as ccocouti\n",
    "import core.statistics.requires_statsmodels as cstresta\n",
    "import core.statistics.sharpe_ratio as cstshrat\n",
    "import dataflow.model as dtfmod\n",
    "import helpers.hdbg as hdbg\n",
    "import helpers.henv as henv\n",
    "import helpers.hpandas as hpandas\n",
    "import helpers.hprint as hprint\n",
    "import im_v2.crypto_chassis.data.client as iccdc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717d24a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "hdbg.init_logger(verbosity=logging.INFO)\n",
    "\n",
    "_LOG = logging.getLogger(__name__)\n",
    "\n",
    "_LOG.info(\"%s\", henv.get_system_signature()[0])\n",
    "\n",
    "hprint.config_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7dd094b",
   "metadata": {},
   "source": [
    "# Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be23c175",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_notebook_config() -> cconconf.Config:\n",
    "    \"\"\"\n",
    "    Get notebook specific config.\n",
    "    \"\"\"\n",
    "    config = cconconf.Config()\n",
    "    param_dict = {\n",
    "        \"im_client_params\": {\n",
    "            \"universe_version\": \"v2\",\n",
    "            \"resample_1min\": True,\n",
    "            \"dataset\": \"ohlcv\",\n",
    "            \"contract_type\": \"spot\",\n",
    "            \"data_snapshot\": \"20220530\",\n",
    "        },\n",
    "        \"data\": {\n",
    "            \"dir_name\": \"/shared_data/model/historical/experiment.E1a.crypto_chassis_v2-all.5T.2018_2022/tiled_results/\",\n",
    "            \"columns\": \"volume vwap vwap.ret_0 vwap.ret_0.vol_adj vwap.ret_0.vol_adj.c vwap.ret_0.vol_adj_2 vwap.ret_0.vol_adj.lag_-2.hat\".split(),\n",
    "            \"start_date\": datetime.date(2018, 1, 1),\n",
    "            \"end_date\": datetime.date(2022, 5, 1),\n",
    "        },\n",
    "        \"column_names\": {\n",
    "            \"asset_id\": \"asset_id\",\n",
    "            \"timestamp\": \"end_ts\",\n",
    "            \"volume\": \"volume\",\n",
    "            \"y\": \"vwap.ret_0.vol_adj_2\",\n",
    "            \"y_hat\": \"vwap.ret_0.vol_adj.lag_-2.hat\",\n",
    "            \"hit\": \"hit\",\n",
    "            \"trade_pnl\": \"trade_pnl\",\n",
    "        },\n",
    "        \"stats_kwargs\": {\n",
    "            \"quantile_ranks\": 10,\n",
    "            # 28500 is the number of 5-minute intervals in ATH in a year.\n",
    "            \"time_scaling\": 28500,\n",
    "            \"n_resamples\": 1000,\n",
    "            \"alpha\": 0.05,\n",
    "        },\n",
    "        \"plot_kwargs\": {\n",
    "            \"y_min_lim_hit_rate\": 49,\n",
    "            \"y_max_lim_hit_rate\": 54,\n",
    "            \"color\": \"C0\",\n",
    "            \"capsize\": 0.2,\n",
    "            \"xticks_rotation\": 70,\n",
    "        },\n",
    "    }\n",
    "    config = cconfig.Config.from_dict(param_dict)\n",
    "    return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde4341e",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = get_notebook_config()\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3b5de5",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862ac8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_predictions_df(config: cconconf.Config) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Get data with ML predictions.\n",
    "    \"\"\"\n",
    "    backtest_df_iter = dtfmod.yield_processed_parquet_tiles_by_year(\n",
    "        config[\"data\"][\"dir_name\"],\n",
    "        config[\"data\"][\"start_date\"],\n",
    "        config[\"data\"][\"end_date\"],\n",
    "        config[\"column_names\"][\"asset_id\"],\n",
    "        data_cols=config[\"data\"][\"columns\"],\n",
    "        asset_ids=None,\n",
    "    )\n",
    "    #\n",
    "    #\n",
    "    predict_df = pd.concat(backtest_df_iter)\n",
    "    predict_df = predict_df.sort_index()\n",
    "    return predict_df\n",
    "\n",
    "\n",
    "# TODO(Max): Move the code out of the lib so we can unit test,\n",
    "# e.g., we want to add (small) specific unit tests for hit.\n",
    "# TODO(Max): Harmonize the code with calculate_hit_rate and other code there.\n",
    "# E.g., factor out the piece of calculate_hit_rate that computes hit, etc.\n",
    "def preprocess_predictions_df(\n",
    "    config: cconconf.Config, predict_df: pd.DataFrame\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Preprocess data with ML predictions for analysis.\n",
    "\n",
    "    Input:\n",
    "\n",
    "    ```\n",
    "                        volume                  vwap\n",
    "    asset_id            1464553467  1467591036  1464553467  1467591036\n",
    "    end_ts\n",
    "    2018-01-01 09:35:00   314.0657     47.3976    729.7789  12887.3945\n",
    "    2018-01-01 09:40:00   178.6543     35.1098    731.0134  12913.6854\n",
    "    ```\n",
    "\n",
    "    Output:\n",
    "\n",
    "    ```\n",
    "                                              volume        vwap\n",
    "    end_ts                        asset_id\n",
    "    2018-01-01 09:35:00  binance::ETH_USDT  314.0657    729.7789\n",
    "                         binance::BTC_USDT   47.3976  12887.3945\n",
    "    2018-01-01 09:40:00  binance::ETH_USDT  178.6543    731.0134\n",
    "                         binance::BTC_USDT   35.1098  12913.6854\n",
    "    ```\n",
    "    \"\"\"\n",
    "    # Convert the prediction stats data to Multiindex by time and asset id.\n",
    "    metrics_df = predict_df.stack()\n",
    "    # Drop NaNs to compute the performance statistics.\n",
    "    metrics_df = hpandas.dropna(metrics_df, report_stats=True)\n",
    "    # Compute hit.\n",
    "    metrics_df[\"hit\"] = (\n",
    "        metrics_df[config[\"column_names\"][\"y\"]]\n",
    "        * metrics_df[config[\"column_names\"][\"y_hat\"]]\n",
    "        >= 0\n",
    "    )\n",
    "    # Convert hit rates to desired format (`calculate_hit_rate` input).\n",
    "    metrics_df[\"hit\"] = metrics_df[\"hit\"].replace(True, 1)\n",
    "    metrics_df[\"hit\"] = metrics_df[\"hit\"].replace(False, -1)\n",
    "    # Compute trade PnL.\n",
    "    metrics_df[\"trade_pnl\"] = (\n",
    "        metrics_df[config[\"column_names\"][\"y\"]]\n",
    "        * metrics_df[config[\"column_names\"][\"y_hat\"]]\n",
    "    )\n",
    "    # TODO(*): Think about avoiding using `ImClient` for mapping.\n",
    "    # Convert asset ids to full symbols using `ImClient` mapping.\n",
    "    im_client = iccdc.get_CryptoChassisHistoricalPqByTileClient_example1(\n",
    "        **config[\"im_client_params\"]\n",
    "    )\n",
    "    metrics_df.index = metrics_df.index.set_levels(\n",
    "        metrics_df.index.levels[1].map(\n",
    "            im_client._asset_id_to_full_symbol_mapping\n",
    "        ),\n",
    "        level=1,\n",
    "    )\n",
    "    return metrics_df\n",
    "\n",
    "\n",
    "# TODO(*): Consider using bootstraping function from SciPy\n",
    "#  https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.bootstrap.html.\n",
    "# TODO(Dan): Consider to return CI values.\n",
    "def bootstrap(\n",
    "    data: pd.Series, func: Callable, n_resamples: int = 100\n",
    ") -> List[Any]:\n",
    "    \"\"\"\n",
    "    Bootstrap computations on specified number of data resamples.\n",
    "\n",
    "    :param data: input data to resample\n",
    "    :param func: function accepting a series and returning a single scalar value\n",
    "    :param n_resamples: number of resamples to create\n",
    "    :return: bootstrapped computations\n",
    "    \"\"\"\n",
    "    res_list = []\n",
    "    for i in range(n_resamples):\n",
    "        resampled_data = data.sample(frac=1, replace=True)\n",
    "        res = func(resampled_data)\n",
    "        res_list.append(res)\n",
    "    return res_list\n",
    "\n",
    "\n",
    "def compute_sharpe_ratio(\n",
    "    config: cconconf.Config, metrics_df: pd.DataFrame, by_col: str\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Compute Sharpe Ratio by specified column.\n",
    "    \"\"\"\n",
    "    res_list = []\n",
    "    for by, data in metrics_df.groupby(by_col):\n",
    "        srs = data[config[\"column_names\"][\"trade_pnl\"]].dropna()\n",
    "        func = lambda pnl: cstshrat.compute_sharpe_ratio(\n",
    "            pnl, time_scaling=config[\"stats_kwargs\"][\"time_scaling\"]\n",
    "        )\n",
    "        # Multiple Sharpe Ratios are being computed on many resamples\n",
    "        # in order to find and plot confidence intervals.\n",
    "        sharpe_ratio_srs = pd.Series(\n",
    "            bootstrap(srs, func, config[\"stats_kwargs\"][\"n_resamples\"]),\n",
    "            name=\"sharpe_ratio\",\n",
    "        )\n",
    "        # Transform and combine data for plotting.\n",
    "        sharpe_ratio_df = sharpe_ratio_srs.to_frame()\n",
    "        sharpe_ratio_df[by_col] = by\n",
    "        res_list.append(sharpe_ratio_df)\n",
    "    res_df = pd.concat(res_list)\n",
    "    #\n",
    "    return res_df\n",
    "\n",
    "\n",
    "def calculate_hit_rate_with_CI(\n",
    "    df: pd.DataFrame, group_by: str, value_col: str\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Compute hit rates, confidence intervals and errors relative to the specific\n",
    "    entity.\n",
    "\n",
    "    :param df: data with hit rates values\n",
    "    :param group_by: column name for grouping entity\n",
    "    :param value_col: column name for PnL data\n",
    "    :return: data with CIs and errors\n",
    "    \"\"\"\n",
    "    # Calculate mean value of statistics as well as CIs for each entity.\n",
    "    hit_df_stacked = df.groupby([group_by])[value_col].apply(\n",
    "        lambda data: cstresta.calculate_hit_rate(\n",
    "            data, alpha=config[\"stats_kwargs\"][\"alpha\"]\n",
    "        )\n",
    "    )\n",
    "    # Process the output and add errors.\n",
    "    hit_df = hit_df_stacked.unstack()\n",
    "    hit_errors_df = add_errors_to_ci_data(hit_df)\n",
    "    return hit_errors_df\n",
    "\n",
    "\n",
    "def calculate_CI_for_PnLs_or_SR(\n",
    "    df: pd.DataFrame, group_by: str, value_col: str\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Compute mean PnL or Sharpe Ratio, confidence intervals and errors relative\n",
    "    to the specific entity.\n",
    "\n",
    "    :param df: data with PnL or Sharpe Ratio values\n",
    "    :param group_by: column name for grouping entity\n",
    "    :param value_col: column name for PnL or Sharpe Ratio data\n",
    "    :return: data with CIs and errors\n",
    "    \"\"\"\n",
    "    grouper = df.groupby([group_by])[value_col]\n",
    "    # Calculate mean value of statistics for each entity.\n",
    "    pnl_df = grouper.mean().to_frame()\n",
    "    # Compute confidence intervals.\n",
    "    conf_ints = grouper.apply(\n",
    "        lambda data: st.t.interval(\n",
    "            1 - config[\"stats_kwargs\"][\"alpha\"],\n",
    "            data.size - 1,\n",
    "            np.mean(data),\n",
    "            st.sem(data),\n",
    "        )\n",
    "    )\n",
    "    # Attach confidence intervals to the mean value data.\n",
    "    pnl_df[[\"low\", \"high\"]] = pd.DataFrame(conf_ints.tolist(), index=pnl_df.index)\n",
    "    # Unify columns and calculate errors (required values for plotting).\n",
    "    pnl_errors_df = add_errors_to_ci_data(pnl_df)\n",
    "    return pnl_errors_df\n",
    "\n",
    "\n",
    "def add_errors_to_ci_data(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Process CI data and add errors.\n",
    "    \"\"\"\n",
    "    # Unify columns for all plotting data.\n",
    "    df.columns = [\"y\", \"ci_low\", \"ci_high\"]\n",
    "    # Required values for plotting (`yerr` input).\n",
    "    df[\"errors\"] = (df[\"ci_high\"] - df[\"ci_low\"]) / 2\n",
    "    return df\n",
    "\n",
    "\n",
    "def plot_stats_barplot(\n",
    "    df: pd.DataFrame,\n",
    "    sort_by: str,\n",
    "    ascending: bool,\n",
    "    ylabel: str,\n",
    "    ylim_min: str,\n",
    "    ylim_max: str,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    :param df: data with prediction statistics\n",
    "    :param sort_by: sorting parameter (e.g., by value, by asset, or None)\n",
    "    :param ylabel: name of the Y-axis graph\n",
    "    :param ylim_min: lower value on Y-axis graph scale\n",
    "    :param ylim_max: upper value on Y-axis graph scale\n",
    "    :return: barplot with model performance statistics\n",
    "    \"\"\"\n",
    "    # Sort data according to the input params.\n",
    "    if sort_by == \"x\":\n",
    "        df_sorted = df.sort_index(ascending=ascending)\n",
    "    elif not sort_by:\n",
    "        df_sorted = df.copy()\n",
    "    else:\n",
    "        df_sorted = df.sort_values(by=sort_by, ascending=ascending)\n",
    "    # Specify errors for plotting.\n",
    "    errors = df_sorted[\"errors\"]\n",
    "    # Plotting params.\n",
    "    df_sorted[\"y\"].plot.bar(\n",
    "        yerr=errors,\n",
    "        capsize=4,\n",
    "        width=0.8,\n",
    "    )\n",
    "    plt.xticks(rotation=xticks_rotation)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.ylim(ylim_min, ylim_max)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_bars_with_widget(\n",
    "    df: pd.DataFrame,\n",
    "    ylabel: str,\n",
    "    ylim_min: float,\n",
    "    ylim_max: float,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Add widgets to expand the sorting parameters for barplots.\n",
    "\n",
    "    :param df: data with prediction statistics\n",
    "    :param ylabel: name of the Y-axis graph\n",
    "    :param ylim_min: lower value on Y-axis graph scale\n",
    "    :param ylim_max: upper value on Y-axis graph scale\n",
    "    :return: barplot with edible model performance statistics\n",
    "    \"\"\"\n",
    "    _ = widgets.interact(\n",
    "        plot_stats_barplot,\n",
    "        df=widgets.fixed(df),\n",
    "        sort_by=widgets.ToggleButtons(\n",
    "            options=[\"x\", \"y\", \"ci_low\", \"ci_high\", False], description=\"Sort by:\"\n",
    "        ),\n",
    "        ascending=widgets.ToggleButtons(\n",
    "            options=[True, False], description=\"Ascending:\"\n",
    "        ),\n",
    "        ylabel=widgets.fixed(ylabel),\n",
    "        ylim_min=widgets.FloatText(\n",
    "            value=ylim_min,\n",
    "            description=\"Min y-value:\",\n",
    "        ),\n",
    "        ylim_max=widgets.FloatText(\n",
    "            value=ylim_max,\n",
    "            description=\"Max y-value:\",\n",
    "        ),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd96a4ed",
   "metadata": {},
   "source": [
    "# Load data with predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a776540a",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_df = load_predictions_df(config)\n",
    "print(predict_df.shape)\n",
    "predict_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f8d0c59",
   "metadata": {},
   "source": [
    "# Compute overall PnL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e507a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    predict_df[config[\"column_names\"][\"y\"]]\n",
    "    * predict_df[config[\"column_names\"][\"y_hat\"]]\n",
    ").sum(axis=1).cumsum().plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d38a3ec",
   "metadata": {},
   "source": [
    "# Get data for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443bc51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df = preprocess_predictions_df(config, predict_df)\n",
    "metrics_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2016ceb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset index to ease further preprocessing.\n",
    "# TODO(Dan): Move index resetting under plotting funtions.\n",
    "metrics_df_reset_index = metrics_df.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f725d6",
   "metadata": {},
   "source": [
    "# Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1876d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set oftenly used config parameters.\n",
    "asset_id = config[\"column_names\"][\"asset_id\"]\n",
    "timestamp = config[\"column_names\"][\"timestamp\"]\n",
    "volume = config[\"column_names\"][\"volume\"]\n",
    "y = config[\"column_names\"][\"y\"]\n",
    "y_hat = config[\"column_names\"][\"y_hat\"]\n",
    "hit = config[\"column_names\"][\"hit\"]\n",
    "trade_pnl = config[\"column_names\"][\"trade_pnl\"]\n",
    "#\n",
    "quantile_ranks = config[\"stats_kwargs\"][\"quantile_ranks\"]\n",
    "y_min_lim_hit_rate = config[\"plot_kwargs\"][\"y_min_lim_hit_rate\"]\n",
    "y_max_lim_hit_rate = config[\"plot_kwargs\"][\"y_max_lim_hit_rate\"]\n",
    "color = config[\"plot_kwargs\"][\"color\"]\n",
    "capsize = config[\"plot_kwargs\"][\"capsize\"]\n",
    "xticks_rotation = config[\"plot_kwargs\"][\"xticks_rotation\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9adc0d8",
   "metadata": {},
   "source": [
    "## By asset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef6de58",
   "metadata": {},
   "source": [
    "### Hit rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394b5c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "hit_by_asset = calculate_hit_rate_with_CI(metrics_df_reset_index, asset_id, hit)\n",
    "plot_bars_with_widget(\n",
    "    hit_by_asset, \"hit_rate\", y_min_lim_hit_rate, y_max_lim_hit_rate\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00479511",
   "metadata": {},
   "source": [
    "### PnL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9437678a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute PnL for each asset id.\n",
    "pnl_stats = (\n",
    "    metrics_df.groupby(asset_id)[trade_pnl].sum().sort_values(ascending=False)\n",
    ")\n",
    "pnl_stats = pnl_stats.rename(\"y\").to_frame()\n",
    "# Confidence Intervals are currently excluded.\n",
    "pnl_stats[\"errors\"] = 0\n",
    "# Plot PnL per asset id.\n",
    "# TODO(Max): infer y-limits automatically.\n",
    "plot_bars_with_widget(pnl_stats, \"avg_pnl_by_asset\", 0, 450)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93b8335",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot cumulative PnL over time per asset id.\n",
    "_ = metrics_df[trade_pnl].dropna().unstack().cumsum().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb14519",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot average trade PnL per asset id.\n",
    "avg_pnl_by_asset = calculate_CI_for_PnLs_or_SR(\n",
    "    metrics_df_reset_index, asset_id, trade_pnl\n",
    ")\n",
    "# TODO(Max): infer y-limits automatically.\n",
    "plot_bars_with_widget(avg_pnl_by_asset, \"avg_pnl_by_asset\", 0, 0.005)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e02e918e",
   "metadata": {},
   "source": [
    "### Sharpe Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347274ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute bootstrapped Sharpe Ratio.\n",
    "sr_by_asset = compute_sharpe_ratio(config, metrics_df_reset_index, asset_id)\n",
    "# Add CIs and errors.\n",
    "sr_ci_by_asset = calculate_CI_for_PnLs_or_SR(\n",
    "    sr_by_asset, asset_id, \"sharpe_ratio\"\n",
    ")\n",
    "# Visualize results.\n",
    "plot_bars_with_widget(sr_ci_by_asset, \"sharpe_ratio\", 0, 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb2ad71",
   "metadata": {},
   "source": [
    "## By time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2406cf0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df_reset_index[\"hour\"] = metrics_df_reset_index[timestamp].dt.hour\n",
    "metrics_df_reset_index[\"weekday\"] = metrics_df_reset_index[\n",
    "    timestamp\n",
    "].dt.day_name()\n",
    "metrics_df_reset_index[\"month\"] = metrics_df_reset_index[\n",
    "    timestamp\n",
    "].dt.month_name()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de2397a",
   "metadata": {},
   "source": [
    "### Hit Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b458aed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "hits_by_time_hour = calculate_hit_rate_with_CI(\n",
    "    metrics_df_reset_index, \"hour\", hit\n",
    ")\n",
    "plot_bars_with_widget(\n",
    "    hits_by_time_hour, \"avg_hit_rate\", y_min_lim_hit_rate, y_max_lim_hit_rate\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b70798e",
   "metadata": {},
   "outputs": [],
   "source": [
    "hits_by_time_weekday = calculate_hit_rate_with_CI(\n",
    "    metrics_df_reset_index, \"weekday\", hit\n",
    ")\n",
    "plot_bars_with_widget(\n",
    "    hits_by_time_weekday, \"avg_hit_rate\", y_min_lim_hit_rate, y_max_lim_hit_rate\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5764e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "hits_by_time_month = calculate_hit_rate_with_CI(\n",
    "    metrics_df_reset_index, \"month\", hit\n",
    ")\n",
    "plot_bars_with_widget(\n",
    "    hits_by_time_month, \"avg_hit_rate\", y_min_lim_hit_rate, y_max_lim_hit_rate\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ba14ac",
   "metadata": {},
   "source": [
    "### PnL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf379b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "pnl_by_time_hour = calculate_CI_for_PnLs_or_SR(\n",
    "    metrics_df_reset_index, \"hour\", trade_pnl\n",
    ")\n",
    "# TODO(Max): infer y-limits automatically.\n",
    "plot_bars_with_widget(pnl_by_time_hour, \"avg_pnl\", 0, 0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b4e7353",
   "metadata": {},
   "outputs": [],
   "source": [
    "pnl_by_time_weekday = calculate_CI_for_PnLs_or_SR(\n",
    "    metrics_df_reset_index, \"weekday\", trade_pnl\n",
    ")\n",
    "# TODO(Max): infer y-limits automatically.\n",
    "plot_bars_with_widget(pnl_by_time_weekday, \"avg_pnl\", 0, 0.004)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2976b08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pnl_by_time_month = calculate_CI_for_PnLs_or_SR(\n",
    "    metrics_df_reset_index, \"month\", trade_pnl\n",
    ")\n",
    "# TODO(Max): infer y-limits automatically.\n",
    "plot_bars_with_widget(pnl_by_time_month, \"avg_pnl\", 0, 0.0055)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2199fad",
   "metadata": {},
   "source": [
    "### Sharpe Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5addec55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute bootstrapped Sharpe Ratio.\n",
    "sr_by_hour = compute_sharpe_ratio(config, metrics_df_reset_index, \"hour\")\n",
    "# Add CIs and errors.\n",
    "sr_ci_by_hour = calculate_CI_for_PnLs_or_SR(sr_by_hour, \"hour\", \"sharpe_ratio\")\n",
    "# Visualize results.\n",
    "plot_bars_with_widget(sr_ci_by_hour, \"sharpe_ratio\", 0, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31bf4d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute bootstrapped Sharpe Ratio.\n",
    "sr_by_weekday = compute_sharpe_ratio(config, metrics_df_reset_index, \"weekday\")\n",
    "# Add CIs and errors.\n",
    "sr_ci_by_weekday = calculate_CI_for_PnLs_or_SR(\n",
    "    sr_by_weekday, \"weekday\", \"sharpe_ratio\"\n",
    ")\n",
    "# Visualize results.\n",
    "plot_bars_with_widget(sr_ci_by_weekday, \"sharpe_ratio\", 0, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09b5acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute bootstrapped Sharpe Ratio.\n",
    "sr_by_month = compute_sharpe_ratio(config, metrics_df_reset_index, \"month\")\n",
    "# Add CIs and errors.\n",
    "sr_ci_by_month = calculate_CI_for_PnLs_or_SR(sr_by_month, \"month\", \"sharpe_ratio\")\n",
    "# Visualize results.\n",
    "plot_bars_with_widget(sr_ci_by_month, \"sharpe_ratio\", 0, 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c45a76a",
   "metadata": {},
   "source": [
    "## By prediction magnitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca68ee01",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_magnitude = \".\".join([y_hat, \"quantile_rank\"])\n",
    "metrics_df_reset_index[prediction_magnitude] = pd.qcut(\n",
    "    metrics_df_reset_index[y_hat], quantile_ranks, labels=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef087c7",
   "metadata": {},
   "source": [
    "### Hit rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b97960",
   "metadata": {},
   "outputs": [],
   "source": [
    "hits_by_prediction_magnitude = calculate_hit_rate_with_CI(\n",
    "    metrics_df_reset_index, prediction_magnitude, hit\n",
    ")\n",
    "plot_bars_with_widget(\n",
    "    hits_by_prediction_magnitude,\n",
    "    \"avg_hit_rate\",\n",
    "    y_min_lim_hit_rate,\n",
    "    y_max_lim_hit_rate,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe1e578",
   "metadata": {},
   "source": [
    "### PnL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311cd7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pnl_by_prediction_magnitude = calculate_CI_for_PnLs_or_SR(\n",
    "    metrics_df_reset_index, prediction_magnitude, trade_pnl\n",
    ")\n",
    "# TODO(Max): infer y-limits automatically.\n",
    "plot_bars_with_widget(pnl_by_prediction_magnitude, \"avg_pnl\", 0, 0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a47a31",
   "metadata": {},
   "source": [
    "### Sharpe Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505a805f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute bootstrapped Sharpe Ratio.\n",
    "sr_by_prediction_magnitude = compute_sharpe_ratio(\n",
    "    config, metrics_df_reset_index, prediction_magnitude\n",
    ")\n",
    "# Add CIs and errors.\n",
    "sr_ci_by_prediction_magnitude = calculate_CI_for_PnLs_or_SR(\n",
    "    sr_by_prediction_magnitude, prediction_magnitude, \"sharpe_ratio\"\n",
    ")\n",
    "# Visualize results.\n",
    "plot_bars_with_widget(sr_ci_by_prediction_magnitude, \"sharpe_ratio\", -1, 12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b689693",
   "metadata": {},
   "source": [
    "## By volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eecade72",
   "metadata": {},
   "outputs": [],
   "source": [
    "volume_quantile = \".\".join([volume, \"quantile_rank\"])\n",
    "metrics_df_reset_index[volume_quantile] = metrics_df_reset_index.groupby(\n",
    "    asset_id\n",
    ")[volume].transform(lambda x: pd.qcut(x, quantile_ranks, labels=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c7b2ad",
   "metadata": {},
   "source": [
    "### Hit rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de4c8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "hits_by_volume = calculate_hit_rate_with_CI(\n",
    "    metrics_df_reset_index, volume_quantile, hit\n",
    ")\n",
    "plot_bars_with_widget(\n",
    "    hits_by_volume, \"avg_hit_rate\", y_min_lim_hit_rate, y_max_lim_hit_rate\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34dc2c05",
   "metadata": {},
   "source": [
    "### PnL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc998b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pnl_by_volume = calculate_CI_for_PnLs_or_SR(\n",
    "    metrics_df_reset_index, volume_quantile, trade_pnl\n",
    ")\n",
    "# TODO(Max): infer y-limits automatically.\n",
    "plot_bars_with_widget(pnl_by_volume, \"avg_pnl\", 0.0005, 0.0045)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "763d33da",
   "metadata": {},
   "source": [
    "### Sharpe Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100442f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute bootstrapped Sharpe Ratio.\n",
    "sr_by_volume_quantile = compute_sharpe_ratio(\n",
    "    config, metrics_df_reset_index, volume_quantile\n",
    ")\n",
    "# Add CIs and errors.\n",
    "sr_ci_by_volume_quantile = calculate_CI_for_PnLs_or_SR(\n",
    "    sr_by_volume_quantile, volume_quantile, \"sharpe_ratio\"\n",
    ")\n",
    "# Visualize results.\n",
    "plot_bars_with_widget(sr_ci_by_volume_quantile, \"sharpe_ratio\", 0, 9)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
