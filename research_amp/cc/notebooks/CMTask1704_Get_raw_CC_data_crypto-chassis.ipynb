{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58d76abe",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d2298b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import logging\n",
    "from typing import List\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "import core.config.config_ as cconconf\n",
    "import core.finance as cofinanc\n",
    "import core.finance.bid_ask as cfibiask\n",
    "import core.finance.resampling as cfinresa\n",
    "import core.plotting.normality as cplonorm\n",
    "import dataflow.core as dtfcore\n",
    "import dataflow.model.stats_computer as dtfmostcom\n",
    "import dataflow.system.source_nodes as dtfsysonod\n",
    "import helpers.hdatetime as hdateti\n",
    "import helpers.hdbg as hdbg\n",
    "import helpers.hprint as hprint\n",
    "import im_v2.common.universe as ivcu\n",
    "import core.explore as coexplor\n",
    "import core.plotting.plotting_utils as cplpluti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb220a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "hdbg.init_logger(verbosity=logging.INFO)\n",
    "\n",
    "_LOG = logging.getLogger(__name__)\n",
    "\n",
    "hprint.config_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea446ce",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0680e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cmtask1704_config_crypto_chassis() -> cconconf.Config:\n",
    "    \"\"\"\n",
    "    Get config, that specifies params for getting raw data from `crypto\n",
    "    chassis`.\n",
    "    \"\"\"\n",
    "    config = cconconf.Config()\n",
    "    # Load parameters.\n",
    "    # config.add_subconfig(\"load\")\n",
    "    # Data parameters.\n",
    "    config.add_subconfig(\"data\")\n",
    "    config[\"data\"][\"full_symbols\"] = [\"binance::BNB_USDT\", \"binance::BTC_USDT\"]\n",
    "    config[\"data\"][\"start_date\"] = pd.Timestamp(\"2022-01-01\", tz=\"UTC\")\n",
    "    config[\"data\"][\"end_date\"] = pd.Timestamp(\"2022-01-15\", tz=\"UTC\")\n",
    "    # Transformation parameters.\n",
    "    config.add_subconfig(\"transform\")\n",
    "    config[\"transform\"][\"resampling_rule\"] = \"5T\"\n",
    "    config[\"transform\"][\"rets_type\"] = \"pct_change\"\n",
    "    return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58dae195",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = get_cmtask1704_config_crypto_chassis()\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d9eef66",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "340a263b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_vwap_twap(df: pd.DataFrame, resampling_rule: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Resample the data and calculate VWAP, TWAP using DataFlow methods.\n",
    "\n",
    "    :param df: Raw data\n",
    "    :param resampling_rule: Desired resampling frequency\n",
    "    :return: Resampled multiindex DataFrame with computed metrics\n",
    "    \"\"\"\n",
    "    # Configure the node to do the TWAP / VWAP resampling.\n",
    "    node_resampling_config = {\n",
    "        \"in_col_groups\": [\n",
    "            (\"close\",),\n",
    "            (\"volume\",),\n",
    "        ],\n",
    "        \"out_col_group\": (),\n",
    "        \"transformer_kwargs\": {\n",
    "            \"rule\": resampling_rule,\n",
    "            \"resampling_groups\": [\n",
    "                ({\"close\": \"close\"}, \"last\", {}),\n",
    "                (\n",
    "                    {\n",
    "                        \"close\": \"twap\",\n",
    "                    },\n",
    "                    \"mean\",\n",
    "                    {},\n",
    "                ),\n",
    "                (\n",
    "                    {\n",
    "                        \"volume\": \"volume\",\n",
    "                    },\n",
    "                    \"sum\",\n",
    "                    {\"min_count\": 1},\n",
    "                ),\n",
    "            ],\n",
    "            \"vwap_groups\": [\n",
    "                (\"close\", \"volume\", \"vwap\"),\n",
    "            ],\n",
    "        },\n",
    "        \"reindex_like_input\": False,\n",
    "        \"join_output_with_input\": False,\n",
    "    }\n",
    "    # Put the data in the DataFlow format (which is multi-index).\n",
    "    converted_data = dtfsysonod._convert_to_multiindex(df, \"full_symbol\")\n",
    "    # Create the node.\n",
    "    nid = \"resample\"\n",
    "    node = dtfcore.GroupedColDfToDfTransformer(\n",
    "        nid,\n",
    "        transformer_func=cofinanc.resample_bars,\n",
    "        **node_resampling_config,\n",
    "    )\n",
    "    # Compute the node on the data.\n",
    "    vwap_twap = node.fit(converted_data)\n",
    "    # Save the result.\n",
    "    vwap_twap_df = vwap_twap[\"df_out\"]\n",
    "    return vwap_twap_df\n",
    "\n",
    "\n",
    "def calculate_returns(df: pd.DataFrame, rets_type: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Compute returns on the resampled data DataFlow-style.\n",
    "\n",
    "    :param df: Resampled multiindex DataFrame\n",
    "    :param rets_type: i.e., \"log_rets\" or \"pct_change\"\n",
    "    :return: The same DataFrame but with attached columns with returns\n",
    "    \"\"\"\n",
    "    # Configure the node to calculate the returns.\n",
    "    node_returns_config = {\n",
    "        \"in_col_groups\": [\n",
    "            (\"close\",),\n",
    "            (\"vwap\",),\n",
    "            (\"twap\",),\n",
    "        ],\n",
    "        \"out_col_group\": (),\n",
    "        \"transformer_kwargs\": {\n",
    "            \"mode\": rets_type,\n",
    "        },\n",
    "        \"col_mapping\": {\n",
    "            \"close\": \"close.ret_0\",\n",
    "            \"vwap\": \"vwap.ret_0\",\n",
    "            \"twap\": \"twap.ret_0\",\n",
    "        },\n",
    "    }\n",
    "    # Create the node that computes ret_0.\n",
    "    nid = \"ret0\"\n",
    "    node = dtfcore.GroupedColDfToDfTransformer(\n",
    "        nid,\n",
    "        transformer_func=cofinanc.compute_ret_0,\n",
    "        **node_returns_config,\n",
    "    )\n",
    "    # Compute the node on the data.\n",
    "    rets = node.fit(df)\n",
    "    # Save the result.\n",
    "    rets_df = rets[\"df_out\"]\n",
    "    return rets_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b068ea0",
   "metadata": {},
   "source": [
    "# Load OHLCV data from `crypto-chassis`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee6fe9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO(Max): Refactor the loading part once #1766 is implemented."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec4b7d20",
   "metadata": {},
   "source": [
    "## Functions to extract and process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc7a1b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_exchange_currency_for_api_request(full_symbol: str) -> str:\n",
    "    \"\"\"\n",
    "    Returns `exchange_id` and `currency_pair` in a format for requests to cc\n",
    "    API.\n",
    "    \"\"\"\n",
    "    cc_exchange_id, cc_currency_pair = ivcu.parse_full_symbol(full_symbol)\n",
    "    cc_currency_pair = cc_currency_pair.lower().replace(\"_\", \"-\")\n",
    "    return cc_exchange_id, cc_currency_pair\n",
    "\n",
    "\n",
    "def load_crypto_chassis_ohlcv_for_one_symbol(full_symbol: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    - Transform CK `full_symbol` to the `crypto-chassis` request format.\n",
    "    - Construct OHLCV data request for `crypto-chassis` API.\n",
    "    - Save the data as a DataFrame.\n",
    "    \"\"\"\n",
    "    # Deconstruct `full_symbol`.\n",
    "    cc_exchange_id, cc_currency_pair = get_exchange_currency_for_api_request(\n",
    "        full_symbol\n",
    "    )\n",
    "    # Build a request.\n",
    "    r = requests.get(\n",
    "        f\"https://api.cryptochassis.com/v1/ohlc/{cc_exchange_id}/{cc_currency_pair}?startTime=0\"\n",
    "    )\n",
    "    # Get url with data.\n",
    "    url = r.json()[\"historical\"][\"urls\"][0][\"url\"]\n",
    "    # Read the data.\n",
    "    df = pd.read_csv(url, compression=\"gzip\")\n",
    "    return df\n",
    "\n",
    "\n",
    "def apply_ohlcv_transformation(\n",
    "    df: pd.DataFrame,\n",
    "    full_symbol: str,\n",
    "    start_date: pd.Timestamp,\n",
    "    end_date: pd.Timestamp,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    The following transformations are applied:\n",
    "\n",
    "    - Convert `timestamps` to the usual format.\n",
    "    - Convert data columns to `float`.\n",
    "    - Add `full_symbol` column.\n",
    "    \"\"\"\n",
    "    # Convert `timestamps` to the usual format.\n",
    "    df = df.rename(columns={\"time_seconds\": \"timestamp\"})\n",
    "    df[\"timestamp\"] = df[\"timestamp\"].apply(\n",
    "        lambda x: hdateti.convert_unix_epoch_to_timestamp(x, unit=\"s\")\n",
    "    )\n",
    "    df = df.set_index(\"timestamp\")\n",
    "    # Convert to `float`.\n",
    "    for cols in df.columns:\n",
    "        df[cols] = df[cols].astype(float)\n",
    "    # Add `full_symbol`.\n",
    "    df[\"full_symbol\"] = full_symbol\n",
    "    # Note: I failed to put [start_time, end_time] to historical request.\n",
    "    # Now it loads all the available data.\n",
    "    # For that reason the time interval is hardcoded on this stage.\n",
    "    df = df.loc[(df.index >= start_date) & (df.index <= end_date)]\n",
    "    return df\n",
    "\n",
    "\n",
    "def read_crypto_chassis_ohlcv(\n",
    "    full_symbols: List[str], start_date: pd.Timestamp, end_date: pd.Timestamp\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    - Load the raw data for one symbol.\n",
    "    - Convert it to CK format.\n",
    "    - Repeat the first two steps for all `full_symbols`.\n",
    "    - Concentrate them into unique DataFrame.\n",
    "    \"\"\"\n",
    "    result = []\n",
    "    for full_symbol in full_symbols:\n",
    "        # Load raw data.\n",
    "        df_raw = load_crypto_chassis_ohlcv_for_one_symbol(full_symbol)\n",
    "        # Process it to CK format.\n",
    "        df = apply_ohlcv_transformation(df_raw, full_symbol, start_date, end_date)\n",
    "        result.append(df)\n",
    "    final_df = pd.concat(result)\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a710edd8",
   "metadata": {},
   "source": [
    "## Data demonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873c900c",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_symbols = config[\"data\"][\"full_symbols\"]\n",
    "start_date = config[\"data\"][\"start_date\"]\n",
    "end_date = config[\"data\"][\"end_date\"]\n",
    "\n",
    "ohlcv_cc = read_crypto_chassis_ohlcv(full_symbols, start_date, end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d39f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "ohlcv_cc.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbccce83",
   "metadata": {},
   "source": [
    "# Calculate VWAP, TWAP and returns in `Dataflow` style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f8eb0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VWAP, TWAP transformation.\n",
    "resampling_rule = config[\"transform\"][\"resampling_rule\"]\n",
    "vwap_twap_df = calculate_vwap_twap(ohlcv_cc, resampling_rule)\n",
    "\n",
    "# Returns calculation.\n",
    "rets_type = config[\"transform\"][\"rets_type\"]\n",
    "vwap_twap_rets_df = calculate_returns(vwap_twap_df, rets_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa23e95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the snippet.\n",
    "vwap_twap_rets_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556c808e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stats and vizualisation to check the outcomes.\n",
    "bnb_ex = vwap_twap_rets_df.swaplevel(axis=1)\n",
    "bnb_ex = bnb_ex[\"binance::BNB_USDT\"][[\"close.ret_0\", \"twap.ret_0\", \"vwap.ret_0\"]]\n",
    "display(bnb_ex.corr())\n",
    "bnb_ex.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc86ee7",
   "metadata": {},
   "source": [
    "# Bid-ask data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2882f2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO(Max): Refactor the loading part once #1766 is implemented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049148ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_list_of_dates_for_period(\n",
    "    start_date: pd.Timestamp, end_date: pd.Timestamp\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Since cc API only loads the data for one day, on need to get all the\n",
    "    timestamps for days in the interval.\n",
    "    \"\"\"\n",
    "    # Get the list of all dates in the range.\n",
    "    num_of_periods = (end_date - start_date).days\n",
    "    datelist = pd.date_range(start_date, periods=num_of_periods).tolist()\n",
    "    datelist = [str(x.strftime(\"%Y-%m-%d\")) for x in datelist]\n",
    "    return datelist\n",
    "\n",
    "\n",
    "def load_bid_ask_data_for_one_symbol(\n",
    "    full_symbol: str, start_date: pd.Timestamp, end_date: pd.Timestamp\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    For each date inside the period load the bid-ask data.\n",
    "    \"\"\"\n",
    "    # Using the variables from `datelist` the multiple requests can be sent to the API.\n",
    "    list_of_dates = get_list_of_dates_for_period(start_date, end_date)\n",
    "    result = []\n",
    "    for date in list_of_dates:\n",
    "        # Deconstruct `full_symbol` for API request.\n",
    "        cc_exchange_id, cc_currency_pair = get_exchange_currency_for_api_request(\n",
    "            full_symbol\n",
    "        )\n",
    "        # Interaction with the API.\n",
    "        r = requests.get(\n",
    "            f\"https://api.cryptochassis.com/v1/market-depth/{cc_exchange_id}/{cc_currency_pair}?startTime={date}\"\n",
    "        )\n",
    "        data = pd.read_csv(r.json()[\"urls\"][0][\"url\"], compression=\"gzip\")\n",
    "        # Attaching it day-by-day to the final DataFrame.\n",
    "        result.append(data)\n",
    "    bid_ask_df = pd.concat(result)\n",
    "    return bid_ask_df\n",
    "\n",
    "\n",
    "def apply_bid_ask_transformation(\n",
    "    df: pd.DataFrame, full_symbol: str\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    - Divide (price, size) columns.\n",
    "    - Convert timestamps and set them as index.\n",
    "    - Convert data columns to `float`.\n",
    "    - Add `full_symbol` column.\n",
    "    \"\"\"\n",
    "    # Split the columns to differentiate between `price` and `size`.\n",
    "    df[[\"bid_price\", \"bid_size\"]] = df[\"bid_price_bid_size\"].str.split(\n",
    "        \"_\", expand=True\n",
    "    )\n",
    "    df[[\"ask_price\", \"ask_size\"]] = df[\"ask_price_ask_size\"].str.split(\n",
    "        \"_\", expand=True\n",
    "    )\n",
    "    df = df.drop(columns=[\"bid_price_bid_size\", \"ask_price_ask_size\"])\n",
    "    # Convert `timestamps` to the usual format.\n",
    "    df = df.rename(columns={\"time_seconds\": \"timestamp\"})\n",
    "    df[\"timestamp\"] = df[\"timestamp\"].apply(\n",
    "        lambda x: hdateti.convert_unix_epoch_to_timestamp(x, unit=\"s\")\n",
    "    )\n",
    "    df = df.set_index(\"timestamp\")\n",
    "    # Convert to `float`.\n",
    "    for cols in df.columns:\n",
    "        df[cols] = df[cols].astype(float)\n",
    "    # Add `full_symbol` column.\n",
    "    df[\"full_symbol\"] = full_symbol\n",
    "    return df\n",
    "\n",
    "\n",
    "def resample_bid_ask(df: pd.DataFrame, resampling_rule: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    In the current format the data is presented in the `seconds` frequency. In\n",
    "    order to convert it to the minutely (or other) frequencies the following\n",
    "    aggregation rules are applied:\n",
    "\n",
    "    - Size is the sum of all sizes during the resampling period\n",
    "    - Price is the mean of all prices during the resampling period\n",
    "    \"\"\"\n",
    "    new_df = cfinresa.resample(df, rule=resampling_rule).agg(\n",
    "        {\n",
    "            \"bid_price\": \"mean\",\n",
    "            \"bid_size\": \"sum\",\n",
    "            \"ask_price\": \"mean\",\n",
    "            \"ask_size\": \"sum\",\n",
    "            \"full_symbol\": \"last\",\n",
    "        }\n",
    "    )\n",
    "    return new_df\n",
    "\n",
    "\n",
    "def read_and_resample_bid_ask_data(\n",
    "    full_symbols: List[str],\n",
    "    start_date: pd.Timestamp,\n",
    "    end_date: pd.Timestamp,\n",
    "    resampling_rule: str,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    General method that does:\n",
    "\n",
    "    - Data loading\n",
    "    - Transformation to CK format\n",
    "    - Resampling\n",
    "    \"\"\"\n",
    "    result = []\n",
    "    for full_symbol in full_symbols:\n",
    "        # Load raw bid ask data.\n",
    "        df = load_bid_ask_data_for_one_symbol(full_symbol, start_date, end_date)\n",
    "        # Apply transformation.\n",
    "        df = apply_bid_ask_transformation(df, full_symbol)\n",
    "        # Resample the data.\n",
    "        df = resample_bid_ask(df, resampling_rule)\n",
    "        result.append(df)\n",
    "    bid_ask_df = pd.concat(result)\n",
    "    return bid_ask_df\n",
    "\n",
    "\n",
    "def calculate_bid_ask_statistics(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    # Convert to multiindex.\n",
    "    converted_df = dtfsysonod._convert_to_multiindex(df, \"full_symbol\")\n",
    "    # Configure the node to calculate the returns.\n",
    "    node_bid_ask_config = {\n",
    "        \"in_col_groups\": [\n",
    "            (\"ask_price\",),\n",
    "            (\"ask_size\",),\n",
    "            (\"bid_price\",),\n",
    "            (\"bid_size\",),\n",
    "        ],\n",
    "        \"out_col_group\": (),\n",
    "        \"transformer_kwargs\": {\n",
    "            \"bid_col\": \"bid_price\",\n",
    "            \"ask_col\": \"ask_price\",\n",
    "            \"bid_volume_col\": \"bid_size\",\n",
    "            \"ask_volume_col\": \"ask_size\",\n",
    "        },\n",
    "    }\n",
    "    # Create the node that computes bid ask metrics.\n",
    "    nid = \"process_bid_ask\"\n",
    "    node = dtfcore.GroupedColDfToDfTransformer(\n",
    "        nid,\n",
    "        transformer_func=cfibiask.process_bid_ask,\n",
    "        **node_bid_ask_config,\n",
    "    )\n",
    "    # Compute the node on the data.\n",
    "    bid_ask_metrics = node.fit(converted_df)\n",
    "    # Save the result.\n",
    "    bid_ask_metrics = bid_ask_metrics[\"df_out\"]\n",
    "    # Convert relative spread to bps.\n",
    "    bid_ask_metrics[\"relative_spread\"] = bid_ask_metrics[\"relative_spread\"]*10000\n",
    "    return bid_ask_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5721338",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the params.\n",
    "full_symbols = config[\"data\"][\"full_symbols\"]\n",
    "start_date = config[\"data\"][\"start_date\"]\n",
    "end_date = config[\"data\"][\"end_date\"]\n",
    "# Get the data.\n",
    "bid_ask_df = read_and_resample_bid_ask_data(\n",
    "    full_symbols, start_date, end_date, \"5T\"\n",
    ")\n",
    "bid_ask_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ccb2409",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate bid-ask metrics.\n",
    "bid_ask_df = calculate_bid_ask_statistics(bid_ask_df)\n",
    "bid_ask_df.tail(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb3d7f6e",
   "metadata": {},
   "source": [
    "## Unite VWAP, TWAP, rets statistics with bid-ask stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8633be",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.concat([vwap_twap_rets_df, bid_ask_df], axis=1)\n",
    "final_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c87bd72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics visualizations.\n",
    "final_df[[\"relative_spread\"]].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31cee040",
   "metadata": {},
   "source": [
    "## Compute the distribution of (return - spread)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580e2761",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the specific `full_symbol`.\n",
    "df_bnb = final_df.swaplevel(axis=1)[\"binance::BNB_USDT\"]\n",
    "df_bnb.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f5f10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate (|returns| - spread) and display descriptive stats.\n",
    "df_bnb[\"ret_spr_diff\"] = abs(df_bnb[\"close.ret_0\"]) - (df_bnb[\"quoted_spread\"]/df_bnb[\"close\"])\n",
    "display(df_bnb[\"ret_spr_diff\"].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b871cd65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the result\n",
    "cplonorm.plot_qq(df_bnb[\"ret_spr_diff\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b029b8",
   "metadata": {},
   "source": [
    "# Deep dive into quantitative statistics #1805"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "658ee23a",
   "metadata": {},
   "source": [
    "## Check that our VWAP and TWAP match the version reported by Chassis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a95971",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load minutely OHLCV data from crypto-chassis (so we don't corrupt initial vwap, twap).\n",
    "# Time interval = 2 years\n",
    "full_symbol = [\"binance::BTC_USDT\"]\n",
    "start_date = pd.Timestamp(\"2020-01-01\", tz=\"UTC\")\n",
    "end_date = pd.Timestamp(\"2022-01-01\", tz=\"UTC\")\n",
    "df = read_crypto_chassis_ohlcv(full_symbol, start_date, end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee5791d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VWAP, TWAP transformation.\n",
    "resampling_rule = \"1T\"\n",
    "vwap_twap_df = calculate_vwap_twap(df, resampling_rule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7deb5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct DataFrame with VWAP, TWAP from different sources.\n",
    "# _chassis - vwap,twap from raw data.\n",
    "cc_vwap = df[[\"vwap\", \"twap\"]]\n",
    "cc_vwap = cc_vwap.add_suffix('_chassis')\n",
    "# _ck - vwap,twap calculated with the nodes.\n",
    "ck_vwap = vwap_twap_df.swaplevel(axis=1)[\"binance::BTC_USDT\"][[\"vwap\", \"twap\"]]\n",
    "ck_vwap = ck_vwap.add_suffix('_ck')\n",
    "# Unique DataFrame.\n",
    "ols_df = pd.concat([cc_vwap, \n",
    "                    ck_vwap],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85cbd769",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OLS VWAP.\n",
    "predicted_var = \"vwap_chassis\"\n",
    "predictor_vars = \"vwap_ck\"\n",
    "intercept = False\n",
    "# Run OLS.\n",
    "coexplor.ols_regress(\n",
    "    ols_df,\n",
    "    predicted_var,\n",
    "    predictor_vars,\n",
    "    intercept,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d61b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OLS TWAP.\n",
    "predicted_var = \"twap_chassis\"\n",
    "predictor_vars = \"twap_ck\"\n",
    "intercept = False\n",
    "# Run OLS.\n",
    "coexplor.ols_regress(\n",
    "    ols_df,\n",
    "    predicted_var,\n",
    "    predictor_vars,\n",
    "    intercept,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746282bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(ols_df.corr())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da643a3d",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86bedeab",
   "metadata": {},
   "source": [
    "Judging by the numbers above, I think it's fair to say that the vwap,twap from raw data is almost a perfect match with the ones computed with internal methods."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "973fe68a",
   "metadata": {},
   "source": [
    "## How much liquidity is available at the top of the book?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c058a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "liquidity_stats = (final_df[\"ask_size\"] * final_df[\"ask_price\"]).median()\n",
    "display(liquidity_stats)\n",
    "cplpluti.plot_barplot(liquidity_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c15480b",
   "metadata": {},
   "source": [
    "## Is the quoted spread constant over the day?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d9cd04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_overtime_spread(coin_df, resampling_rule, num_stds=1):\n",
    "    df = cfinresa.resample(coin_df, rule=resampling_rule)[\"quoted_spread\"].mean().to_frame()\n",
    "    df[\"time\"] = df.index.time\n",
    "    mean = df.groupby(\"time\")[\"quoted_spread\"].mean()\n",
    "    std = df.groupby(\"time\")[\"quoted_spread\"].std()\n",
    "    (mean + num_stds * std).plot(color=\"blue\")\n",
    "    mean.plot(lw=2, color=\"black\")\n",
    "    #(mean - num_stds * std).plot(color=\"blue\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e1cda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#full_symbol = \"binance::BNB_USDT\"\n",
    "full_symbol = \"binance::BTC_USDT\"\n",
    "data = final_df.swaplevel(axis=1)[full_symbol]\n",
    "dd = plot_overtime_spread(data, \"10T\")\n",
    "display(dd.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5effa6c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f819e753",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "24f6974c",
   "metadata": {},
   "source": [
    "## - Compute some high-level stats (e.g., median relative spread, median bid / ask notional, volatility, volume) by coins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd0c43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "high_level_stats = pd.DataFrame()\n",
    "high_level_stats[\"median_relative_spread\"] = final_df[\"relative_spread\"].median()\n",
    "high_level_stats[\"median_notional_bid\"] = final_df[\"bid_value\"].median()\n",
    "high_level_stats[\"median_notional_ask\"] = final_df[\"ask_value\"].median()\n",
    "high_level_stats[\"median_notional_volume\"] = (final_df[\"volume\"]*final_df[\"close\"]).median()\n",
    "high_level_stats[\"volatility_for_period\"] = final_df['close.ret_0'].std()*final_df.shape[0]**0.5\n",
    "\n",
    "high_level_stats.head(3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
