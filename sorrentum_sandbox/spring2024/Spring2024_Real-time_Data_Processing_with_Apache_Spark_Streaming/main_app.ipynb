{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0HoQ-_fX9pUL"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/spark/python/pyspark/streaming/context.py:72: FutureWarning: DStream is deprecated as of Spark 3.4.0. Migrate to Structured Streaming.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark Streaming context...\n",
      "Awaiting termination...\n",
      "New Batch Arrived!\n",
      "Average characters per Tweet in this batch: 136.47\n",
      "Shortest Tweet in this batch: 38 characters\n",
      "Longest Tweet in this batch: 217 characters\n",
      "\n",
      "New Batch Arrived!\n",
      "Average characters per Tweet in this batch: 130.98\n",
      "Shortest Tweet in this batch: -8 characters\n",
      "Longest Tweet in this batch: 249 characters\n",
      "\n",
      "New Batch Arrived!\n",
      "Average characters per Tweet in this batch: 137.89\n",
      "Shortest Tweet in this batch: 43 characters\n",
      "Longest Tweet in this batch: 255 characters\n",
      "\n",
      "New Batch Arrived!\n",
      "Average characters per Tweet in this batch: 136.46\n",
      "Shortest Tweet in this batch: 22 characters\n",
      "Longest Tweet in this batch: 260 characters\n",
      "\n",
      "New Batch Arrived!\n",
      "Average characters per Tweet in this batch: 137.69\n",
      "Shortest Tweet in this batch: 62 characters\n",
      "Longest Tweet in this batch: 226 characters\n",
      "\n",
      "New Batch Arrived!\n",
      "Average characters per Tweet in this batch: 143.54\n",
      "Shortest Tweet in this batch: 44 characters\n",
      "Longest Tweet in this batch: 255 characters\n",
      "\n",
      "New Batch Arrived!\n",
      "Average characters per Tweet in this batch: 140.12\n",
      "Shortest Tweet in this batch: 47 characters\n",
      "Longest Tweet in this batch: 227 characters\n",
      "\n",
      "New Batch Arrived!\n",
      "Average characters per Tweet in this batch: 143.12\n",
      "Shortest Tweet in this batch: 40 characters\n",
      "Longest Tweet in this batch: 238 characters\n",
      "\n",
      "New Batch Arrived!\n",
      "Average characters per Tweet in this batch: 134.44\n",
      "Shortest Tweet in this batch: 3 characters\n",
      "Longest Tweet in this batch: 240 characters\n",
      "\n",
      "New Batch Arrived!\n",
      "Average characters per Tweet in this batch: 137.0\n",
      "Shortest Tweet in this batch: 38 characters\n",
      "Longest Tweet in this batch: 213 characters\n",
      "\n",
      "All Batches Processed! Run Again for More Data\n"
     ]
    }
   ],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark.streaming import StreamingContext\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# Initialize SparkContext and StreamingContext\n",
    "sc = SparkContext(\"local[2]\", \"RandomDataStream\")\n",
    "ssc = StreamingContext(sc, 1)  # Batch interval of 1 second\n",
    "\n",
    "def generate_data():\n",
    "    return [int(np.random.normal(140, 40)) for _ in range(100)]  # Generate 100 random numbers to represent Tweet lengths in characters\n",
    "\n",
    "def process_data(data):\n",
    "    if data.isEmpty():\n",
    "        print(\"All Batches Processed! Run Again for More Data\")\n",
    "        ssc.stop(stopSparkContext=True, stopGraceFully=True)\n",
    "    else:\n",
    "\n",
    "        # Calculate mean\n",
    "        count = data.count()\n",
    "        sum_of_data = data.reduce(lambda x, y: x + y)\n",
    "        mean = sum_of_data / count\n",
    "        print(\"New Batch Arrived!\")\n",
    "        print(\"Average characters per Tweet in this batch:\", mean)\n",
    "\n",
    "        # Calculate min and max\n",
    "        min_val = data.min()\n",
    "        max_val = data.max()\n",
    "        print(f\"Shortest Tweet in this batch: {min_val} characters\")\n",
    "        print(f\"Longest Tweet in this batch: {max_val} characters\\n\")\n",
    "\n",
    "# Create a DStream from generate_data\n",
    "stream = ssc.queueStream([sc.parallelize(generate_data()) for _ in range(10)])\n",
    "\n",
    "# Process the stream\n",
    "stream.foreachRDD(process_data)\n",
    "\n",
    "# Start the streaming context\n",
    "print(\"Starting Spark Streaming context...\")\n",
    "ssc.start()\n",
    "\n",
    "# Wait for the termination of the streaming context\n",
    "print(\"Awaiting termination...\")\n",
    "ssc.awaitTermination()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
