{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import as:\n",
    "\n",
    "import core.plotting as plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import calendar\n",
    "import logging\n",
    "import math\n",
    "from typing import Any, Dict, List, Optional, Tuple, Union\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as mpl_col\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import seaborn as sns\n",
    "import sklearn.decomposition as skldec\n",
    "import sklearn.metrics as sklmet\n",
    "import sklearn.utils.validation as skluv\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.regression.rolling as smrr\n",
    "\n",
    "import core.explore as expl\n",
    "import core.finance as fin\n",
    "import core.signal_processing as sigp\n",
    "import core.statistics as stats\n",
    "import helpers.dataframe as hdf\n",
    "import helpers.dbg as dbg\n",
    "import helpers.list as hlist\n",
    "\n",
    "_LOG = logging.getLogger(__name__)\n",
    "\n",
    "_RETURNS_DICT_TYPE = Dict[str, Dict[int, pd.Series]]\n",
    "\n",
    "_PCA_TYPE = Union[skldec.PCA, skldec.IncrementalPCA]\n",
    "\n",
    "FIG_SIZE = (20, 5)\n",
    "\n",
    "_DATETIME_TYPES = [\n",
    "    \"year\",\n",
    "    \"month\",\n",
    "    \"quarter\",\n",
    "    \"weekofyear\",\n",
    "    \"dayofweek\",\n",
    "    \"hour\",\n",
    "    \"minute\",\n",
    "    \"second\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "General plotting helpers\n",
    "#############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_non_na_cols(\n",
    "    df: pd.core.frame.DataFrame,\n",
    "    sort: bool = False,\n",
    "    ascending: bool = True,\n",
    "    max_num: Optional[int] = None,\n",
    ") -> Any:\n",
    "    \"\"\"Plot a diagram describing the non-nans intervals for the columns of df.\n",
    "\n",
    "    :param df: usual df indexed with times\n",
    "    :param sort: sort the columns by number of non-nans\n",
    "    :param ascending:\n",
    "    :param max_num: max number of columns to plot\n",
    "    \"\"\"\n",
    "    # Check that there are no repeated columns.\n",
    "    # TODO(gp): dassert_no_duplicates\n",
    "    dbg.dassert_eq(len(hlist.find_duplicates(df.columns.tolist())), 0)\n",
    "    # Note that the plot assumes that the first column is at the bottom of the\n",
    "    # Assign 1.0 to all the non-nan value.\n",
    "    df = df.where(df.isnull(), 1)\n",
    "    # Sort.\n",
    "    if sort:\n",
    "        cnt = df.sum().sort_values(ascending=not ascending)\n",
    "        df = df.reindex(cnt.index.tolist(), axis=1)\n",
    "    _LOG.debug(\"Columns=%d %s\", len(df.columns), \", \".join(df.columns))\n",
    "    # Limit the number of elements.\n",
    "    if max_num is not None:\n",
    "        _LOG.warning(\n",
    "            \"Plotting only %d columns instead of all %d columns\",\n",
    "            max_num,\n",
    "            df.shape[1],\n",
    "        )\n",
    "        dbg.dassert_lte(1, max_num)\n",
    "        if max_num > df.shape[1]:\n",
    "            _LOG.warning(\n",
    "                \"Too many columns requested: %d > %d\", max_num, df.shape[1]\n",
    "            )\n",
    "        df = df.iloc[:, :max_num]\n",
    "    _LOG.debug(\"Columns=%d %s\", len(df.columns), \", \".join(df.columns))\n",
    "    _LOG.debug(\"To plot=\\n%s\", df.head())\n",
    "    # Associate each column to a number between 1 and num_cols + 1.\n",
    "    scale = pd.Series({col: idx + 1 for idx, col in enumerate(df.columns)})\n",
    "    df *= scale\n",
    "    num_cols = df.shape[1]\n",
    "    # Heuristics to find the value of ysize.\n",
    "    figsize = None\n",
    "    ysize = num_cols * 0.3\n",
    "    figsize = (20, ysize)\n",
    "    ax = df.plot(figsize=figsize, legend=False)\n",
    "    # Force all the yticks to be equal to the column names and to be visible.\n",
    "    ax.set_yticks(np.arange(num_cols, 0, -1))\n",
    "    ax.set_yticklabels(reversed(df.columns.tolist()))\n",
    "    return ax\n",
    "\n",
    "\n",
    "def plot_categories_count(\n",
    "    df: pd.core.frame.DataFrame,\n",
    "    category_column: str,\n",
    "    figsize: Optional[Tuple[int, int]] = None,\n",
    "    title: Optional[str] = None,\n",
    "    label: Optional[str] = None,\n",
    ") -> None:\n",
    "    \"\"\"Plot countplot of a given `category_column`.\n",
    "\n",
    "    :param df: df to plot\n",
    "    :param category_column: categorical column to subset plots by\n",
    "    :param figsize: if nothing specified, basic (20,5) used\n",
    "    :param title: title for the plot\n",
    "    \"\"\"\n",
    "    if not figsize:\n",
    "        figsize = FIG_SIZE\n",
    "    if not label:\n",
    "        label = category_column\n",
    "    num_categories = df[category_column].nunique()\n",
    "    if num_categories > 10:\n",
    "        ylen = math.ceil(num_categories / 26) * 5\n",
    "        figsize = (figsize[0], ylen)\n",
    "        plt.figure(figsize=figsize)\n",
    "        ax = sns.countplot(\n",
    "            y=df[category_column], order=df[category_column].value_counts().index\n",
    "        )\n",
    "        ax.set(xlabel=f\"Number of {label}s\")\n",
    "        ax.set(ylabel=category_column.lower())\n",
    "        for p in ax.patches:\n",
    "            ax.text(\n",
    "                p.get_width() + 0.1,\n",
    "                p.get_y() + 0.5,\n",
    "                str(round((p.get_width()), 2)),\n",
    "            )\n",
    "    else:\n",
    "        plt.figure(figsize=figsize)\n",
    "        ax = sns.countplot(\n",
    "            x=df[category_column], order=df[category_column].value_counts().index\n",
    "        )\n",
    "        ax.set(xlabel=category_column.lower())\n",
    "        ax.set(ylabel=f\"Number of {label}s\")\n",
    "        for p in ax.patches:\n",
    "            ax.annotate(p.get_height(), (p.get_x() + 0.35, p.get_height() + 1))\n",
    "    if not title:\n",
    "        plt.title(f\"Distribution by {category_column}\")\n",
    "    else:\n",
    "        plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def get_multiple_plots(\n",
    "    num_plots: int,\n",
    "    num_cols: int,\n",
    "    y_scale: Optional[float] = None,\n",
    "    *args: Any,\n",
    "    **kwargs: Any,\n",
    ") -> Tuple[mpl.figure.Figure, np.array]:\n",
    "    \"\"\"Create figure to accommodate `num_plots` plots. The figure is arranged\n",
    "    in rows with `num_cols` columns.\n",
    "\n",
    "    :param num_plots: number of plots\n",
    "    :param num_cols: number of columns to use in the subplot\n",
    "    :param y_scale: if not None\n",
    "    :return: figure and array of axes\n",
    "    \"\"\"\n",
    "    dbg.dassert_lte(1, num_plots)\n",
    "    dbg.dassert_lte(1, num_cols)\n",
    "    # Heuristic to find the dimension of the fig.\n",
    "    if y_scale is not None:\n",
    "        dbg.dassert_lt(0, y_scale)\n",
    "        ysize = math.ceil(num_plots / num_cols) * y_scale\n",
    "        figsize: Optional[Tuple[float, float]] = (20, ysize)\n",
    "    else:\n",
    "        figsize = None\n",
    "    fig, ax = plt.subplots(\n",
    "        math.ceil(num_plots / num_cols),\n",
    "        num_cols,\n",
    "        figsize=figsize,\n",
    "        *args,\n",
    "        **kwargs,\n",
    "    )\n",
    "    if isinstance(ax, np.ndarray):\n",
    "        return fig, ax.flatten()\n",
    "    return fig, ax\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data count plots.\n",
    "#############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_value_counts(\n",
    "    srs: pd.Series, dropna: bool = True, *args: Any, **kwargs: Any\n",
    ") -> None:\n",
    "    \"\"\"Plot barplots for the counts of a series and print the values.\n",
    "\n",
    "    Same interface as plot_count_series() but computing the count of the\n",
    "    given series `srs`.\n",
    "    \"\"\"\n",
    "    # Compute the counts.\n",
    "    counts = srs.value_counts(dropna=dropna)\n",
    "    # Plot.\n",
    "    return plot_counts(counts, *args, **kwargs)\n",
    "\n",
    "\n",
    "def plot_counts(\n",
    "    counts: pd.Series,\n",
    "    top_n_to_print: int = 10,\n",
    "    top_n_to_plot: Optional[int] = None,\n",
    "    plot_title: Optional[str] = None,\n",
    "    label: Optional[str] = None,\n",
    "    figsize: Optional[Tuple[int, int]] = None,\n",
    "    rotation: int = 0,\n",
    ") -> None:\n",
    "    \"\"\"Plot barplots for series containing counts and print the values.\n",
    "\n",
    "    If the number of labels is over 20, the plot is oriented horizontally\n",
    "    and the height of the plot is automatically adjusted.\n",
    "\n",
    "    :param counts: series to plot value counts for\n",
    "    :param top_n_to_print: top N values by count to print. None for all. 0 for\n",
    "        no values\n",
    "    :param top_n_to_plot: like top_n_to_print, but for the plot\n",
    "    :param plot_title: title of the barplot\n",
    "    :param label: label of the X axis\n",
    "    :param figsize: size of the plot\n",
    "    :param rotation: rotation of xtick labels\n",
    "    \"\"\"\n",
    "    # Get default values for plot title and label.\n",
    "    if not figsize:\n",
    "        figsize = FIG_SIZE\n",
    "    # Display a number of unique values in Ñolumn.\n",
    "    print(\"Number of unique values: %d\" % counts.index.nunique())\n",
    "    if top_n_to_print == 0:\n",
    "        # Do not show anything.\n",
    "        pass\n",
    "    else:\n",
    "        counts_tmp = counts.copy()\n",
    "        counts.sort_values(ascending=False, inplace=True)\n",
    "        if top_n_to_print is not None:\n",
    "            dbg.dassert_lte(1, top_n_to_print)\n",
    "            counts_tmp = counts_tmp[:top_n_to_print]\n",
    "            print(\"Up to first %d unique labels:\" % top_n_to_print)\n",
    "        else:\n",
    "            print(\"All unique labels:\")\n",
    "        print(counts_tmp)\n",
    "    # Plot horizontally or vertically, depending on counts number.\n",
    "    if top_n_to_plot == 0:\n",
    "        # Do not show anything.\n",
    "        pass\n",
    "    else:\n",
    "        counts_tmp = counts.copy()\n",
    "        # Subset N values to plot.\n",
    "        if top_n_to_plot is not None:\n",
    "            dbg.dassert_lte(1, top_n_to_plot)\n",
    "            counts_tmp = counts_tmp[:top_n_to_plot]\n",
    "        if len(counts_tmp) > 20:\n",
    "            # Plot large number of categories horizontally.\n",
    "            counts_tmp.sort_values(ascending=True, inplace=True)\n",
    "            ylen = math.ceil(len(counts_tmp) / 26) * 5\n",
    "            figsize = (figsize[0], ylen)\n",
    "            plot_barplot(\n",
    "                counts_tmp,\n",
    "                orientation=\"horizontal\",\n",
    "                title=plot_title,\n",
    "                figsize=figsize,\n",
    "                xlabel=label,\n",
    "                rotation=rotation,\n",
    "            )\n",
    "        else:\n",
    "            # Plot small number of categories vertically.\n",
    "            plot_barplot(\n",
    "                counts_tmp,\n",
    "                orientation=\"vertical\",\n",
    "                title=plot_title,\n",
    "                figsize=figsize,\n",
    "                xlabel=label,\n",
    "                rotation=rotation,\n",
    "            )\n",
    "\n",
    "\n",
    "def plot_barplot(\n",
    "    srs: pd.Series,\n",
    "    orientation: str = \"vertical\",\n",
    "    annotation_mode: str = \"pct\",\n",
    "    string_format: str = \"%.2f\",\n",
    "    top_n_to_plot: Optional[int] = None,\n",
    "    title: Optional[str] = None,\n",
    "    xlabel: Optional[str] = None,\n",
    "    unicolor: bool = False,\n",
    "    color_palette: Optional[List[Tuple[float, float, float]]] = None,\n",
    "    figsize: Optional[Tuple[int, int]] = None,\n",
    "    rotation: int = 0,\n",
    "    ax: Optional[mpl.axes.Axes] = None,\n",
    ") -> None:\n",
    "    \"\"\"Plot a barplot.\n",
    "\n",
    "    :param srs: pd.Series\n",
    "    :param orientation: vertical or horizontal bars\n",
    "    :param annotation_mode: `pct`, `value` or None\n",
    "    :param string_format: format of bar annotations\n",
    "    :param top_n_to_plot: number of top N integers to plot\n",
    "    :param title: title of the plot\n",
    "    :param xlabel: label of the X axis\n",
    "    :param unicolor: if True, plot all bars in neutral blue color\n",
    "    :param color_palette: color palette\n",
    "    :param figsize: size of plot\n",
    "    :param rotation: rotation of xtick labels\n",
    "    :param ax: axes\n",
    "    \"\"\"\n",
    "\n",
    "    def _get_annotation_loc(\n",
    "        x_: float, y_: float, height_: float, width_: float\n",
    "    ) -> Tuple[float, float]:\n",
    "        if orientation == \"vertical\":\n",
    "            return x_, y_ + max(height_, 0)\n",
    "        if orientation == \"horizontal\":\n",
    "            return x_ + max(width_, 0), y_\n",
    "        raise ValueError(\"Invalid orientation='%s'\" % orientation)\n",
    "\n",
    "    # Get default figure size.\n",
    "    if figsize is None:\n",
    "        figsize = FIG_SIZE\n",
    "    if top_n_to_plot is None:\n",
    "        # If top_n not specified, plot all values.\n",
    "        srs_top_n = srs\n",
    "    else:\n",
    "        # Assert N>0.\n",
    "        dbg.dassert_lte(1, top_n_to_plot)\n",
    "        # Sort in descending order.\n",
    "        srs_sorted = srs.sort_values(ascending=False)\n",
    "        # Select top N.\n",
    "        srs_top_n = srs_sorted[:top_n_to_plot]\n",
    "    # Choose colors.\n",
    "    if unicolor:\n",
    "        color = sns.color_palette(\"muted\")[0]\n",
    "    else:\n",
    "        color_palette = color_palette or sns.diverging_palette(10, 133, n=2)\n",
    "        color = (srs > 0).map({True: color_palette[-1], False: color_palette[0]})\n",
    "    # Choose orientation.\n",
    "    if orientation == \"vertical\":\n",
    "        kind = \"bar\"\n",
    "    elif orientation == \"horizontal\":\n",
    "        kind = \"barh\"\n",
    "    else:\n",
    "        raise ValueError(\"Invalid orientation='%s'\" % orientation)\n",
    "    ax = ax or plt.gca()\n",
    "    # Plot top N.\n",
    "    srs_top_n.plot(\n",
    "        kind=kind, color=color, rot=rotation, title=title, ax=ax, figsize=figsize\n",
    "    )\n",
    "    # Add annotations to bars.\n",
    "    # Note: annotations in both modes are taken from\n",
    "    # entire series, not top N.\n",
    "    if annotation_mode:\n",
    "        if annotation_mode == \"pct\":\n",
    "            annotations = srs * 100 / srs.sum()\n",
    "            string_format = string_format + \"%%\"\n",
    "            annotations = annotations.apply(lambda z: string_format % z)\n",
    "        elif annotation_mode == \"value\":\n",
    "            annotations = srs.apply(lambda z: string_format % z)\n",
    "        else:\n",
    "            raise ValueError(\"Invalid annotations_mode='%s'\" % annotation_mode)\n",
    "        # Annotate bars.\n",
    "        for i, p in enumerate(ax.patches):\n",
    "            height = p.get_height()\n",
    "            width = p.get_width()\n",
    "            x, y = p.get_xy()\n",
    "            annotation_loc = _get_annotation_loc(x, y, height, width)\n",
    "            ax.annotate(annotations.iloc[i], annotation_loc)\n",
    "    # Set X-axis label.\n",
    "    if xlabel:\n",
    "        ax.set(xlabel=xlabel)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time series plotting\n",
    "#############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_timeseries_distribution(\n",
    "    srs: pd.Series,\n",
    "    datetime_types: Optional[List[str]] = None,\n",
    ") -> None:\n",
    "    \"\"\"Plot timeseries distribution by.\n",
    "\n",
    "    - \"year\",\n",
    "    - \"month\",\n",
    "    - \"quarter\",\n",
    "    - \"weekofyear\",\n",
    "    - \"dayofweek\",\n",
    "    - \"hour\",\n",
    "    - \"second\"\n",
    "    unless otherwise provided by `datetime_types`.\n",
    "\n",
    "    :param srs: timeseries pd.Series to plot\n",
    "    :param datetime_types: types of pd.datetime, e.g. \"month\", \"quarter\"\n",
    "    \"\"\"\n",
    "    dbg.dassert_isinstance(srs, pd.Series)\n",
    "    dbg.dassert_isinstance(srs.index, pd.DatetimeIndex)\n",
    "    srs = hdf.apply_nan_mode(srs, mode=\"drop\")\n",
    "    index_series = pd.Series(srs.index)\n",
    "    if datetime_types is None:\n",
    "        datetime_types = _DATETIME_TYPES\n",
    "    for datetime_type in datetime_types:\n",
    "        plt.figure(figsize=FIG_SIZE)\n",
    "        sns.countplot(getattr(index_series.dt, datetime_type))\n",
    "        plt.title(f\"Distribution by {datetime_type}\")\n",
    "        plt.xlabel(datetime_type, fontsize=12)\n",
    "        plt.ylabel(f\"Quantity of {srs.name}\", fontsize=12)\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "def plot_timeseries_per_category(\n",
    "    df: pd.core.frame.DataFrame,\n",
    "    datetime_types: Optional[List[\"str\"]],\n",
    "    column: str,\n",
    "    ts_column: str,\n",
    "    category_column: str,\n",
    "    categories: Optional[List[str]] = None,\n",
    "    top_n: Optional[int] = None,\n",
    "    figsize: Optional[Tuple[int, int]] = None,\n",
    ") -> None:\n",
    "    \"\"\"Plot distribution (where `datetime_types` has the same meaning as in\n",
    "    plot_headlines) for a given list of categories.\n",
    "\n",
    "    If `categories` param is not specified, `top_n` must be specified and plots\n",
    "    will show the `top_n` most popular categories.\n",
    "    :param df: df to plot\n",
    "    :param datetime_types: types of pd.datetime, e.g. \"month\", \"quarter\"\n",
    "    :param column: distribution of which variable to represent\n",
    "    :param ts_column: timeseries column\n",
    "    :param category_column: categorical column to subset plots by\n",
    "    :param categories: categories to represent\n",
    "    :param top_n: number of top categories to use, if categories are not specified\n",
    "    \"\"\"\n",
    "    if not figsize:\n",
    "        figsize = FIG_SIZE\n",
    "    unique_rows = expl.drop_duplicates(df=df, subset=[column])\n",
    "    if top_n:\n",
    "        categories = (\n",
    "            df[category_column].value_counts().iloc[:top_n].index.to_list()\n",
    "        )\n",
    "    dbg.dassert(categories, \"No categories found.\")\n",
    "    if not datetime_types:\n",
    "        datetime_types = _DATETIME_TYPES\n",
    "    for datetime_type in datetime_types:\n",
    "        rows = math.ceil(len(categories) / 3)\n",
    "        fig, ax = plt.subplots(\n",
    "            figsize=(FIG_SIZE[0], rows * 4.5),\n",
    "            ncols=3,\n",
    "            nrows=rows,\n",
    "            constrained_layout=True,\n",
    "        )\n",
    "        ax = ax.flatten()\n",
    "        a = iter(ax)\n",
    "        for category in categories:\n",
    "            j = next(a)\n",
    "            # Prepare a subset of data for the current category only.\n",
    "            rows_by_category = unique_rows.loc[\n",
    "                unique_rows[categories] == category, :\n",
    "            ]\n",
    "            sns.countplot(\n",
    "                getattr(rows_by_category[ts_column].dt, datetime_type), ax=j\n",
    "            )\n",
    "            j.set_ylabel(f\"Quantity of {column}\")\n",
    "            j.set_xlabel(datetime_type)\n",
    "            j.set_xticklabels(j.get_xticklabels(), rotation=45)\n",
    "            j.set_title(category)\n",
    "        fig.suptitle(f\"Distribution by {datetime_type}\")\n",
    "\n",
    "\n",
    "# TODO(*): Rename. Maybe `plot_sequence_and_density()`.\n",
    "def plot_cols(\n",
    "    data: Union[pd.Series, pd.DataFrame],\n",
    "    colormap: str = \"rainbow\",\n",
    "    mode: Optional[str] = None,\n",
    "    axes: Optional[List[mpl.axes.Axes]] = None,\n",
    "    figsize: Optional[Tuple[float, float]] = (20, 10),\n",
    ") -> None:\n",
    "    \"\"\"Plot lineplot and density plot for the given dataframe.\n",
    "\n",
    "    :param data: data to plot\n",
    "    :param colormap: preferred colors\n",
    "    :param mode: \"renormalize\" or \"default\"\n",
    "    :param axes: pair of axes for plot over time and density plot\n",
    "    :param figsize: matplotlib figsize. Default is `(20, 10)`. If `None`, uses\n",
    "        notebook default parameters\n",
    "    \"\"\"\n",
    "    if isinstance(data, pd.Series):\n",
    "        data = data.to_frame()\n",
    "    if axes is None:\n",
    "        _, axes = plt.subplots(2, ncols=1, figsize=figsize)\n",
    "    if mode is None or mode == \"default\":\n",
    "        pass\n",
    "    elif mode == \"renormalize\":\n",
    "        data = data.copy()\n",
    "        data /= data.std()\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported mode `{mode}`\")\n",
    "    data.replace([np.inf, -np.inf], np.nan).plot(\n",
    "        kind=\"density\", colormap=colormap, ax=axes[0]\n",
    "    )\n",
    "    data.plot(colormap=colormap, ax=axes[1])\n",
    "\n",
    "\n",
    "# TODO(*): Check that data index size exceeds lags.\n",
    "def plot_autocorrelation(\n",
    "    signal: Union[pd.Series, pd.DataFrame],\n",
    "    lags: int = 40,\n",
    "    zero: bool = False,\n",
    "    nan_mode: str = \"conservative\",\n",
    "    fft: bool = True,\n",
    "    title_prefix: Optional[str] = None,\n",
    "    axes: Optional[List[mpl.axes.Axes]] = None,\n",
    "    **kwargs: Any,\n",
    ") -> None:\n",
    "    \"\"\"Plot ACF and PACF of columns.\n",
    "\n",
    "    https://www.statsmodels.org/stable/_modules/statsmodels/graphics/tsaplots.html#plot_acf\n",
    "    https://www.statsmodels.org/stable/_modules/statsmodels/tsa/stattools.html#acf\n",
    "    \"\"\"\n",
    "    if axes is None:\n",
    "        axes = [[None, None]]\n",
    "    if isinstance(signal, pd.Series):\n",
    "        signal = signal.to_frame()\n",
    "    nrows = len(signal.columns)\n",
    "    if axes == [[None, None]]:\n",
    "        _, axes = plt.subplots(nrows=nrows, ncols=2, figsize=(20, 5 * nrows))\n",
    "        if axes.size == 2:\n",
    "            axes = [axes]\n",
    "    if title_prefix is None:\n",
    "        title_prefix = \"\"\n",
    "    for idx, col in enumerate(signal.columns):\n",
    "        if nan_mode == \"conservative\":\n",
    "            data = signal[col].fillna(0).dropna()\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported nan_mode `{nan_mode}`\")\n",
    "        ax1 = axes[idx][0]\n",
    "        # Exclude lag zero so that the y-axis does not get squashed.\n",
    "        acf_title = title_prefix + f\"{col} autocorrelation\"\n",
    "        _ = sm.graphics.tsa.plot_acf(\n",
    "            data, lags=lags, fft=fft, ax=ax1, zero=zero, title=acf_title, **kwargs\n",
    "        )\n",
    "        ax2 = axes[idx][1]\n",
    "        pacf_title = title_prefix + f\"{col} partial autocorrelation\"\n",
    "        _ = sm.graphics.tsa.plot_pacf(\n",
    "            data,\n",
    "            lags=lags,\n",
    "            ax=ax2,\n",
    "            zero=zero,\n",
    "            title=pacf_title,\n",
    "            **kwargs,\n",
    "        )\n",
    "\n",
    "\n",
    "def plot_spectrum(\n",
    "    signal: Union[pd.Series, pd.DataFrame],\n",
    "    nan_mode: str = \"conservative\",\n",
    "    title_prefix: Optional[str] = None,\n",
    "    axes: Optional[List[mpl.axes.Axes]] = None,\n",
    ") -> None:\n",
    "    \"\"\"Plot power spectral density and spectrogram of columns.\n",
    "\n",
    "    PSD:\n",
    "      - Estimate the power spectral density using Welch's method.\n",
    "      - Related to autocorrelation via the Fourier transform (Wiener-Khinchin).\n",
    "    Spectrogram:\n",
    "      - From the scipy documentation of spectrogram:\n",
    "        \"Spectrograms can be used as a way of visualizing the change of a\n",
    "         nonstationary signal's frequency content over time.\"\n",
    "    \"\"\"\n",
    "    if axes is None:\n",
    "        axes = [[None, None]]\n",
    "    if isinstance(signal, pd.Series):\n",
    "        signal = signal.to_frame()\n",
    "    if title_prefix is None:\n",
    "        title_prefix = \"\"\n",
    "    nrows = len(signal.columns)\n",
    "    if axes == [[None, None]]:\n",
    "        _, axes = plt.subplots(nrows=nrows, ncols=2, figsize=(20, 5 * nrows))\n",
    "        if axes.size == 2:\n",
    "            axes = [axes]\n",
    "    for idx, col in enumerate(signal.columns):\n",
    "        if nan_mode == \"conservative\":\n",
    "            data = signal[col].fillna(0).dropna()\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported nan_mode `{nan_mode}`\")\n",
    "        ax1 = axes[idx][0]\n",
    "        f_pxx, Pxx = sp.signal.welch(data)\n",
    "        ax1.semilogy(f_pxx, Pxx)\n",
    "        ax1.set_title(title_prefix + f\"{col} power spectral density\")\n",
    "        # TODO(*): Maybe put labels on a shared axis.\n",
    "        # ax1.set_xlabel(\"Frequency\")\n",
    "        # ax1.set_ylabel(\"Power\")\n",
    "        ax2 = axes[idx][1]\n",
    "        f_sxx, t, Sxx = sp.signal.spectrogram(data)\n",
    "        ax2.pcolormesh(t, f_sxx, Sxx)\n",
    "        ax2.set_title(title_prefix + f\"{col} spectrogram\")\n",
    "        # ax2.set_ylabel(\"Frequency band\")\n",
    "        # ax2.set_xlabel(\"Time window\")\n",
    "\n",
    "\n",
    "def plot_time_series_dict(\n",
    "    dict_: Dict[str, pd.Series],\n",
    "    num_plots: Optional[int] = None,\n",
    "    num_cols: Optional[int] = 2,\n",
    "    y_scale: Optional[float] = 4,\n",
    "    sharex: bool = True,\n",
    "    sharey: bool = False,\n",
    "    exclude_empty: bool = True,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Plot series from a dict of series.\n",
    "\n",
    "    :param dict_: dict of series\n",
    "    :param num_plots: number of plots\n",
    "    :param num_cols: number of columns to use in the subplot\n",
    "    :param y_scale: scale of y-axis\n",
    "    :param sharex: unify x-axis if True\n",
    "    :param sharey: unify y-axis if True\n",
    "    :param exclude_empty: whether to exclude plots of empty series\n",
    "    \"\"\"\n",
    "    if exclude_empty:\n",
    "        non_empty_dict_ = {\n",
    "            key: val for key, val in dict_.items() if not val.empty\n",
    "        }\n",
    "        if len(non_empty_dict_) < len(dict_):\n",
    "            excluded_series = set(dict_).difference(non_empty_dict_)\n",
    "            _LOG.warning(\"Excluded empty series: %s\", excluded_series)\n",
    "        dict_ = non_empty_dict_\n",
    "    num_plots = num_plots or len(dict_)\n",
    "    # Create figure to accommodate plots.\n",
    "    _, axes = get_multiple_plots(\n",
    "        num_plots=num_plots,\n",
    "        num_cols=num_cols,\n",
    "        y_scale=y_scale,\n",
    "        sharex=sharex,\n",
    "        sharey=sharey,\n",
    "    )\n",
    "    # Select first `num_plots` series in the dict and plot them.\n",
    "    keys_to_draw = list(dict_.keys())[:num_plots]\n",
    "    for i, key in enumerate(keys_to_draw):\n",
    "        srs = dict_[key]\n",
    "        srs.to_frame().plot(title=key, ax=axes[i])\n",
    "\n",
    "        \n",
    "def plot_histograms_and_lagged_scatterplot(\n",
    "    srs: pd.Series,\n",
    "    lag: int,\n",
    "    title = None,\n",
    "    figsize: Optional[Tuple] = None,\n",
    "    hist_kwargs: Optional[Any] = None,\n",
    "    scatter_kwargs: Optional[Any] = None,\n",
    ") -> None:\n",
    "    \"\"\"Plot histograms and scatterplot to test stationarity visually.\n",
    "\n",
    "    Function plots histograms with density plot for 1st and 2nd half of the time\n",
    "    series (if the timeseries is stationary, the histogram of the 1st half of \n",
    "    the timeseries would be similar to the histogram of the 2nd half) and \n",
    "    scatter-plot of time series observations versus their lagged values (x_t \n",
    "    versus x_{t - lag}, where lag > 0). If it is stationary the scatter-plot \n",
    "    with its lagged values would resemble a circular cloud.\n",
    "    \"\"\"\n",
    "    hist_kwargs = hist_kwargs or {}\n",
    "    scatter_kwargs = scatter_kwargs or {}\n",
    "    # Sort index if it is not sorted yet.\n",
    "    srs = srs.sort_index()\n",
    "    # Divide timeseries to two parts.\n",
    "    srs_first_half = srs.iloc[: len(srs) // 2]\n",
    "    srs_second_half = srs.iloc[len(srs) // 2 :]\n",
    "    # Plot histograms.\n",
    "    fig, axes = plt.subplots(nrows=2, ncols=2, figsize=figsize)\n",
    "    plt.suptitle(title or srs.name)\n",
    "    sns.histplot(srs_first_half, ax=axes[0][0], kde=True, **hist_kwargs)\n",
    "    axes[0][0].set(\n",
    "        xlabel=None, \n",
    "        ylabel=None, \n",
    "        title=\"1st half-sample distribution\"\n",
    "    )\n",
    "    sns.histplot(srs_second_half, ax=axes[0][1], kde=True, **hist_kwargs)\n",
    "    axes[0][1].set(\n",
    "        xlabel=None, \n",
    "        ylabel=None, \n",
    "        title=\"2nd half-sample distribution\"\n",
    "    )\n",
    "    # Plot scatter plot.\n",
    "    fig.subplots_adjust(hspace=0.25)\n",
    "    axes[1][0].scatter(srs, srs.shift(lag), **scatter_kwargs)\n",
    "    axes[1][0].set_title(\"scatter-plot with lag={}\".format(lag))\n",
    "    fig.delaxes(axes[1][1])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlation-type plots\n",
    "#############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_heatmap(\n",
    "    corr_df: pd.core.frame.DataFrame,\n",
    "    mode: Optional[str] = None,\n",
    "    annot: Union[bool, str] = \"auto\",\n",
    "    figsize: Optional[Tuple[int, int]] = None,\n",
    "    title: Optional[str] = None,\n",
    "    vmin: float = -1.0,\n",
    "    vmax: float = 1.0,\n",
    "    ax: Optional[plt.axes] = None,\n",
    ") -> None:\n",
    "    \"\"\"Plot a heatmap for a corr / cov df.\n",
    "\n",
    "    :param corr_df: df to plot a heatmap\n",
    "    :param mode: \"heatmap_semitriangle\", \"heatmap\" or \"clustermap\"\n",
    "    :param annot: determines whether to use annotations\n",
    "    :param figsize: if nothing specified, basic (20,5) used\n",
    "    :param title: title for the plot\n",
    "    :param vmin: minimum value to anchor the colormap\n",
    "    :param vmax: maximum value to anchor the colormap\n",
    "    :param ax: axes in which to draw the plot\n",
    "    \"\"\"\n",
    "    # Sanity check.\n",
    "    dbg.dassert_eq(corr_df.shape[0], corr_df.shape[1])\n",
    "    if corr_df.empty:\n",
    "        _LOG.warning(\"Can't plot heatmap for empty `corr_df`\")\n",
    "        return\n",
    "    if corr_df.shape[0] > 20:\n",
    "        _LOG.warning(\"The corr_df.shape[0]='%s' > 20\", corr_df.shape[0])\n",
    "    if np.all(np.isnan(corr_df)):\n",
    "        _LOG.warning(\n",
    "            \"Can't plot heatmap with only nans:\\n%s\", corr_df.to_string()\n",
    "        )\n",
    "        return\n",
    "    #\n",
    "    if annot == \"auto\":\n",
    "        annot = corr_df.shape[0] < 10\n",
    "    # Generate a custom diverging colormap.\n",
    "    cmap = _get_heatmap_colormap()\n",
    "    if figsize is None:\n",
    "        figsize = FIG_SIZE\n",
    "    mode = mode or \"heatmap\"\n",
    "    if mode in (\"heatmap\", \"heatmap_semitriangle\"):\n",
    "        # Set up the matplotlib figure.\n",
    "        if ax is None:\n",
    "            _, ax = plt.subplots(figsize=figsize)\n",
    "        mask = _get_heatmap_mask(corr_df, mode)\n",
    "        sns.heatmap(\n",
    "            corr_df,\n",
    "            cmap=cmap,\n",
    "            vmin=vmin,\n",
    "            vmax=vmax,\n",
    "            # Use correct aspect ratio.\n",
    "            square=True,\n",
    "            annot=annot,\n",
    "            fmt=\".2f\",\n",
    "            cbar_kws={\"shrink\": 0.5},\n",
    "            mask=mask,\n",
    "            ax=ax,\n",
    "        )\n",
    "        ax.set_title(title)\n",
    "    elif mode == \"clustermap\":\n",
    "        dbg.dassert_is(ax, None)\n",
    "        g = sns.clustermap(\n",
    "            corr_df,\n",
    "            cmap=cmap,\n",
    "            vmin=vmin,\n",
    "            vmax=vmax,\n",
    "            square=True,\n",
    "            annot=annot,\n",
    "            figsize=figsize,\n",
    "        )\n",
    "        g.ax_heatmap.set_title(title)\n",
    "    else:\n",
    "        raise RuntimeError(\"Invalid mode='%s'\" % mode)\n",
    "\n",
    "\n",
    "# TODO(gp): Add an option to mask out the correlation with low pvalues\n",
    "# http://stackoverflow.com/questions/24432101/correlation-coefficients-and-p-values-for-all-pairs-of-rows-of-a-matrix\n",
    "def plot_correlation_matrix(\n",
    "    df: pd.core.frame.DataFrame,\n",
    "    mode: Optional[str] = None,\n",
    "    annot: Union[bool, str] = False,\n",
    "    figsize: Optional[Tuple[int, int]] = None,\n",
    "    title: Optional[str] = None,\n",
    "    method: Optional[str] = None,\n",
    "    min_periods: Optional[int] = None,\n",
    ") -> pd.core.frame.DataFrame:\n",
    "    \"\"\"Compute correlation matrix and plot its heatmap.\n",
    "\n",
    "    :param df: Df to compute correlation matrix and plot a heatmap\n",
    "    :param mode: \"heatmap_semitriangle\", \"heatmap\" or \"clustermap\"\n",
    "    :param annot: determines whether to use annotations\n",
    "    :param figsize: if nothing specified, basic (20,5) used\n",
    "    :param title: title for the plot\n",
    "    :param method: \"pearson\", \"kendall\", \"spearman\" or callable method of correlation\n",
    "    :param min_periods: minimum number of observations required per pair of columns to have\n",
    "        a valid result; currently only available for Pearson and Spearman correlation\n",
    "    \"\"\"\n",
    "    if df.empty:\n",
    "        _LOG.warning(\"Skipping correlation matrix since `df` is empty\")\n",
    "        return None\n",
    "    # Compute the correlation matrix.\n",
    "    method = method or \"pearson\"\n",
    "    corr_df = df.corr(method=method, min_periods=min_periods)\n",
    "    # Plot heatmap.\n",
    "    plot_heatmap(\n",
    "        corr_df,\n",
    "        mode=mode,\n",
    "        annot=annot,\n",
    "        figsize=figsize,\n",
    "        title=title,\n",
    "        vmin=-1.0,\n",
    "        vmax=1.0,\n",
    "    )\n",
    "    return corr_df\n",
    "\n",
    "\n",
    "def display_corr_df(df: pd.core.frame.DataFrame) -> None:\n",
    "    \"\"\"Display a correlation df with values with 2 decimal places.\"\"\"\n",
    "    if df is not None:\n",
    "        df_tmp = df.applymap(lambda x: \"%.2f\" % x)\n",
    "        expl.display_df(df_tmp)\n",
    "    else:\n",
    "        _LOG.warning(\"Can't display correlation df since it is None\")\n",
    "\n",
    "\n",
    "def plot_dendrogram(\n",
    "    df: pd.core.frame.DataFrame,\n",
    "    figsize: Optional[Tuple[int, int]] = None,\n",
    "    **kwargs: Any,\n",
    ") -> None:\n",
    "    \"\"\"Plot a dendrogram.\n",
    "\n",
    "    A dendrogram is a diagram representing a tree.\n",
    "\n",
    "    :param df: df to plot a heatmap\n",
    "    :param figsize: if nothing specified, basic (20,5) used\n",
    "    :param kwargs: kwargs for `sp.cluster.hierarchy.dendrogram`\n",
    "    \"\"\"\n",
    "    # Look at:\n",
    "    # ~/.conda/envs/root_longman_20150820/lib/python2.7/site-packages/seaborn/matrix.py\n",
    "    # https://joernhees.de/blog/2015/08/26/scipy-hierarchical-clustering-and-dendrogram-tutorial/\n",
    "    # Drop constant columns.\n",
    "    constant_cols = df.columns[(df.diff().iloc[1:] == 0).all()]\n",
    "    if not constant_cols.empty:\n",
    "        _LOG.warning(\"Excluding constant columns: %s\", constant_cols.tolist())\n",
    "        df = df.drop(columns=constant_cols)\n",
    "    if df.shape[1] < 2:\n",
    "        _LOG.warning(\"Skipping correlation matrix since df is %s\", str(df.shape))\n",
    "        return\n",
    "    y = df.corr().values\n",
    "    z = sp.cluster.hierarchy.linkage(y, \"average\")\n",
    "    if figsize is None:\n",
    "        figsize = FIG_SIZE\n",
    "    _ = plt.figure(figsize=figsize)\n",
    "    sp.cluster.hierarchy.dendrogram(\n",
    "        z, labels=df.columns.tolist(), orientation=\"right\", **kwargs\n",
    "    )\n",
    "\n",
    "\n",
    "def plot_corr_over_time(\n",
    "    corr_df: pd.core.frame.DataFrame,\n",
    "    mode: Optional[str] = None,\n",
    "    annot: bool = False,\n",
    "    num_cols: int = 4,\n",
    ") -> None:\n",
    "    \"\"\"Plot correlation over time.\"\"\"\n",
    "    mode = mode or \"heatmap\"\n",
    "    timestamps = corr_df.index.get_level_values(0).unique()\n",
    "    if len(timestamps) > 20:\n",
    "        _LOG.warning(\"The first level of index length='%s' > 20\", len(timestamps))\n",
    "    # Get the axes.\n",
    "    fig, axes = get_multiple_plots(\n",
    "        len(timestamps), num_cols=num_cols, y_scale=4, sharex=True, sharey=True\n",
    "    )\n",
    "    # Add color map bar on the side.\n",
    "    cbar_ax = fig.add_axes([0.91, 0.3, 0.03, 0.4])\n",
    "    cmap = _get_heatmap_colormap()\n",
    "    for i, dt in enumerate(timestamps):\n",
    "        corr_tmp = corr_df.loc[dt]\n",
    "        # Generate a mask for the upper triangle.\n",
    "        mask = _get_heatmap_mask(corr_tmp, mode)\n",
    "        # Plot.\n",
    "        sns.heatmap(\n",
    "            corr_tmp,\n",
    "            cmap=cmap,\n",
    "            cbar=i == 0,\n",
    "            cbar_ax=None if i else cbar_ax,\n",
    "            vmin=-1,\n",
    "            vmax=1,\n",
    "            square=True,\n",
    "            annot=annot,\n",
    "            fmt=\".2f\",\n",
    "            linewidths=0.5,\n",
    "            mask=mask,\n",
    "            # cbar_kws={\"shrink\": .5},\n",
    "            ax=axes[i],\n",
    "        )\n",
    "        axes[i].set_title(timestamps[i])\n",
    "\n",
    "\n",
    "class PCA:\n",
    "    def __init__(self, mode: str, **kwargs: Any):\n",
    "        if mode == \"standard\":\n",
    "            self.pca = skldec.PCA(**kwargs)\n",
    "        elif mode == \"incremental\":\n",
    "            self.pca = skldec.IncrementalPCA(**kwargs)\n",
    "        else:\n",
    "            raise ValueError(\"Invalid mode='%s'\" % mode)\n",
    "\n",
    "    def plot_components(\n",
    "        self, num_components: Optional[int] = None, num_cols: int = 4\n",
    "    ) -> None:\n",
    "        \"\"\"Plot principal components.\n",
    "\n",
    "        :param num_components: number of top components to plot\n",
    "        :param num_cols: number of columns to use in the subplot\n",
    "        \"\"\"\n",
    "        skluv.check_is_fitted(self.pca)\n",
    "        pcs = pd.DataFrame(self.pca.components_)\n",
    "        max_pcs = self.pca.components_.shape[0]\n",
    "        num_components = self._get_num_pcs_to_plot(num_components, max_pcs)\n",
    "        _LOG.info(\"num_components=%s\", num_components)\n",
    "        _, axes = get_multiple_plots(\n",
    "            num_components, num_cols=num_cols, sharex=True, sharey=True\n",
    "        )\n",
    "        plt.suptitle(\"Principal components\")\n",
    "        for i in range(num_components):\n",
    "            pc = pcs.iloc[i, :]\n",
    "            pc.plot(\n",
    "                kind=\"barh\", ax=axes[i], title=\"PC%s\" % i, edgecolor=\"tab:blue\"\n",
    "            )\n",
    "\n",
    "    def plot_explained_variance(self) -> None:\n",
    "        skluv.check_is_fitted(self.pca)\n",
    "        explained_variance_ratio = pd.Series(self.pca.explained_variance_ratio_)\n",
    "        eigenvals = pd.Series(self.pca.explained_variance_)\n",
    "        # Plot explained variance.\n",
    "        explained_variance_ratio.cumsum().plot(\n",
    "            title=\"Explained variance ratio\", lw=5, ylim=(0, 1)\n",
    "        )\n",
    "        (eigenvals / eigenvals.max()).plot(color=\"g\", kind=\"bar\", rot=0)\n",
    "\n",
    "    def fit(self, X: pd.DataFrame, standardize: bool = False) -> _PCA_TYPE:\n",
    "        if standardize:\n",
    "            X = (X - X.mean()) / X.std()\n",
    "        return self.pca.fit(X)\n",
    "\n",
    "    @staticmethod\n",
    "    def _get_num_pcs_to_plot(num_pcs_to_plot: Optional[int], max_pcs: int) -> int:\n",
    "        \"\"\"Get the number of principal components to plot.\"\"\"\n",
    "        if num_pcs_to_plot is None:\n",
    "            num_pcs_to_plot = max_pcs\n",
    "            _LOG.warning(\"Plotting all %s components\", num_pcs_to_plot)\n",
    "        dbg.dassert_lte(1, num_pcs_to_plot)\n",
    "        dbg.dassert_lte(num_pcs_to_plot, max_pcs)\n",
    "        return num_pcs_to_plot\n",
    "\n",
    "\n",
    "def _get_heatmap_mask(corr: pd.DataFrame, mode: str) -> np.ndarray:\n",
    "    if mode == \"heatmap_semitriangle\":\n",
    "        # Generate a mask for the upper triangle.\n",
    "        mask = np.zeros_like(corr, dtype=np.bool)\n",
    "        mask[np.triu_indices_from(mask)] = True\n",
    "    elif mode == \"heatmap\":\n",
    "        mask = None\n",
    "    else:\n",
    "        raise ValueError(\"Invalid mode='%s'\" % mode)\n",
    "    return mask\n",
    "\n",
    "\n",
    "def _get_heatmap_colormap() -> mpl_col.LinearSegmentedColormap:\n",
    "    \"\"\"Generate a custom diverging colormap useful for heatmaps.\"\"\"\n",
    "    cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
    "    return cmap\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eval metrics plots\n",
    "#############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_confusion_heatmap(\n",
    "    y_true: Union[List[Union[float, int]], np.array],\n",
    "    y_pred: Union[List[Union[float, int]], np.array],\n",
    "    return_results: bool = False,\n",
    ") -> Any:\n",
    "    \"\"\"Construct and plot a heatmap for a confusion matrix of fact and\n",
    "    prediction.\n",
    "\n",
    "    :param y_true: true values\n",
    "    :param y_pred: predictions\n",
    "    :param return_results: determines whether to return result dataframes\n",
    "    \"\"\"\n",
    "    confusion = sklmet.confusion_matrix(y_true, y_pred)\n",
    "    labels = set(list(y_true))\n",
    "    df_out = pd.DataFrame(confusion, index=labels, columns=labels)\n",
    "    df_out_percentage = df_out.apply(lambda x: x / x.sum(), axis=1)\n",
    "    _, (ax, ax2) = plt.subplots(figsize=(FIG_SIZE), ncols=2)\n",
    "    plot_heatmap(\n",
    "        df_out,\n",
    "        mode=\"heatmap\",\n",
    "        vmin=df_out.min().min(),\n",
    "        vmax=df_out.max().max(),\n",
    "        ax=ax,\n",
    "    )\n",
    "    plot_heatmap(\n",
    "        df_out_percentage,\n",
    "        mode=\"heatmap\",\n",
    "        vmin=df_out_percentage.min().min(),\n",
    "        vmax=df_out_percentage.max().max(),\n",
    "        ax=ax2,\n",
    "    )\n",
    "    if return_results:\n",
    "        return df_out, df_out_percentage\n",
    "    return None\n",
    "\n",
    "\n",
    "def multipletests_plot(\n",
    "    pvals: pd.Series,\n",
    "    threshold: float,\n",
    "    adj_pvals: Optional[Union[pd.Series, pd.DataFrame]] = None,\n",
    "    num_cols: Optional[int] = None,\n",
    "    method: Optional[str] = None,\n",
    "    suptitle: Optional[str] = None,\n",
    "    **kwargs: Any,\n",
    ") -> None:\n",
    "    \"\"\"Plot adjusted p-values and pass/fail threshold.\n",
    "\n",
    "    :param pvals: unadjusted p-values\n",
    "    :param threshold: threshold for adjusted p-values separating accepted and\n",
    "        rejected hypotheses, e.g., \"FWER\", or family-wise error rate\n",
    "    :param adj_pvals: adjusted p-values, if provided, will be used instead\n",
    "        calculating inside the function\n",
    "    :param num_cols: number of columns in multiplotting\n",
    "    :param method: method for performing p-value adjustment, e.g., \"fdr_bh\"\n",
    "    :param suptitle: overall title of all plots\n",
    "    \"\"\"\n",
    "    if adj_pvals is None:\n",
    "        pval_series = pvals.dropna().sort_values().reset_index(drop=True)\n",
    "        adj_pvals = stats.multipletests(pval_series, method=method).to_frame()\n",
    "    else:\n",
    "        pval_series = pvals.dropna()\n",
    "        if isinstance(adj_pvals, pd.Series):\n",
    "            adj_pvals = adj_pvals.to_frame()\n",
    "    num_cols = num_cols or 1\n",
    "    adj_pvals = adj_pvals.dropna(axis=1, how=\"all\")\n",
    "    _, ax = get_multiple_plots(\n",
    "        adj_pvals.shape[1],\n",
    "        num_cols=num_cols,\n",
    "        sharex=False,\n",
    "        sharey=True,\n",
    "        y_scale=5,\n",
    "    )\n",
    "    if not isinstance(ax, np.ndarray):\n",
    "        ax = [ax]\n",
    "    for i, col in enumerate(adj_pvals.columns):\n",
    "        mask = adj_pvals[col].notna()\n",
    "        adj_pval = adj_pvals.loc[mask, col].sort_values().reset_index(drop=True)\n",
    "        ax[i].plot(\n",
    "            pval_series.loc[mask].sort_values().reset_index(drop=True),\n",
    "            label=\"pvals\",\n",
    "            **kwargs,\n",
    "        )\n",
    "        ax[i].plot(adj_pval, label=\"adj pvals\", **kwargs)\n",
    "        # Show min adj p-val in text.\n",
    "        min_adj_pval = adj_pval.iloc[0]\n",
    "        ax[i].text(0.1, 0.7, \"adj pval=%.3f\" % min_adj_pval, fontsize=20)\n",
    "        ax[i].text(\n",
    "            0.1,\n",
    "            0.6,\n",
    "            weight=\"bold\",\n",
    "            fontsize=20,\n",
    "            **(\n",
    "                {\"s\": \"PASS\", \"color\": \"g\"}\n",
    "                if min_adj_pval <= threshold\n",
    "                else {\"s\": \"FAIL\", \"color\": \"r\"}\n",
    "            ),\n",
    "        )\n",
    "        ax[i].set_title(col)\n",
    "        ax[i].axhline(threshold, ls=\"--\", c=\"k\")\n",
    "        ax[i].set_ylim(0, 1)\n",
    "        ax[i].legend()\n",
    "    plt.suptitle(suptitle, x=0.5105, y=1.01, fontsize=15)\n",
    "    plt.tight_layout()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model evaluation\n",
    "#############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_cumulative_returns(\n",
    "    cumulative_rets: pd.Series,\n",
    "    mode: str,\n",
    "    unit: str = \"ratio\",\n",
    "    benchmark_series: Optional[pd.Series] = None,\n",
    "    title_suffix: Optional[str] = None,\n",
    "    ax: Optional[mpl.axes.Axes] = None,\n",
    "    plot_zero_line: bool = True,\n",
    "    events: Optional[List[Tuple[str, Optional[str]]]] = None,\n",
    ") -> None:\n",
    "    \"\"\"Plot cumulative returns.\n",
    "\n",
    "    :param cumulative_rets: log or pct cumulative returns\n",
    "    :param mode: log or pct, used to choose plot title\n",
    "    :param unit: \"ratio\", \"%\" or \"bps\", both input series are rescaled\n",
    "        appropriately\n",
    "    :param benchmark_series: additional series to plot\n",
    "    :param title_suffix: suffix added to the title\n",
    "    :param ax: axes\n",
    "    :param plot_zero_line: whether to plot horizontal line at 0\n",
    "    :param events: list of tuples with dates and labels to point out on the plot\n",
    "    \"\"\"\n",
    "    title_suffix = title_suffix or \"\"\n",
    "    scale_coeff = _choose_scaling_coefficient(unit)\n",
    "    cumulative_rets = cumulative_rets * scale_coeff\n",
    "    #\n",
    "    if mode == \"log\":\n",
    "        title = \"Cumulative log returns\"\n",
    "    elif mode == \"pct\":\n",
    "        title = \"Cumulative returns\"\n",
    "    else:\n",
    "        raise ValueError(\"Invalid mode='%s'\" % mode)\n",
    "    label = cumulative_rets.name or \"returns\"\n",
    "    #\n",
    "    ax = ax or plt.gca()\n",
    "    cumulative_rets.plot(ax=ax, title=f\"{title}{title_suffix}\", label=label)\n",
    "    if benchmark_series is not None:\n",
    "        benchmark_series = benchmark_series.loc[\n",
    "            cumulative_rets.index[0] : cumulative_rets.index[-1]\n",
    "        ]\n",
    "        benchmark_series = benchmark_series * scale_coeff\n",
    "        bs_label = benchmark_series.name or \"benchmark_series\"\n",
    "        benchmark_series.plot(ax=ax, label=bs_label, color=\"grey\")\n",
    "    if plot_zero_line:\n",
    "        ax.axhline(0, linestyle=\"--\", linewidth=0.8, color=\"black\")\n",
    "    _maybe_add_events(ax=ax, events=events)\n",
    "    ax.set_ylabel(unit)\n",
    "    ax.legend()\n",
    "\n",
    "\n",
    "def plot_rolling_annualized_volatility(\n",
    "    srs: pd.Series,\n",
    "    tau: float,\n",
    "    min_periods: Optional[int] = None,\n",
    "    min_depth: int = 1,\n",
    "    max_depth: int = 1,\n",
    "    p_moment: float = 2,\n",
    "    unit: str = \"ratio\",\n",
    "    trim_index: Optional[bool] = False,\n",
    "    ax: Optional[mpl.axes.Axes] = None,\n",
    "    events: Optional[List[Tuple[str, Optional[str]]]] = None,\n",
    ") -> None:\n",
    "    \"\"\"Plot rolling annualized volatility.\n",
    "\n",
    "    :param srs: input series\n",
    "    :param tau: argument as for sigp.compute_rolling_std\n",
    "    :param min_periods: argument as for sigp.compute_rolling_std\n",
    "    :param min_depth: argument as for sigp.compute_rolling_std\n",
    "    :param max_depth: argument as for sigp.compute_rolling_std\n",
    "    :param p_moment: argument as for sigp.compute_rolling_std\n",
    "    :param unit: \"ratio\", \"%\" or \"bps\" scaling coefficient\n",
    "        \"Exchange:Kibot_symbol\"\n",
    "        \"Exchange:Exchange_symbol\"\n",
    "    :param trim_index: start plot at original index if True\n",
    "    :param ax: axes\n",
    "    :param events: list of tuples with dates and labels to point out on the plot\n",
    "    \"\"\"\n",
    "    min_periods = min_periods or tau\n",
    "    srs = hdf.apply_nan_mode(srs, mode=\"fill_with_zero\")\n",
    "    # Calculate rolling volatility.\n",
    "    rolling_volatility = sigp.compute_rolling_std(\n",
    "        srs, tau, min_periods, min_depth, max_depth, p_moment\n",
    "    )\n",
    "    # Annualize rolling volatility.\n",
    "    ppy = hdf.infer_sampling_points_per_year(srs)\n",
    "    annualized_rolling_volatility = np.sqrt(ppy) * rolling_volatility\n",
    "    # Remove leading `NaNs`.\n",
    "    first_valid_index = annualized_rolling_volatility.first_valid_index()\n",
    "    annualized_rolling_volatility = annualized_rolling_volatility.loc[\n",
    "        first_valid_index:\n",
    "    ]\n",
    "    # Rescale according to desired output units.\n",
    "    scale_coeff = _choose_scaling_coefficient(unit)\n",
    "    annualized_rolling_volatility *= scale_coeff\n",
    "    # Calculate whole-period target volatility.\n",
    "    annualized_volatility = fin.compute_annualized_volatility(srs)\n",
    "    annualized_volatility *= scale_coeff\n",
    "    # Plot.\n",
    "    ax = ax or plt.gca()\n",
    "    ax.plot(\n",
    "        annualized_rolling_volatility,\n",
    "        label=\"annualized rolling volatility\",\n",
    "    )\n",
    "    ax.axhline(\n",
    "        annualized_volatility,\n",
    "        linestyle=\"--\",\n",
    "        linewidth=2,\n",
    "        color=\"green\",\n",
    "        label=\"average annualized volatility\",\n",
    "    )\n",
    "    ax.axhline(0, linewidth=0.8, color=\"black\")\n",
    "    _maybe_add_events(ax=ax, events=events)\n",
    "    ax.set_title(f\"Annualized rolling volatility ({unit})\")\n",
    "    # Start plot from original index if specified.\n",
    "    if not trim_index:\n",
    "        ax.set_xlim([min(srs.index), max(srs.index)])\n",
    "    else:\n",
    "        ax.set_xlim(\n",
    "            annualized_rolling_volatility.index[0],\n",
    "            annualized_rolling_volatility.index[-1],\n",
    "        )\n",
    "    ax.set_ylabel(unit)\n",
    "    ax.set_xlabel(\"period\")\n",
    "    ax.legend()\n",
    "\n",
    "\n",
    "def plot_rolling_annualized_sharpe_ratio(\n",
    "    srs: pd.Series,\n",
    "    tau: float,\n",
    "    min_depth: int = 1,\n",
    "    max_depth: int = 1,\n",
    "    p_moment: float = 2,\n",
    "    ci: float = 0.95,\n",
    "    title_suffix: Optional[str] = None,\n",
    "    trim_index: Optional[bool] = False,\n",
    "    ax: Optional[mpl.axes.Axes] = None,\n",
    "    events: Optional[List[Tuple[str, Optional[str]]]] = None,\n",
    ") -> None:\n",
    "    \"\"\"Plot rolling annualized Sharpe ratio.\n",
    "\n",
    "    :param srs: input series\n",
    "    :param tau: argument as for sigp.compute_smooth_moving_average\n",
    "    :param min_depth: argument as for sigp.compute_smooth_moving_average\n",
    "    :param max_depth: argument as for sigp.compute_smooth_moving_average\n",
    "    :param p_moment: argument as for sigp.compute_smooth_moving_average\n",
    "    :param ci: confidence interval\n",
    "    :param title_suffix: suffix added to the title\n",
    "    :param trim_index: start plot at original index if True\n",
    "    :param ax: axes\n",
    "    :param events: list of tuples with dates and labels to point out on the plot\n",
    "    \"\"\"\n",
    "    title_suffix = title_suffix or \"\"\n",
    "    srs = hdf.apply_nan_mode(srs, mode=\"fill_with_zero\")\n",
    "    min_periods = tau * max_depth\n",
    "    rolling_sharpe = sigp.compute_rolling_annualized_sharpe_ratio(\n",
    "        srs,\n",
    "        tau,\n",
    "        min_periods=min_periods,\n",
    "        min_depth=min_depth,\n",
    "        max_depth=max_depth,\n",
    "        p_moment=p_moment,\n",
    "    )\n",
    "    # Remove leading `NaNs`.\n",
    "    first_valid_index = rolling_sharpe.first_valid_index()\n",
    "    rolling_sharpe = rolling_sharpe.loc[first_valid_index:]\n",
    "    # Prepare for plotting SE band.\n",
    "    z = sp.stats.norm.ppf((1 - ci) / 2)\n",
    "    rolling_sharpe[\"sr-z*se\"] = (\n",
    "        rolling_sharpe[\"annualized_SR\"] + z * rolling_sharpe[\"annualized_SE(SR)\"]\n",
    "    )\n",
    "    rolling_sharpe[\"sr+z*se\"] = (\n",
    "        rolling_sharpe[\"annualized_SR\"] - z * rolling_sharpe[\"annualized_SE(SR)\"]\n",
    "    )\n",
    "    # Plot.\n",
    "    ax = rolling_sharpe[\"annualized_SR\"].plot(\n",
    "        ax=ax, title=f\"Annualized rolling Sharpe ratio{title_suffix}\", label=\"SR\"\n",
    "    )\n",
    "    ax.fill_between(\n",
    "        rolling_sharpe.index,\n",
    "        rolling_sharpe[\"sr-z*se\"],\n",
    "        rolling_sharpe[\"sr+z*se\"],\n",
    "        alpha=0.4,\n",
    "        label=f\"{100*ci:.2f}% confidence interval\",\n",
    "    )\n",
    "    mean_sharpe_ratio = (\n",
    "        rolling_sharpe[\"annualized_SR\"]\n",
    "        .replace([np.inf, -np.inf], value=np.nan)\n",
    "        .mean()\n",
    "    )\n",
    "    ax = ax or plt.gca()\n",
    "    ax.axhline(\n",
    "        mean_sharpe_ratio,\n",
    "        linestyle=\"--\",\n",
    "        linewidth=2,\n",
    "        color=\"green\",\n",
    "        label=\"average SR\",\n",
    "    )\n",
    "    ax.axhline(0, linewidth=0.8, color=\"black\", label=\"0\")\n",
    "    _maybe_add_events(ax=ax, events=events)\n",
    "    # Start plot from original index if specified.\n",
    "    if not trim_index:\n",
    "        ax.set_xlim([min(srs.index), max(srs.index)])\n",
    "    ax.set_ylabel(\"annualized SR\")\n",
    "    ax.legend()\n",
    "\n",
    "\n",
    "def plot_yearly_barplot(\n",
    "    log_rets: pd.Series,\n",
    "    unit: str = \"ratio\",\n",
    "    unicolor: bool = False,\n",
    "    orientation: str = \"vertical\",\n",
    "    figsize: Optional[Tuple[int, int]] = None,\n",
    "    ax: Optional[mpl.axes.Axes] = None,\n",
    ") -> None:\n",
    "    \"\"\"Plot a barplot of log returns statistics by year.\n",
    "\n",
    "    :param log_rets: input series of log returns\n",
    "    :param unit: \"ratio\", \"%\" or \"bps\" scaling coefficient\n",
    "    :param unicolor: if True, plot all bars in neutral blue color\n",
    "    :param orientation: vertical or horizontal bars\n",
    "    :param figsize: size of plot\n",
    "    :param ax: axes\n",
    "    \"\"\"\n",
    "    scale_coeff = _choose_scaling_coefficient(unit)\n",
    "    yearly_log_returns = log_rets.resample(\"Y\").sum()\n",
    "    yearly_pct_returns = fin.convert_log_rets_to_pct_rets(yearly_log_returns)\n",
    "    yearly_returns = yearly_pct_returns * scale_coeff\n",
    "    yearly_returns.index = yearly_returns.index.year\n",
    "    ax = ax or plt.gca()\n",
    "    plot_barplot(\n",
    "        yearly_returns,\n",
    "        annotation_mode=\"value\",\n",
    "        orientation=orientation,\n",
    "        title=f\"Annual returns ({unit})\",\n",
    "        unicolor=unicolor,\n",
    "        ax=ax,\n",
    "        figsize=figsize,\n",
    "    )\n",
    "    if orientation == \"vertical\":\n",
    "        xlabel = \"year\"\n",
    "        ylabel = unit\n",
    "    elif orientation == \"horizontal\":\n",
    "        xlabel = unit\n",
    "        ylabel = \"year\"\n",
    "    else:\n",
    "        raise ValueError(\"Invalid orientation='%s'\" % orientation)\n",
    "    ax.set_xlabel(xlabel)\n",
    "    ax.set_ylabel(ylabel)\n",
    "\n",
    "\n",
    "def plot_monthly_heatmap(\n",
    "    log_rets: pd.Series, unit: str = \"ratio\", ax: Optional[mpl.axes.Axes] = None\n",
    ") -> None:\n",
    "    \"\"\"Plot a heatmap of log returns statistics by year and month.\n",
    "\n",
    "    :param log_rets: input series of log returns\n",
    "    :param unit: \"ratio\", `%` or \"bps\" scaling coefficient\n",
    "    :param ax: axes\n",
    "    \"\"\"\n",
    "    scale_coeff = _choose_scaling_coefficient(unit)\n",
    "    ax = ax or plt.gca()\n",
    "    monthly_pct_spread = _calculate_year_to_month_spread(log_rets)\n",
    "    monthly_spread = monthly_pct_spread * scale_coeff\n",
    "    cmap = sns.diverging_palette(10, 133, as_cmap=True)\n",
    "    sns.heatmap(monthly_spread, center=0, cmap=cmap, annot=True, fmt=\".2f\", ax=ax)\n",
    "    ax.set_title(f\"Monthly returns ({unit})\")\n",
    "    ax.tick_params(axis=\"y\", rotation=0)\n",
    "\n",
    "\n",
    "def plot_pnl(\n",
    "    pnls: Dict[int, pd.Series],\n",
    "    title: Optional[str] = None,\n",
    "    colormap: Optional[str] = None,\n",
    "    figsize: Optional[Tuple[int]] = None,\n",
    "    start_date: Optional[Union[str, pd.Timestamp]] = None,\n",
    "    end_date: Optional[Union[str, pd.Timestamp]] = None,\n",
    "    nan_mode: Optional[str] = None,\n",
    "    xlabel: Optional[str] = None,\n",
    "    ylabel: Optional[str] = None,\n",
    "    ax: Optional[mpl.axes.Axes] = None,\n",
    ") -> None:\n",
    "    \"\"\"Plot pnls for dict of pnl time series.\n",
    "\n",
    "    :param pnls: dict of pnl time series\n",
    "    :param title: plot title\n",
    "    :param colormap: matplotlib colormap name\n",
    "    :param figsize: size of plot\n",
    "    :param start_date: left limit value of the X axis\n",
    "    :param end_date: right limit value of the X axis\n",
    "    :param nan_mode: argument for hdf.apply_nan_mode()\n",
    "    :param xlabel: label of the X axis\n",
    "    :param ylabel: label of the Y axis\n",
    "    :param ax: axes\n",
    "    \"\"\"\n",
    "    title = title or \"\"\n",
    "    colormap = colormap or \"rainbow\"\n",
    "    nan_mode = nan_mode or \"drop\"\n",
    "    xlabel = xlabel or None\n",
    "    ylabel = ylabel or None\n",
    "    fstr = \"{col} (SR={sr})\"\n",
    "    ax = ax or plt.gca()\n",
    "    #\n",
    "    pnls_notna = {}\n",
    "    empty_srs = []\n",
    "    for key, srs in pnls.items():\n",
    "        srs = hdf.apply_nan_mode(srs, mode=nan_mode)\n",
    "        if srs.dropna().empty:\n",
    "            empty_srs.append(key)\n",
    "        else:\n",
    "            pnls_notna[key] = srs\n",
    "    if empty_srs:\n",
    "        _LOG.warning(\n",
    "            \"Empty input series were dropped: '%s'\",\n",
    "            \", \".join([str(x) for x in empty_srs]),\n",
    "        )\n",
    "    df_plot = pd.concat(pnls_notna, axis=1)\n",
    "    # Compute sharpe ratio for every time series.\n",
    "    sharpe_ratio = {\n",
    "        key: stats.compute_annualized_sharpe_ratio(srs)\n",
    "        for key, srs in pnls.items()\n",
    "    }\n",
    "    sharpe_ratio = pd.Series(sharpe_ratio)\n",
    "    sharpe_cols = [\n",
    "        [round(sr, 1), df_plot.columns[i]] for i, sr in enumerate(sharpe_ratio)\n",
    "    ]\n",
    "    # Change column names and order to column names with sharpe ratio.\n",
    "    df_plot.columns = [\n",
    "        fstr.format(col=str(item[1]), sr=str(item[0])) for item in sharpe_cols\n",
    "    ]\n",
    "    sharpe_cols = sorted(sharpe_cols, key=lambda x: x[0], reverse=True)\n",
    "    sorted_names = [\n",
    "        fstr.format(col=str(item[1]), sr=str(item[0])) for item in sharpe_cols\n",
    "    ]\n",
    "    df_plot = df_plot.reindex(sorted_names, axis=1)\n",
    "    # Plotting the dataframe without dropping `NaN`s in each column results in\n",
    "    # a missing line for some of the pnls. To avoid it, plot by column.\n",
    "    cmap = mpl.cm.get_cmap(colormap)\n",
    "    colors = np.linspace(0, 1, df_plot.shape[1])\n",
    "    colors = [cmap(c) for c in colors]\n",
    "    for color, col in zip(colors, df_plot.columns):\n",
    "        df_plot[col].cumsum().dropna().plot(ax=ax, color=color, figsize=figsize)\n",
    "    # Setting fixed borders of x-axis.\n",
    "    left_lim = start_date or min(df_plot.index)\n",
    "    right_lim = end_date or max(df_plot.index)\n",
    "    ax.set_xlim([left_lim, right_lim])\n",
    "    # Formatting.\n",
    "    ax.set_title(title, fontsize=20)\n",
    "    ax.set_ylabel(ylabel, fontsize=20)\n",
    "    ax.set_xlabel(xlabel, fontsize=20)\n",
    "    ax.legend(prop=dict(size=13), loc=\"upper left\")\n",
    "\n",
    "\n",
    "def plot_drawdown(\n",
    "    log_rets: pd.Series,\n",
    "    unit: str = \"%\",\n",
    "    title_suffix: Optional[str] = None,\n",
    "    ax: Optional[mpl.axes.Axes] = None,\n",
    "    events: Optional[List[Tuple[str, Optional[str]]]] = None,\n",
    ") -> None:\n",
    "    \"\"\"Plot drawdown.\n",
    "\n",
    "    :param log_rets: log returns\n",
    "    :param unit: `ratio`, `%`, input series is rescaled appropriately\n",
    "    :param title_suffix: suffix added to the title\n",
    "    :param ax: axes\n",
    "    :param events: list of tuples with dates and labels to point out on the plot\n",
    "    \"\"\"\n",
    "    title_suffix = title_suffix or \"\"\n",
    "    scale_coeff = _choose_scaling_coefficient(unit)\n",
    "    drawdown = -scale_coeff * fin.compute_perc_loss_from_high_water_mark(log_rets)\n",
    "    label = drawdown.name or \"drawdown\"\n",
    "    title = f\"Drawdown ({unit})\"\n",
    "    ax = ax or plt.gca()\n",
    "    drawdown.plot(ax=ax, label=\"_nolegend_\", color=\"b\", linewidth=3.5)\n",
    "    drawdown.plot.area(\n",
    "        ax=ax, title=f\"{title}{title_suffix}\", label=label, color=\"b\", alpha=0.3\n",
    "    )\n",
    "    _maybe_add_events(ax=ax, events=events)\n",
    "    ax.set_ylim(top=0)\n",
    "    ax.set_ylabel(unit)\n",
    "    ax.legend()\n",
    "\n",
    "\n",
    "def plot_holdings(\n",
    "    holdings: pd.Series,\n",
    "    unit: str = \"ratio\",\n",
    "    ax: Optional[mpl.axes.Axes] = None,\n",
    "    events: Optional[List[Tuple[str, Optional[str]]]] = None,\n",
    ") -> None:\n",
    "    \"\"\"Plot holdings, average holdings and average holdings by month.\n",
    "\n",
    "    :param holdings: pnl series to plot\n",
    "    :param unit: \"ratio\", \"%\" or \"bps\" scaling coefficient\n",
    "    :param ax: axes in which to draw the plot\n",
    "    :param events: list of tuples with dates and labels to point out on the plot\n",
    "    \"\"\"\n",
    "    ax = ax or plt.gca()\n",
    "    scale_coeff = _choose_scaling_coefficient(unit)\n",
    "    holdings = scale_coeff * holdings\n",
    "    holdings.plot(linewidth=1, ax=ax, label=\"holdings\")\n",
    "    holdings.resample(\"M\").mean().plot(\n",
    "        linewidth=2.5, ax=ax, label=\"average holdings by month\"\n",
    "    )\n",
    "    ax.axhline(\n",
    "        holdings.mean(),\n",
    "        linestyle=\"--\",\n",
    "        color=\"green\",\n",
    "        label=\"average holdings, overall\",\n",
    "    )\n",
    "    _maybe_add_events(ax=ax, events=events)\n",
    "    ax.set_ylabel(unit)\n",
    "    ax.legend()\n",
    "    ax.set_title(f\"Total holdings ({unit})\")\n",
    "\n",
    "\n",
    "def plot_qq(\n",
    "    srs: pd.Series,\n",
    "    ax: Optional[mpl.axes.Axes] = None,\n",
    "    dist: Optional[str] = None,\n",
    "    nan_mode: Optional[str] = None,\n",
    ") -> None:\n",
    "    \"\"\"Plot ordered values against theoretical quantiles of the given\n",
    "    distribution.\n",
    "\n",
    "    :param srs: data to plot\n",
    "    :param ax: axes in which to draw the plot\n",
    "    :param dist: distribution name\n",
    "    :param nan_mode: argument for hdf.apply_nan_mode()\n",
    "    \"\"\"\n",
    "    dist = dist or \"norm\"\n",
    "    ax = ax or plt.gca()\n",
    "    nan_mode = nan_mode or \"drop\"\n",
    "    x_plot = hdf.apply_nan_mode(srs, mode=nan_mode)\n",
    "    sp.stats.probplot(x_plot, dist=dist, plot=ax)\n",
    "    ax.set_title(f\"{dist} probability plot\")\n",
    "\n",
    "\n",
    "def plot_turnover(\n",
    "    positions: pd.Series,\n",
    "    unit: str = \"ratio\",\n",
    "    ax: Optional[mpl.axes.Axes] = None,\n",
    "    events: Optional[List[Tuple[str, Optional[str]]]] = None,\n",
    ") -> None:\n",
    "    \"\"\"Plot turnover, average turnover by month and overall average turnover.\n",
    "\n",
    "    :param positions: series of positions to plot\n",
    "    :param unit: \"ratio\", \"%\" or \"bps\" scaling coefficient\n",
    "    :param ax: axes in which to draw the plot\n",
    "    :param events: list of tuples with dates and labels to point out on the plot\n",
    "    \"\"\"\n",
    "    ax = ax or plt.gca()\n",
    "    scale_coeff = _choose_scaling_coefficient(unit)\n",
    "    turnover = fin.compute_turnover(positions)\n",
    "    turnover = scale_coeff * turnover\n",
    "    turnover.plot(linewidth=1, ax=ax, label=\"turnover\")\n",
    "    turnover.resample(\"M\").mean().plot(\n",
    "        linewidth=2.5, ax=ax, label=\"average turnover by month\"\n",
    "    )\n",
    "    ax.axhline(\n",
    "        turnover.mean(),\n",
    "        linestyle=\"--\",\n",
    "        color=\"green\",\n",
    "        label=\"average turnover, overall\",\n",
    "    )\n",
    "    _maybe_add_events(ax=ax, events=events)\n",
    "    ax.set_ylabel(unit)\n",
    "    ax.legend()\n",
    "    ax.set_title(f\"Turnover ({unit})\")\n",
    "\n",
    "\n",
    "def plot_allocation(\n",
    "    position_df: pd.DataFrame,\n",
    "    config: Dict[str, Any],\n",
    "    figsize: Optional[Tuple[int, int]] = None,\n",
    "    ax: Optional[mpl.axes.Axes] = None,\n",
    "    events: Optional[List[Tuple[str, Optional[str]]]] = None,\n",
    ") -> None:\n",
    "    \"\"\"Plot position allocations over time.\n",
    "\n",
    "    :param position_df: dataframe with position time series\n",
    "    :param config: information about time series\n",
    "    :param figsize: size of plot\n",
    "    :param ax: axes\n",
    "    :param events: list of tuples with dates and labels to point out on the plot\n",
    "    \"\"\"\n",
    "    ax = ax or plt.gca()\n",
    "    figsize = figsize or (20, 5)\n",
    "    fstr = \"{key} [{tag}]\"\n",
    "    labels = [\n",
    "        fstr.format(key=str(key), tag=config[key][\"tag\"]) for key in config.keys()\n",
    "    ]\n",
    "    position_df_plot = position_df.copy()\n",
    "    position_df_plot.columns = labels\n",
    "    position_df_plot.plot(ax=ax, figsize=figsize)\n",
    "    _maybe_add_events(ax=ax, events=events)\n",
    "    ax.set_title(\n",
    "        f\"Portfolio allocation over time; {position_df.shape[1]} positions\"\n",
    "    )\n",
    "    ax.set_xlabel(\"period\")\n",
    "    ax.legend()\n",
    "\n",
    "\n",
    "def plot_rolling_beta(\n",
    "    rets: pd.Series,\n",
    "    benchmark_rets: pd.Series,\n",
    "    window: int,\n",
    "    nan_mode: Optional[str] = None,\n",
    "    ax: Optional[mpl.axes.Axes] = None,\n",
    "    events: Optional[List[Tuple[str, Optional[str]]]] = None,\n",
    "    **kwargs: Any,\n",
    ") -> None:\n",
    "    \"\"\"Regress returns against benchmark series and plot rolling beta.\n",
    "\n",
    "    :param rets: returns\n",
    "    :param benchmark_rets: benchmark returns\n",
    "    :param window: length of the rolling window\n",
    "    :param nan_mode: argument for hdf.apply_nan_mode()\n",
    "    :param ax: axis\n",
    "    :param events: list of tuples with dates and labels to point out on the plot\n",
    "    :param kwargs: kwargs for statsmodels.regression.rolling.RollingOLS\n",
    "    \"\"\"\n",
    "    dbg.dassert_strictly_increasing_index(rets)\n",
    "    dbg.dassert_strictly_increasing_index(benchmark_rets)\n",
    "    dbg.dassert_eq(rets.index.freq, benchmark_rets.index.freq)\n",
    "    # Assert that the 'rets' index is a subset of the 'benchmark_rets' index.\n",
    "    dbg.dassert(rets.index.isin(benchmark_rets.index).all())\n",
    "    dbg.dassert_lte(\n",
    "        window,\n",
    "        min(len(rets), len(benchmark_rets)),\n",
    "        \"`window` should not be larger than inputs' lengths.\",\n",
    "    )\n",
    "    rets_name = rets.name\n",
    "    benchmark_name = benchmark_rets.name\n",
    "    dbg.dassert_ne(\n",
    "        rets_name, benchmark_name, \"Inputs should have different names.\"\n",
    "    )\n",
    "    nan_mode = nan_mode or \"drop\"\n",
    "    # Combine rets and benchmark_rets in one dataframe over the intersection\n",
    "    #    of their indices.\n",
    "    all_rets_df = pd.concat([rets, benchmark_rets], axis=1, join=\"inner\")\n",
    "    all_rets_df.columns = [rets_name, benchmark_name]\n",
    "    # Extract common index in order to keep NaN periods on the X-axis.\n",
    "    common_index = all_rets_df.index\n",
    "    # Apply `.dropna()` after `hdf.apply_nan_mode` in oder to drop remaining\n",
    "    #     rows with NaNs and calculate rolling beta without NaN gaps in input.\n",
    "    clean_rets_df = all_rets_df.apply(hdf.apply_nan_mode, mode=nan_mode).dropna()\n",
    "    # Get copies of rets and benchmark_rets with unified indices and no NaNs.\n",
    "    rets = clean_rets_df[rets_name]\n",
    "    benchmark_rets = clean_rets_df[benchmark_name]\n",
    "    # Calculate and plot rolling beta.\n",
    "    ax = ax or plt.gca()\n",
    "    benchmark_rets = sm.add_constant(benchmark_rets)\n",
    "    # Calculate and plot rolling beta.\n",
    "    model_rolling = smrr.RollingOLS(rets, benchmark_rets, window=window, **kwargs)\n",
    "    res_rolling = model_rolling.fit()\n",
    "    beta_rolling = res_rolling.params[\n",
    "        benchmark_name\n",
    "    ]  # pylint: disable=unsubscriptable-object\n",
    "    # Return NaN periods to the rolling beta series for the plot.\n",
    "    beta_rolling = beta_rolling.reindex(common_index)\n",
    "    beta_rolling.plot(\n",
    "        ax=ax,\n",
    "        title=f\"Beta with respect to {benchmark_name}\",\n",
    "        label=\"Rolling beta\",\n",
    "    )\n",
    "    # Calculate and plot beta for the whole period.\n",
    "    model_whole_period = sm.OLS(rets, benchmark_rets)\n",
    "    res_whole_period = model_whole_period.fit()\n",
    "    beta_whole_period = res_whole_period.params[benchmark_name]\n",
    "    ax.axhline(beta_whole_period, ls=\"--\", c=\"k\", label=\"Whole-period beta\")\n",
    "    ax.set_xlabel(\"period\")\n",
    "    ax.set_ylabel(\"beta\")\n",
    "    _maybe_add_events(ax=ax, events=events)\n",
    "    ax.legend()\n",
    "\n",
    "\n",
    "def plot_rolling_correlation(\n",
    "    srs1: pd.Series,\n",
    "    srs2: pd.Series,\n",
    "    tau: float,\n",
    "    demean: bool = True,\n",
    "    min_periods: int = 0,\n",
    "    min_depth: int = 1,\n",
    "    max_depth: int = 1,\n",
    "    p_moment: float = 2,\n",
    "    mode: Optional[str] = None,\n",
    "    ax: Optional[mpl.axes.Axes] = None,\n",
    "    events: Optional[List[Tuple[str, Optional[str]]]] = None,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Return rolling correlation between 2 series and plot rolling correlation.\n",
    "\n",
    "    :param srs1: first series\n",
    "    :param srs2: second series\n",
    "    :param tau: tau correlation coefficient\n",
    "    :param demean: bool demean\n",
    "    :param min_periods: min periods\n",
    "    :param min_depth: min depth\n",
    "    :param max_depth: max depth\n",
    "    :param p_moment: p moment\n",
    "    :param mode: corr or zcorr\n",
    "    :param ax: axis\n",
    "    :param events: list of tuples with dates and labels to point out on the plot\n",
    "    \"\"\"\n",
    "    mode = mode or \"corr\"\n",
    "    # Calculate and plot rolling correlation.\n",
    "    ax = ax or plt.gca()\n",
    "    # Calculate rolling correlation.\n",
    "    if mode == \"zcorr\":\n",
    "        roll_correlation = sigp.compute_rolling_zcorr\n",
    "        title = \"Z Correlation of 2 time series\"\n",
    "        label = \"Rolling z correlation\"\n",
    "    elif mode == \"corr\":\n",
    "        roll_correlation = sigp.compute_rolling_corr\n",
    "        title = \"Correlation of 2 time series\"\n",
    "        label = \"Rolling correlation\"\n",
    "    else:\n",
    "        raise ValueError(\"Invalid mode='%s'\" % mode)\n",
    "    # Calculate rolling correlation with the given mode.\n",
    "    roll_corr = roll_correlation(\n",
    "        srs1,\n",
    "        srs2,\n",
    "        tau=tau,\n",
    "        demean=demean,\n",
    "        min_periods=min_periods,\n",
    "        min_depth=min_depth,\n",
    "        max_depth=max_depth,\n",
    "        p_moment=p_moment,\n",
    "    )\n",
    "    # Plot rolling correlation.\n",
    "    roll_corr.plot(ax=ax, title=title, label=label)\n",
    "    # Calculate correlation whole period.\n",
    "    whole_period = srs1.corr(srs2)\n",
    "    # Plot correlation whole period.\n",
    "    ax.axhline(whole_period, ls=\"--\", c=\"k\", label=\"Whole-period correlation\")\n",
    "    ax.set_xlabel(\"period\")\n",
    "    ax.set_ylabel(\"correlation\")\n",
    "    _maybe_add_events(ax=ax, events=events)\n",
    "    ax.legend()\n",
    "\n",
    "\n",
    "def plot_sharpe_ratio_panel(\n",
    "    log_rets: pd.Series,\n",
    "    frequencies: Optional[List[str]] = None,\n",
    "    ax: Optional[mpl.axes.Axes] = None,\n",
    ") -> None:\n",
    "    \"\"\"Plot how SRs vary under resampling.\n",
    "\n",
    "    :param log_rets: log returns\n",
    "    :param frequencies: frequencies to calculate SR for\n",
    "    :param ax: axis\n",
    "    \"\"\"\n",
    "    dbg.dassert_isinstance(log_rets, pd.Series)\n",
    "    frequencies = frequencies or [\"B\", \"D\", \"W\", \"M\", \"Q\"]\n",
    "    srs_freq = pd.infer_freq(log_rets.index)\n",
    "    if not srs_freq:\n",
    "        _LOG.warning(\"Input has no frequency and it has been rescaled to 'D'\")\n",
    "        srs_freq = \"D\"\n",
    "    # Resample input for assuring input frequency in calculations.\n",
    "    log_rets = sigp.resample(log_rets, rule=srs_freq).sum()\n",
    "    # Initiate series for Sharpe ratios of selected frequencies.\n",
    "    sr_series = pd.Series([], dtype=\"object\")\n",
    "    # Initiate list for Sharpe ratios' standard errors for error bars.\n",
    "    res_se = []\n",
    "    # Initiate list for frequencies that do not lead to upsampling.\n",
    "    valid_frequencies = []\n",
    "    # Compute input frequency points per year for identifying upsampling.\n",
    "    input_freq_points_per_year = hdf.infer_sampling_points_per_year(log_rets)\n",
    "    for freq in frequencies:\n",
    "        freq_points_per_year = hdf.compute_points_per_year_for_given_freq(freq)\n",
    "        if freq_points_per_year > input_freq_points_per_year:\n",
    "            _LOG.warning(\n",
    "                \"Upsampling from input freq='%s' to freq='%s' is blocked\",\n",
    "                srs_freq,\n",
    "                freq,\n",
    "            )\n",
    "            continue\n",
    "        resampled_log_rets = sigp.resample(log_rets, rule=freq).sum()\n",
    "        if len(resampled_log_rets) == 1:\n",
    "            _LOG.warning(\n",
    "                \"Resampling to freq='%s' is blocked because resampled series has only 1 observation\",\n",
    "                freq,\n",
    "            )\n",
    "            continue\n",
    "        sr = stats.compute_annualized_sharpe_ratio(resampled_log_rets)\n",
    "        se = stats.compute_annualized_sharpe_ratio_standard_error(\n",
    "            resampled_log_rets\n",
    "        )\n",
    "        sr_series[freq] = sr\n",
    "        res_se.append(se)\n",
    "        valid_frequencies.append(freq)\n",
    "    ax = ax or plt.gca()\n",
    "    sr_series.plot(\n",
    "        yerr=res_se, marker=\"o\", capsize=2, ax=ax, label=\"Sharpe ratio\"\n",
    "    )\n",
    "    ax.set_xticks(range(len(valid_frequencies)))\n",
    "    ax.set_xticklabels(valid_frequencies)\n",
    "    ax.set_xlabel(\"Frequencies\")\n",
    "    ax.legend()\n",
    "\n",
    "\n",
    "def _choose_scaling_coefficient(unit: str) -> int:\n",
    "    if unit == \"%\":\n",
    "        scale_coeff = 100\n",
    "    elif unit == \"bps\":\n",
    "        scale_coeff = 10000\n",
    "    elif unit == \"ratio\":\n",
    "        scale_coeff = 1\n",
    "    else:\n",
    "        raise ValueError(\"Invalid unit='%s'\" % unit)\n",
    "    return scale_coeff\n",
    "\n",
    "\n",
    "def _calculate_year_to_month_spread(log_rets: pd.Series) -> pd.DataFrame:\n",
    "    \"\"\"Calculate log returns statistics by year and month.\n",
    "\n",
    "    :param log_rets: input series of log returns\n",
    "    :return: dataframe of log returns with years on y-axis and\n",
    "        months on x-axis\n",
    "    \"\"\"\n",
    "    srs_name = log_rets.name or 0\n",
    "    log_rets_df = pd.DataFrame(log_rets)\n",
    "    log_rets_df[\"year\"] = log_rets_df.index.year\n",
    "    log_rets_df[\"month\"] = log_rets_df.index.month\n",
    "    log_rets_df.reset_index(inplace=True)\n",
    "    monthly_log_returns = log_rets_df.groupby([\"year\", \"month\"])[srs_name].sum()\n",
    "    monthly_pct_returns = fin.convert_log_rets_to_pct_rets(monthly_log_returns)\n",
    "    monthly_pct_spread = monthly_pct_returns.unstack()\n",
    "    monthly_pct_spread.columns = monthly_pct_spread.columns.map(\n",
    "        lambda x: calendar.month_abbr[x]\n",
    "    )\n",
    "    return monthly_pct_spread\n",
    "\n",
    "\n",
    "def _maybe_add_events(\n",
    "    ax: mpl.axes.Axes, events: Optional[List[Tuple[str, Optional[str]]]]\n",
    ") -> None:\n",
    "    \"\"\"Add labeled vertical lines at events' dates on a plot.\n",
    "\n",
    "    :param ax: axes\n",
    "    :param events: list of tuples with dates and labels to point out on the plot\n",
    "    \"\"\"\n",
    "    if not events:\n",
    "        return None\n",
    "    colors = cm.get_cmap(\"Set1\")(np.linspace(0, 1, len(events)))\n",
    "    for event, color in zip(events, colors):\n",
    "        ax.axvline(\n",
    "            x=pd.Timestamp(event[0]),\n",
    "            label=event[1],\n",
    "            color=color,\n",
    "            linestyle=\"--\",\n",
    "        )\n",
    "    return None"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "notebook_metadata_filter": "-all",
   "text_representation": {
    "extension": ".py",
    "format_name": "sphinx"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
