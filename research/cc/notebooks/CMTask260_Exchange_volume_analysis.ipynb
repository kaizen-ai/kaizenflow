{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d89954b",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c5136c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import core.config.config_ as ccocon\n",
    "import helpers.dbg as hdbg\n",
    "import helpers.env as henv\n",
    "import helpers.printing as hprintin\n",
    "import helpers.s3 as hs3\n",
    "import im.data.universe as imdauni\n",
    "import research.cc.statistics as rccsta\n",
    "import research.cc.volume as rccvol\n",
    "\n",
    "import core.plotting as cplot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b385e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "hdbg.init_logger(verbosity=logging.INFO)\n",
    "\n",
    "_LOG = logging.getLogger(__name__)\n",
    "\n",
    "_LOG.info(\"%s\", henv.get_system_signature()[0])\n",
    "\n",
    "hprintin.config_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb724155",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80c98e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cmtask260_config() -> ccocon.Config:\n",
    "    \"\"\"\n",
    "    Get task260-specific config.\n",
    "    \"\"\"\n",
    "    config = ccocon.Config()\n",
    "    # Load parameters.\n",
    "    config.add_subconfig(\"load\")\n",
    "    config[\"load\"][\"aws_profile\"] = \"am\"\n",
    "    config[\"load\"][\"data_dir\"] = os.path.join(hs3.get_path(), \"data\")\n",
    "    # Data parameters.\n",
    "    config.add_subconfig(\"data\")\n",
    "    config[\"data\"][\"data_type\"] = \"OHLCV\"\n",
    "    config[\"data\"][\"universe_version\"] = \"v0_3\"\n",
    "    # Column names.\n",
    "    config.add_subconfig(\"column_names\")\n",
    "    config[\"column_names\"][\"volume\"] = \"volume\"\n",
    "    config[\"column_names\"][\"currency_pair\"] = \"currency_pair\"\n",
    "    config[\"column_names\"][\"exchange\"] = \"exchange_id\"\n",
    "    config[\"column_names\"][\"close\"] = \"close\"\n",
    "    return config\n",
    "\n",
    "\n",
    "config = get_cmtask260_config()\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192b67b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loader = imccdaloloa.CcxtLoader(\n",
    "#    root_dir=\"s3://alphamatic-data/data\", aws_profile=\"am\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e96cec",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7764af",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_cumul_volume_ = lambda data: rccvol.compute_cumul_volume(\n",
    "    data, config, is_notional_volume=False\n",
    ")\n",
    "\n",
    "cumul_volume = rccsta.compute_stats_for_universe(config, compute_cumul_volume_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78766ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "_LOG.info(\"The number of (exchanges, currency pairs) =%s\", cumul_volume.shape[0])\n",
    "cumul_volume.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a681e0",
   "metadata": {},
   "source": [
    "# Compute total volume per exchange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e5c18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_volume_by_exchange = rccvol.get_total_volume_by_exchange(\n",
    "    cumul_volume, config, avg_daily=False\n",
    ")\n",
    "print(total_volume_by_exchange)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77404f60",
   "metadata": {},
   "source": [
    "# Compute total volume per currency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15783d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_volume_by_coins = rccvol.get_total_volume_by_coins(\n",
    "    cumul_volume, config, avg_daily=False\n",
    ")\n",
    "print(total_volume_by_coins)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7dcccb",
   "metadata": {},
   "source": [
    "# Issue with compute_stats_for_universe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f10d2e",
   "metadata": {},
   "source": [
    "As one can see, __compute_stats_for_universe()__ returns DataFrame with omitted timestamp values that are necessary to plot graph for rolling volume.\n",
    "\n",
    "What do you think we should do in this case?\n",
    "- We can either add param to your initial function that doesn't drop timestamp values\n",
    "- Or write the new one that takes into account timestamp values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf6863c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_daily_volume(data, is_nominal_value):\n",
    "    if is_nominal_value:\n",
    "        data[\"volume\"]=data[\"volume\"]*data[\"close\"]\n",
    "    data[\"date\"] = data.index.date\n",
    "    data_grouped = data.groupby([\"exchange_id\", \"currency_pair\", \"date\"], as_index=False)\n",
    "    cumul_daily_volume = data_grouped[\"volume\"].sum()\n",
    "    return cumul_daily_volume\n",
    "\n",
    "compute_daily_volume = lambda data: get_daily_volume(data, is_nominal_value=True)\n",
    "\n",
    "cumul_daily_volume = rccsta.compute_stats_for_universe(\n",
    "    config, compute_daily_volume\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ff51e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cumul_daily_volume"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c3802a3",
   "metadata": {},
   "source": [
    "# Rolling Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af38ad82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rolling_volume_per_group(data, group, window, display_plot):\n",
    "    data_grouped = data.groupby([group, \"date\"], as_index=False)\n",
    "    cum_volume_per_group_per_day = data_grouped[\"volume\"].sum()\n",
    "    resampler = cum_volume_per_group_per_day.groupby([group])\n",
    "    rolling_volume = resampler[\"volume\"].transform(lambda x: x.rolling(window).mean())\n",
    "    cum_volume_per_group_per_day = cum_volume_per_group_per_day.merge(rolling_volume.to_frame(),left_index=True,right_index=True)\n",
    "    cum_volume_per_group_per_day.rename(columns={'volume_x':'volume','volume_y':\"rolling_volume\"}, inplace=True)\n",
    "    if display_plot:\n",
    "        sns.lineplot(data=cum_volume_per_group_per_day, x='date', y='rolling_volume', hue=group)\n",
    "    return cum_volume_per_group_per_day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a872aa61",
   "metadata": {},
   "outputs": [],
   "source": [
    "rolling_vol_exchange = get_rolling_volume_per_group(cumul_daily_volume, group=\"exchange_id\", window=90, display_plot=True)\n",
    "print(rolling_vol_exchange)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d42738b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rolling_vol_coins = get_rolling_volume_per_group(cumul_daily_volume, group=\"currency_pair\", window=90, display_plot=True)\n",
    "print(rolling_vol_coins)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cadaa4f",
   "metadata": {},
   "source": [
    "# Compare weekday volumes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b45b8fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_weekdays_volumes(df, plot_total_volumes, plot_distr_by_weekdays):\n",
    "    df[\"weekday\"] = df[\"date\"].map(lambda x: x.strftime(\"%A\"))\n",
    "    total_volume_by_weekdays = df.groupby(\"weekday\")[\"volume\"].sum().sort_values(ascending=False)\n",
    "    if plot_total_volumes:\n",
    "        cplot.plot_barplot(\n",
    "                    total_volume_by_weekdays,\n",
    "                    title=\"Total volume per weekdays\",\n",
    "                    figsize=[15, 7],\n",
    "                )\n",
    "    if plot_distr_by_weekdays:\n",
    "        weekends = df[(df[\"weekday\"] == \"Saturday\") | (df[\"weekday\"] == \"Sunday\")]\n",
    "        weekdays = df[(df[\"weekday\"] != \"Saturday\") & (df[\"weekday\"] != \"Sunday\")]\n",
    "        weekends_volume = weekends.groupby([\"date\",\"weekday\"])[\"volume\"].sum()\n",
    "        weekdays_volume = weekdays.groupby([\"date\",\"weekday\"])[\"volume\"].sum()\n",
    "        sns.displot(weekends_volume).set(title = 'Volume Distribution by weekends')\n",
    "        sns.displot(weekdays_volume).set(title = 'Volume Distribution by working days')\n",
    "    return total_volume_by_weekdays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd28586",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_volume_by_weekdays = compare_weekdays_volumes(cumul_daily_volume,\n",
    "                                                    plot_total_volumes=True,\n",
    "                                                    plot_distr_by_weekdays=True)\n",
    "print(total_volume_by_weekdays)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a4050b9",
   "metadata": {},
   "source": [
    "# Compare ATH volumes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0208862d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ath_volumes_comparison(df_list):\n",
    "    \"\"\"\n",
    "    Return the graph with the comparison of average minute total trading volume\n",
    "    in ATH vs.\n",
    "\n",
    "    non-ATH\n",
    "    Parameters: dataframe with volumes from a given exchange\n",
    "    \"\"\"\n",
    "    plot_df = []\n",
    "    for df in df_list:\n",
    "        df_ath = df.iloc[df.index.indexer_between_time(\"09:30\", \"16:00\")]\n",
    "        df_not_ath = df.loc[~df.index.isin(df_ath.index)]\n",
    "        ath_stat = pd.DataFrame()\n",
    "        ath_stat.loc[f\"{df.name}\", f\"minute_avg_total_volume_ath_{df.name}\"] = (\n",
    "            df_ath.sum().sum() / df_ath.shape[0]\n",
    "        )\n",
    "        ath_stat.loc[\n",
    "            f\"{df.name}\", f\"minute_avg_total_volume_not_ath_{df.name}\"\n",
    "        ] = (df_not_ath.sum().sum() / df_not_ath.shape[0])\n",
    "        plot_df.append(ath_stat)\n",
    "    plot_df = pd.concat(plot_df)\n",
    "    plot_df.plot.bar(figsize=(15, 7), logy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52579e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ath_volume(data, is_nominal_value):\n",
    "    if is_nominal_value:\n",
    "        data[\"volume\"]=data[\"volume\"]*data[\"close\"]\n",
    "    df_ath = data.iloc[data.index.indexer_between_time(\"09:30\", \"16:00\")]\n",
    "    df_not_ath = data.loc[~data.index.isin(df_ath.index)]\n",
    "    ath_stat = pd.DataFrame()\n",
    "    ath_stat.loc[f\"{df.name}\", f\"minute_avg_total_volume_ath_{df.name}\"] = (\n",
    "        df_ath.sum().sum() / df_ath.shape[0]\n",
    "    )\n",
    "    ath_stat.loc[\n",
    "        f\"{df.name}\", f\"minute_avg_total_volume_not_ath_{df.name}\"\n",
    "    ] = (df_not_ath.sum().sum() / df_not_ath.shape[0])\n",
    "    plot_df.append(ath_stat)\n",
    "    plot_df = pd.concat(plot_df)\n",
    "    plot_df.plot.bar(figsize=(15, 7), logy=True)\n",
    "    \n",
    "    \n",
    "    \n",
    "    data[\"date\"] = data.index.date\n",
    "    data_grouped = data.groupby([\"exchange_id\", \"currency_pair\", \"date\"], as_index=False)\n",
    "    cumul_daily_volume = data_grouped[\"volume\"].sum()\n",
    "    return cumul_daily_volume\n",
    "\n",
    "    compute_ath_volume = lambda data: get_ath_volume(data, is_nominal_value=True)\n",
    "\n",
    "    compute_ath_volume = rccsta.compute_stats_for_universe(\n",
    "        config, compute_ath_volume\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098faacd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9fb52ea5",
   "metadata": {},
   "source": [
    "# OLD CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2985527",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ace4cd6",
   "metadata": {},
   "source": [
    "Note: by \"volume\" I mean the standard output that is nominated in the number of coins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8119c44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_volume_df_for_exch(coins, exchange):\n",
    "    \"\"\"\n",
    "    Return the DataFrame with a volume of all available coins for a given exchange \\\n",
    "    with timestamp transformation to one day\n",
    "    Parameters: list of coins for a particular exchange, exchange name\n",
    "    \"\"\"\n",
    "    result = []\n",
    "    for coin in coins:\n",
    "        df = config.read_data_from_filesystem(\n",
    "            exchange_id=exchange, currency_pair=coin, data_type=\"OHLCV\"\n",
    "        )\n",
    "        # transform timestamp into one-day format\n",
    "        volume_df = pd.DataFrame(df.groupby(by=df.index.date)[\"volume\"].sum())\n",
    "        volume_df.columns = [\n",
    "            col_name + f\"_{suffixes[coin]}_{exchange}\"\n",
    "            for col_name in volume_df.columns\n",
    "        ]\n",
    "        result.append(volume_df)\n",
    "    final_result = pd.concat(result, axis=1)\n",
    "    return final_result\n",
    "\n",
    "\n",
    "def get_total_trading_volume_by_coins(coin_list, exch_list):\n",
    "    \"\"\"\n",
    "    Return the DataFrame with total trading volume and normalised trading volume (by day) \\\n",
    "    of all coins from all available exchanges\n",
    "    Parameters: list of coin names, volume dataframes\n",
    "    \"\"\"\n",
    "    df = pd.concat(exch_list, axis=1)\n",
    "    volume_df = pd.DataFrame()\n",
    "    for coin in coin_list:\n",
    "        coin_cols = [col for col in df.columns if coin in col]\n",
    "        coin_df = df[coin_cols]\n",
    "        coin_df[\"total_volume\"] = coin_df.sum(axis=1)\n",
    "        total_volume_ = coin_df[\"total_volume\"].sum()\n",
    "        norm_volume_ = coin_df[\"total_volume\"].sum() / len(\n",
    "            coin_df[coin_df[\"total_volume\"] != 0]\n",
    "        )\n",
    "        volume_df.loc[\n",
    "            \"{}\".format(f\"{coin}\"), (\"total_trading_volume_in_coins\")\n",
    "        ] = total_volume_\n",
    "        volume_df.loc[\n",
    "            \"{}\".format(f\"{coin}\"), (\"daily_avg_coin_volume\")\n",
    "        ] = norm_volume_\n",
    "    return volume_df.sort_values(\n",
    "        by=\"total_trading_volume_in_coins\", ascending=False\n",
    "    )\n",
    "\n",
    "\n",
    "def get_total_trading_volume_by_exchange(df_list):\n",
    "    \"\"\"\n",
    "    Return the DataFrame with total trading volume on exchanges\n",
    "    Parameters: volume dataframes\n",
    "    \"\"\"\n",
    "    exch_volume = pd.DataFrame()\n",
    "    for df in df_list:\n",
    "        total_volume_ = df.sum().sum()\n",
    "        norm_volume_ = df.sum().sum() / df.shape[0]\n",
    "        exch_volume.loc[\n",
    "            \"{}\".format(f\"{df.name}\"), \"total_trading_volume_in_coins\"\n",
    "        ] = total_volume_\n",
    "        exch_volume.loc[\n",
    "            \"{}\".format(f\"{df.name}\"), \"daily_avg_coin_volume\"\n",
    "        ] = norm_volume_\n",
    "    return exch_volume.sort_values(\n",
    "        by=\"total_trading_volume_in_coins\", ascending=False\n",
    "    )\n",
    "\n",
    "\n",
    "def plot_rolling_volume_by_coins(coin_list, exch_list):\n",
    "    \"\"\"\n",
    "    Return the graph of 90-days rolling volumes for each coin on all exchanges\n",
    "    Parameters: list of all coin names, volume dataframes\n",
    "    \"\"\"\n",
    "    df = pd.concat(exch_list, axis=1)\n",
    "    rolling_df = []\n",
    "    for coin in coin_list:\n",
    "        coin_df = df[[col for col in df.columns if coin in col]]\n",
    "        coin_df[\"total_volume\"] = coin_df.sum(axis=1)\n",
    "        coin_df[f\"rolling_90_volume_{coin}\"] = (\n",
    "            coin_df[\"total_volume\"].rolling(90).mean()\n",
    "        )\n",
    "        rolling_df.append(coin_df[f\"rolling_90_volume_{coin}\"])\n",
    "    rolling_df = pd.concat(rolling_df, axis=1)\n",
    "    rolling_df.plot(figsize=(12, 7))\n",
    "\n",
    "\n",
    "def plot_rolling_volume_by_exchange(exch_list, exch_names):\n",
    "    \"\"\"\n",
    "    Return the graph of 90-days rolling volumes for each exchanges for all coins\n",
    "    Parameters: volume dataframes, volume dataframes' names\n",
    "    \"\"\"\n",
    "    df = pd.concat(exch_list, axis=1)\n",
    "    rolling_df = []\n",
    "    for exch in exch_names:\n",
    "        exch_cols = [col for col in df.columns if exch in col]\n",
    "        exch_df = df[exch_cols]\n",
    "        exch_df[\"total_volume\"] = exch_df.sum(axis=1)\n",
    "        exch_df[f\"rolling_90_volume_{exch}\"] = (\n",
    "            exch_df[\"total_volume\"].rolling(90).mean()\n",
    "        )\n",
    "        rolling_df.append(exch_df[f\"rolling_90_volume_{exch}\"])\n",
    "    rolling_df = pd.concat(rolling_df, axis=1)\n",
    "    rolling_df.plot(figsize=(12, 7))\n",
    "\n",
    "\n",
    "def compare_weekdays_volumes(exch_list):\n",
    "    \"\"\"\n",
    "    Return statistics and graphs with working days vs.\n",
    "\n",
    "    weekends analysis\n",
    "    Parameters: volume dataframes\n",
    "    \"\"\"\n",
    "    # clean the existing dataframes from previously calculated volumes\n",
    "    df = pd.concat(exch_list, axis=1)\n",
    "    df = df[[col for col in df.columns if \"total_volume\" not in col]]\n",
    "    df = df[[col for col in df.columns if \"rolling_volume\" not in col]]\n",
    "    # calculate new volumes that sum up all coins and exchanges\n",
    "    df[\"total_volume\"] = df.sum(axis=1)\n",
    "    # create column with ids for weekdays\n",
    "    df[\"weekday\"] = df.index.map(lambda x: x.weekday())\n",
    "    # plot total amount of volume for each day\n",
    "    df.groupby(\"weekday\").total_volume.sum().plot.bar(figsize=(12, 7))\n",
    "    # plot working days vs. weekends\n",
    "    weekends = df[(df[\"weekday\"] == 5) | (df[\"weekday\"] == 6)]\n",
    "    sns.displot(weekends, x=\"total_volume\")\n",
    "    weekdays = df[(df[\"weekday\"] != 5) & (df[\"weekday\"] != 6)]\n",
    "    sns.displot(weekdays, x=\"total_volume\")\n",
    "    # calculate descriptive statistics for working days vs. weekends\n",
    "    print(\"Descriptive statistics:\")\n",
    "    weeknd_stat = weekends[\"total_volume\"].describe()\n",
    "    weekdys_stat = weekdays[\"total_volume\"].describe()\n",
    "    weeknd_stat = pd.DataFrame(weeknd_stat)\n",
    "    weekdys_stat = pd.DataFrame(weekdys_stat)\n",
    "    stats = pd.concat([weeknd_stat, weekdys_stat], axis=1)\n",
    "    stats.columns = [\"weekends\", \"working_days\"]\n",
    "    print(stats)\n",
    "    print(\n",
    "        \"The graph labels in respective order: Total Volume by weekdays, Distribution of Volume over weekends, Distribution of Volume over working days\"\n",
    "    )\n",
    "\n",
    "\n",
    "def get_initial_df_with_volumes(coins, exchange):\n",
    "    \"\"\"\n",
    "    Return DataFrame with the volume of all coins for exchange with initial timestamps\n",
    "    Parameters: list of coins, exchange name\n",
    "    \"\"\"\n",
    "    result = []\n",
    "    for coin in coins:\n",
    "        df = config.read_data_from_filesystem(\n",
    "            exchange_id=exchange, currency_pair=coin, data_type=\"OHLCV\"\n",
    "        )\n",
    "        result.append(df[\"volume\"])\n",
    "    final_result = pd.concat(result, axis=1)\n",
    "    return final_result\n",
    "\n",
    "\n",
    "def plot_ath_volumes_comparison(df_list):\n",
    "    \"\"\"\n",
    "    Return the graph with the comparison of average minute total trading volume\n",
    "    in ATH vs.\n",
    "\n",
    "    non-ATH\n",
    "    Parameters: dataframe with volumes from a given exchange\n",
    "    \"\"\"\n",
    "    plot_df = []\n",
    "    for df in df_list:\n",
    "        df_ath = df.iloc[df.index.indexer_between_time(\"09:30\", \"16:00\")]\n",
    "        df_not_ath = df.loc[~df.index.isin(df_ath.index)]\n",
    "        ath_stat = pd.DataFrame()\n",
    "        ath_stat.loc[f\"{df.name}\", f\"minute_avg_total_volume_ath_{df.name}\"] = (\n",
    "            df_ath.sum().sum() / df_ath.shape[0]\n",
    "        )\n",
    "        ath_stat.loc[\n",
    "            f\"{df.name}\", f\"minute_avg_total_volume_not_ath_{df.name}\"\n",
    "        ] = (df_not_ath.sum().sum() / df_not_ath.shape[0])\n",
    "        plot_df.append(ath_stat)\n",
    "    plot_df = pd.concat(plot_df)\n",
    "    plot_df.plot.bar(figsize=(15, 7), logy=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d35e28",
   "metadata": {},
   "source": [
    "### Supporting variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64188e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the list of all coin paires for each exchange\n",
    "binance_coins = imdauni.get_trade_universe(\"v0_1\")[\"CCXT\"][\"binance\"]\n",
    "bitfinex_coins = imdauni.get_trade_universe(\"v0_1\")[\"CCXT\"][\"bitfinex\"]\n",
    "ftx_coins = imdauni.get_trade_universe(\"v0_1\")[\"CCXT\"][\"ftx\"]\n",
    "gateio_coins = imdauni.get_trade_universe(\"v0_1\")[\"CCXT\"][\"gateio\"]\n",
    "kucoin_coins = imdauni.get_trade_universe(\"v0_1\")[\"CCXT\"][\"kucoin\"]\n",
    "\n",
    "suffixes = {\n",
    "    \"ADA/USDT\": \"ada\",\n",
    "    \"AVAX/USDT\": \"avax\",\n",
    "    \"BNB/USDT\": \"bnb\",\n",
    "    \"BTC/USDT\": \"btc\",\n",
    "    \"DOGE/USDT\": \"doge\",\n",
    "    \"EOS/USDT\": \"eos\",\n",
    "    \"ETH/USDT\": \"eth\",\n",
    "    \"LINK/USDT\": \"link\",\n",
    "    \"SOL/USDT\": \"sol\",\n",
    "    \"FIL/USDT\": \"fil\",\n",
    "    \"XRP/USDT\": \"xrp\",\n",
    "}\n",
    "\n",
    "# get the list of all unique coin names\n",
    "coins = set(\n",
    "    binance_coins + bitfinex_coins + ftx_coins + gateio_coins + kucoin_coins\n",
    ")\n",
    "coins = [i.split(\"/\")[0].lower() for i in coins]\n",
    "\n",
    "exch_names = [\"binance\", \"bitfinex\", \"ftx\", \"gateio\", \"kucoin\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "767ee083",
   "metadata": {},
   "source": [
    "## Load the volumes dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "819fdbd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "binance = get_volume_df_for_exch_notional(binance_coins, \"binance\")\n",
    "bitfinex = get_volume_df_for_exch_notional(bitfinex_coins, \"bitfinex\")\n",
    "ftx = get_volume_df_for_exch_notional(ftx_coins, \"ftx\")\n",
    "gateio = get_volume_df_for_exch_notional(gateio_coins, \"gateio\")\n",
    "kucoin = get_volume_df_for_exch_notional(kucoin_coins, \"kucoin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e06500",
   "metadata": {},
   "outputs": [],
   "source": [
    "binance = get_volume_df_for_exch(binance_coins, \"binance\")\n",
    "bitfinex = get_volume_df_for_exch(bitfinex_coins, \"bitfinex\")\n",
    "ftx = get_volume_df_for_exch(ftx_coins, \"ftx\")\n",
    "gateio = get_volume_df_for_exch(gateio_coins, \"gateio\")\n",
    "kucoin = get_volume_df_for_exch(kucoin_coins, \"kucoin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf67dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "binance.name = \"binance\"\n",
    "bitfinex.name = \"bitfinex\"\n",
    "ftx.name = \"ftx\"\n",
    "gateio.name = \"gateio\"\n",
    "kucoin.name = \"kucoin\"\n",
    "\n",
    "exch_list = [binance, bitfinex, ftx, gateio, kucoin]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1603f8",
   "metadata": {},
   "source": [
    "# Compute total trading volume for each currency\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8d7629",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_trading_vol = get_total_trading_volume_by_coins(coins, exch_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa8b50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_trading_vol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f545727f",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_trading_vol[\"total_trading_volume_in_coins\"].plot.bar(\n",
    "    figsize=(15, 7), logy=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e94284",
   "metadata": {},
   "outputs": [],
   "source": [
    "# daily_avg\n",
    "total_trading_vol[\"daily_avg_coin_volume\"].sort_values(ascending=False).plot.bar(\n",
    "    figsize=(15, 7), logy=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e552381c",
   "metadata": {},
   "source": [
    "# Rolling volume for each currency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7b7b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_rolling_volume_by_coins(coins, exch_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da663556",
   "metadata": {},
   "source": [
    "# Compute total volume per exchange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf07794",
   "metadata": {},
   "outputs": [],
   "source": [
    "exchange_trading_volume = get_total_trading_volume_by_exchange(exch_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bab5c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "exchange_trading_volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305663fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "exchange_trading_volume[\"total_trading_volume_in_coins\"].plot.bar(\n",
    "    figsize=(15, 7), logy=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3b2b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalised\n",
    "exchange_trading_volume[\"daily_avg_coin_volume\"].plot.bar(\n",
    "    figsize=(15, 7), logy=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d75a9d",
   "metadata": {},
   "source": [
    "# Rolling volume for each exchange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5250bd8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_rolling_volume_by_exchange(exch_list, exch_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb18665",
   "metadata": {},
   "source": [
    "# Is volume constant over different days? E.g., weekend vs workdays?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b571ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_weekdays_volumes(exch_list):\n",
    "    \"\"\"\n",
    "    Return statistics and graphs with working days vs.\n",
    "\n",
    "    weekends analysis\n",
    "    Parameters: volume dataframes\n",
    "    \"\"\"\n",
    "    # clean the existing dataframes from previously calculated volumes\n",
    "    df = pd.concat(exch_list, axis=1)\n",
    "    df = df[[col for col in df.columns if \"total_volume\" not in col]]\n",
    "    df = df[[col for col in df.columns if \"rolling_volume\" not in col]]\n",
    "    # calculate new volumes that sum up all coins and exchanges\n",
    "    df[\"total_volume\"] = df.sum(axis=1)\n",
    "    # create column with ids for weekdays\n",
    "    df[\"weekday\"] = df.index.map(lambda x: x.strftime(\"%A\"))\n",
    "    # plot total amount of volume for each day\n",
    "    df.groupby(\"weekday\").total_volume.sum().sort_values(\n",
    "        ascending=False\n",
    "    ).plot.bar(figsize=(12, 7))\n",
    "    # plot working days vs. weekends\n",
    "    weekends = df[(df[\"weekday\"] == \"Saturday\") | (df[\"weekday\"] == \"Sunday\")]\n",
    "    sns.displot(weekends, x=\"total_volume\")\n",
    "    weekdays = df[(df[\"weekday\"] != \"Saturday\") & (df[\"weekday\"] != \"Sunday\")]\n",
    "    sns.displot(weekdays, x=\"total_volume\")\n",
    "    # calculate descriptive statistics for working days vs. weekends\n",
    "    print(\"Descriptive statistics:\")\n",
    "    weeknd_stat = weekends[\"total_volume\"].describe()\n",
    "    weekdys_stat = weekdays[\"total_volume\"].describe()\n",
    "    weeknd_stat = pd.DataFrame(weeknd_stat)\n",
    "    weekdys_stat = pd.DataFrame(weekdys_stat)\n",
    "    stats = pd.concat([weeknd_stat, weekdys_stat], axis=1)\n",
    "    stats.columns = [\"weekends\", \"working_days\"]\n",
    "    print(stats)\n",
    "    print(\n",
    "        \"The graph labels in respective order: Total Volume by weekdays, Distribution of Volume over weekends, Distribution of Volume over working days\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9989810",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_weekdays_volumes(exch_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe1a8f7",
   "metadata": {},
   "source": [
    "# How does it vary over hours? E.g., US stock times 9:30-16 vs other time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df13454e",
   "metadata": {},
   "source": [
    "## Binance example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378d64fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "binance_1 = get_initial_df_with_volumes(binance_coins, \"binance\")\n",
    "bitfinex_1 = get_initial_df_with_volumes(bitfinex_coins, \"bitfinex\")\n",
    "ftx_1 = get_initial_df_with_volumes(ftx_coins, \"ftx\")\n",
    "gateio_1 = get_initial_df_with_volumes(gateio_coins, \"gateio\")\n",
    "kucoin_1 = get_initial_df_with_volumes(kucoin_coins, \"kucoin\")\n",
    "\n",
    "exchange_list = [binance_1, bitfinex_1, ftx_1, gateio_1, kucoin_1]\n",
    "binance_1.name = \"binance\"\n",
    "bitfinex_1.name = \"bitfinex\"\n",
    "ftx_1.name = \"ftx\"\n",
    "gateio_1.name = \"gateio\"\n",
    "kucoin_1.name = \"kucoin\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce18f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_ath_volumes_comparison(exchange_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00dadce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "text_representation": {
    "extension": ".py",
    "format_name": "percent",
    "format_version": "1.3",
    "jupytext_version": "1.13.0"
   }
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
