{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "047c5c80",
   "metadata": {},
   "source": [
    "# Description\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "296f9d2f",
   "metadata": {},
   "source": [
    "This notebook showcases locations and basic structure of raw data from:\n",
    "\n",
    "- S3 (parquet datasets)\n",
    "- DB (PostGres)\n",
    "\n",
    "The following exchanges and data types for each universe are included:\n",
    "**Rewrite the data names according to the protocol https://docs.google.com/document/d/1r53D8XHlDhoSF_rSXfWhXIbX7VR-QeZ_7Y-vnf_nUcQ/edit#heading=h.n1q8t37kb6e4**\n",
    "- CCXT OHLCV futures realtime (DB)\n",
    "- CCXT OHLCV futures historical (daily from S3)\n",
    "- CryptoChassis bid/ask futures historical daily (1 sec)\n",
    "- CryptoChassis bid/ask futures historical daily (1 min resample)\n",
    "- CryptoChassis bid/ask spot historical daily (1 sec)\n",
    "- CryptoChassis bid/ask spot historical daily (1 min resample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7934ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO(Danya): Replace prints with logs/functions from hprint\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc27535",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d1a9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from typing import List, Optional\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import core.statistics.descriptive as cstadesc\n",
    "import helpers.hdbg as hdbg\n",
    "import helpers.henv as henv\n",
    "import helpers.hparquet as hparque\n",
    "import helpers.hprint as hprint\n",
    "import helpers.hsql as hsql\n",
    "import im_v2.im_lib_tasks as imvimlita"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e56ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "hdbg.init_logger(verbosity=logging.INFO)\n",
    "\n",
    "_LOG = logging.getLogger(__name__)\n",
    "\n",
    "_LOG.info(\"%s\", henv.get_system_signature()[0])\n",
    "\n",
    "hprint.config_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31434422",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf99fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO(Danya) -> get_raw_data_from_db\n",
    "# -> master_raw_data_gallery_lib.py\n",
    "def get_raw_ccxt_realtime_data(\n",
    "    db_table: str,\n",
    "    exchange_id: str,\n",
    "    start_ts: Optional[str],\n",
    "    end_ts: Optional[str],\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Read raw data for given exchange from the RT DB.\n",
    "\n",
    "    Bypasses the IM Client to avoid any on-the-fly transformations.\n",
    "    \"\"\"\n",
    "    # Get DB connection.\n",
    "    env_file = imvimlita.get_db_env_path(\"dev\")\n",
    "    # Connect with the parameters from the env file.\n",
    "    connection_params = hsql.get_connection_info_from_env_file(env_file)\n",
    "    connection = hsql.get_connection(*connection_params)\n",
    "    # Read data from DB.\n",
    "    query = f\"SELECT * FROM {db_table} WHERE exchange_id='{exchange_id}'\"\n",
    "    if start_ts:\n",
    "        start_ts = pd.Timestamp(start_ts)\n",
    "        unix_start_timestamp = hdateti.convert_timestamp_to_unix_epoch(start_ts)\n",
    "        query += f\" AND timestamp >='{unix_start_timestamp}'\"\n",
    "    if end_ts:\n",
    "        end_ts = pd.Timestamp(end_ts)\n",
    "        unix_end_timestamp = hdateti.convert_timestamp_to_unix_epoch(end_ts)\n",
    "        query += f\" AND timestamp <='{unix_end_timestamp}'\"\n",
    "    rt_data = hsql.execute_query_to_df(connection, query)\n",
    "    return rt_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cbdcb5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -> master_raw_data_gallery_lib.py\n",
    "def load_parquet_by_period(\n",
    "    start_ts: pd.Timestamp, end_ts: pd.Timestamp, s3_path: str\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Read raw historical data from the S3.\n",
    "\n",
    "    Bypasses the IM Client to avoid any on-the-fly transformations.\n",
    "    \"\"\"\n",
    "    # Create timestamp filters.\n",
    "    timestamp_filters = hparque.get_parquet_filters_from_timestamp_interval(\n",
    "        \"by_year_month\", start_ts, end_ts\n",
    "    )\n",
    "    # Load daily data from s3 parquet.\n",
    "    cc_ba_futures_daily = hparque.from_parquet(\n",
    "        s3_path, filters=timestamp_filters, aws_profile=\"ck\"\n",
    "    )\n",
    "    \n",
    "    cc_ba_futures_daily = cc_ba_futures_daily.sort_index()\n",
    "    return cc_ba_futures_daily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0d354e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO(Danya): look into the `add` method on a list of Series.\n",
    "def combine_stats(stats: List[pd.Series]) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Summarize the statistics from pandas Series.\n",
    "\n",
    "    Example of one statistic Series:\n",
    "\n",
    "        bid_price    0.0\n",
    "        bid_size     0.0\n",
    "        ask_price    0.0\n",
    "        ask_size     0.0\n",
    "        dtype: float64\n",
    "    \"\"\"\n",
    "    base_stat = stats[0]\n",
    "    for stat in stats[1:]:\n",
    "        base_stat = base_stat.add(stat)\n",
    "    return base_stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "663205d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO(Danya): Remove, import the function merged into master.\n",
    "def find_gaps_in_time_series(\n",
    "    time_series: pd.Series,\n",
    "    start_timestamp: pd.Timestamp,\n",
    "    end_timestamp: pd.Timestamp,\n",
    "    step: str,\n",
    ") -> pd.Series:\n",
    "    \"\"\"\n",
    "    Find missing points on a time interval specified by [start_timestamp,\n",
    "    end_timestamp], where point distribution is determined by <step>.\n",
    "\n",
    "    :param time_series: time series to find gaps in\n",
    "    :param start_timestamp: start of the time interval to check\n",
    "    :param end_timestamp: end of the time interval to check\n",
    "    :param step: distance between two data points on the interval,\n",
    "      i.e. \"S\" -> second, \"T\" -> minute\n",
    "      for a list of aliases.\n",
    "    :return: pd.Series representing missing points in the source time series.\n",
    "    \"\"\"\n",
    "    correct_time_series = pd.date_range(\n",
    "        start=start_timestamp, end=end_timestamp, freq=step\n",
    "    )\n",
    "    return correct_time_series.difference(time_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29392ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO(Danya): Check if this is the latest version, -> master_raw_data_gallery_lib.py\n",
    "def process_s3_data_in_chunks(\n",
    "    start_ts: str, end_ts: str, s3_path: str\n",
    ") -> List[pd.Series]:\n",
    "    \"\"\"\n",
    "    Load S3 historical data by parts and count the statisticts.\n",
    "    \"\"\"\n",
    "    overall_rows = 0\n",
    "    gaps_count = 0\n",
    "    nans_stats = []\n",
    "    zeros_stats = []\n",
    "    start_ts = pd.Timestamp(start_ts, tz=\"UTC\")\n",
    "    end_ts = pd.Timestamp(end_ts, tz=\"UTC\")\n",
    "    # Separate time period to months.\n",
    "    # E.g. of `dates` sequence `['2022-10-31 00:00:00+00:00', '2022-11-30 00:00:00+00:00']`.\n",
    "    dates = pd.date_range(start_ts, end_ts, freq=\"M\")\n",
    "    for i in range(0, len(dates), 2):\n",
    "        # Iterate through the dates to select the loading period boundaries.\n",
    "        # One chunk of data is loaded for two months. \n",
    "        # E.g. the sequence of ['2022-09-31', '2022-10-30', '2022-11-31', '2022-12-31']\n",
    "        # should be divided into two periods: ['2022-09-31', '2022-10-30']\n",
    "        # and ['2022-11-31', '2022-12-31']\n",
    "        # TODO(Danya): Pass a month timedelta as a parameter.\n",
    "        start_end = dates[i : i + 2]\n",
    "        if len(start_end) == 2:\n",
    "            start, end = dates[i : i + 2]\n",
    "            print(f\"Loading data for the months {start.month} and {end.month}\")\n",
    "        else:\n",
    "            start = dates[i]\n",
    "            end = None\n",
    "            print(f\"Loading data for the month {start.month}\")\n",
    "        # Load the data of the time period.\n",
    "        daily_data = load_parquet_by_period(start, end, s3_path)\n",
    "        overall_rows += len(daily_data)\n",
    "        print(\"Head:\")\n",
    "        display(daily_data.head(2))\n",
    "        print(\"Tail:\")\n",
    "        display(daily_data.tail(2))\n",
    "        # Count NaNs.\n",
    "        nans = cstadesc.compute_frac_nan(daily_data)\n",
    "        # Count zeros.\n",
    "        zeros = cstadesc.compute_frac_zero(\n",
    "            daily_data[\n",
    "                [\"bid_price\", \"bid_size\", \"ask_price\", \"ask_size\"]\n",
    "            ]\n",
    "        )\n",
    "        nans_stats.append(nans)\n",
    "        zeros_stats.append(zeros)\n",
    "        # Count gaps in time series.\n",
    "        if end is None:\n",
    "            end = daily_data.index[-1]\n",
    "        gaps = find_gaps_in_time_series(\n",
    "            daily_data.index, start, end, \"T\"\n",
    "        )\n",
    "        gaps_count += len(gaps)\n",
    "    print(f\"{overall_rows} rows overall\")\n",
    "    print(f\"Found {gaps_count} missing points on a time interval, step - minutes\")\n",
    "    return nans_stats, zeros_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5271eefc",
   "metadata": {},
   "source": [
    "# Realtime (the DB data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f27af4c",
   "metadata": {},
   "source": [
    "## OHLCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e9e56fe",
   "metadata": {},
   "source": [
    "### CCXT futures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3803a860",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the real time data from DB.\n",
    "ccxt_rt = get_raw_ccxt_realtime_data(\n",
    "    \"ccxt_ohlcv_futures\", \"binance\", start_ts=None, end_ts=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d31130",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{len(ccxt_rt)} rows overall\")\n",
    "print(\"Head:\")\n",
    "display(ccxt_rt.head(3))\n",
    "print(\"Tail:\")\n",
    "display(ccxt_rt.tail(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "137c686e",
   "metadata": {},
   "source": [
    "#### Count NaNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f8d9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO(Danya): Remove this stat\n",
    "cstadesc.compute_frac_nan(ccxt_rt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca4dddf3",
   "metadata": {},
   "source": [
    "#### Rows with `volume` equal to 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6c29ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO(Danya): Remove this stat\n",
    "volume0 = ccxt_rt.loc[ccxt_rt[\"volume\"] == 0]\n",
    "volume0_proc = \"{:.2f}\".format(len(volume0) * 100 / len(ccxt_rt))\n",
    "print(\n",
    "    f\"Percentage of data with `volume=0` in real time CCXT data: {volume0_proc}%\"\n",
    ")\n",
    "print(f\"{len(volume0)} overall\")\n",
    "print(\"First 5 rows:\")\n",
    "display(volume0.head())\n",
    "print(\"Last 5 rows:\")\n",
    "display(volume0.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5e1dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = volume0[\"currency_pair\"].value_counts().plot(kind=\"bar\")\n",
    "ax = ax.bar_label(ax.containers[-1], label_type=\"edge\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df3f4a24",
   "metadata": {},
   "source": [
    "# Historical (data updated daily)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f882eb43",
   "metadata": {},
   "source": [
    "## OHLCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ff4d63",
   "metadata": {},
   "source": [
    "### CCXT futures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a72dd91",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_path = \"s3://cryptokaizen-data/reorg/daily_staged.airflow.pq/ohlcv-futures/ccxt/binance\"\n",
    "# Load daily data from s3 parquet.\n",
    "ccxt_futures_daily = hparque.from_parquet(s3_path, aws_profile=\"ck\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "726262eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{len(ccxt_futures_daily)} rows overall\")\n",
    "print(\"Head:\")\n",
    "display(ccxt_futures_daily.head())\n",
    "print(\"Tail:\")\n",
    "display(ccxt_futures_daily.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa8965f8",
   "metadata": {},
   "source": [
    "**Count NaNs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0765f521",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO(Danya): Remove this stat\n",
    "\n",
    "cstadesc.compute_frac_nan(ccxt_futures_daily)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c24429a",
   "metadata": {},
   "source": [
    "#### Rows with `volume` equal to 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32727c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO(Danya): Remove this stat\n",
    "\n",
    "volume0 = ccxt_futures_daily.loc[ccxt_futures_daily[\"volume\"] == 0]\n",
    "volume0_proc = \"{:.2f}\".format(len(volume0) * 100 / len(ccxt_futures_daily))\n",
    "print(\n",
    "    f\"Percentage of data with `volume=0` in historical CCXT data for the period: {volume0_proc}%\"\n",
    ")\n",
    "print(f\"{len(volume0)} overall\")\n",
    "print(\"First 5 rows:\")\n",
    "display(volume0.head())\n",
    "print(\"Last 5 rows:\")\n",
    "display(volume0.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4134b011",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO(Danya): Remove this stat\n",
    "ax = volume0[\"currency_pair\"].value_counts().plot(kind=\"bar\")\n",
    "ax = ax.bar_label(ax.containers[-1], label_type=\"edge\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b497fbf9",
   "metadata": {},
   "source": [
    "## BID-ASK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df0b6f8",
   "metadata": {},
   "source": [
    "### CC futures (1 sec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f5df42",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_path = \"s3://cryptokaizen-data/reorg/daily_staged.airflow.pq/bid_ask-futures/crypto_chassis/binance\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d50d1e",
   "metadata": {},
   "source": [
    "The amount of data is too big to process it all at once, so the data will be loaded separately for each month and all statistics will be aggregated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e137a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_ts = \"20220627-000000\"\n",
    "end_ts = \"20221130-000000\"\n",
    "nans_stats, zeros_stats = process_s3_data_in_chunks(start_ts, end_ts, s3_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db2fee3e",
   "metadata": {},
   "source": [
    "#### Count NaNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71aac4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_stats(nans_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5cbd4eb",
   "metadata": {},
   "source": [
    "#### Count zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14401cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_stats(zeros_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9bbb51e",
   "metadata": {},
   "source": [
    "### CC futures resampled to 1 min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3996ad84",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_path = \"s3://cryptokaizen-data/reorg/daily_staged.airflow.pq/bid_ask-futures/crypto_chassis.resampled_1min/binance\"\n",
    "# Load daily data from s3 parquet.\n",
    "cc_ba_futures_resampled = hparque.from_parquet(s3_path, aws_profile=\"ck\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c4e43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{len(cc_ba_futures_resampled)} rows overall\")\n",
    "print(\"Head:\")\n",
    "display(cc_ba_futures_resampled.head())\n",
    "print(\"Tail:\")\n",
    "display(cc_ba_futures_resampled.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de5321c7",
   "metadata": {},
   "source": [
    "#### Count NaNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126564d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cstadesc.compute_frac_nan(cc_ba_futures_resampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b07063",
   "metadata": {},
   "source": [
    "#### Count zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ae2f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "cstadesc.compute_frac_zero(\n",
    "            cc_ba_futures_resampled[\n",
    "                [\"bid_price\", \"bid_size\", \"ask_price\", \"ask_size\"]\n",
    "            ]\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b0a2b9",
   "metadata": {},
   "source": [
    "### CC spot (1 sec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7fe3dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_path = \"s3://cryptokaizen-data/reorg/daily_staged.airflow.pq/bid_ask/crypto_chassis/binance\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6abde07",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_ts = \"20220501-000000\"\n",
    "end_ts = \"20221130-000000\"\n",
    "nans_stats, zeros_stats = process_s3_data_in_chunks(start_ts, end_ts, s3_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc70845",
   "metadata": {},
   "source": [
    "#### Count NaNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4276ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_stats(nans_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df76dc3",
   "metadata": {},
   "source": [
    "#### Count zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471629f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_stats(zeros_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfbe9bf5",
   "metadata": {},
   "source": [
    "### CC spot resampled to 1 min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221eea3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_path = \"s3://cryptokaizen-data/reorg/daily_staged.airflow.pq/bid_ask/crypto_chassis.resampled_1min/binance\"\n",
    "# Load daily data from s3 parquet.\n",
    "cc_ba_spot_resampled = hparque.from_parquet(s3_path, aws_profile=\"ck\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46532dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{len(cc_ba_spot_resampled)} rows overall\")\n",
    "print(\"Head:\")\n",
    "display(cc_ba_spot_resampled.head())\n",
    "print(\"Tail:\")\n",
    "display(cc_ba_spot_resampled.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebcbf464",
   "metadata": {},
   "source": [
    "#### Count NaNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4018ca94",
   "metadata": {},
   "outputs": [],
   "source": [
    "cstadesc.compute_frac_nan(cc_ba_spot_resampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6956e74",
   "metadata": {},
   "source": [
    "#### Count zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62693c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cstadesc.compute_frac_zero(\n",
    "            cc_ba_spot_resampled[\n",
    "                [\"bid_price\", \"bid_size\", \"ask_price\", \"ask_size\"]\n",
    "            ]\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "207px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
